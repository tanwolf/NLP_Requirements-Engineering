{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de9871e8-3881-46dc-83dc-494a95202348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('merged_adf_df_with_lda_topic1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dc66091-effd-43b3-a592-154c64b54d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "num_classes = df['LDATopic'].nunique()\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2c900af-835e-4bdb-ade5-48dbd6fa32a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "107/107 [==============================] - 2s 11ms/step - loss: 0.5135 - accuracy: 0.7534\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 0.3380 - accuracy: 0.8412\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.2373 - accuracy: 0.9032\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 0.1594 - accuracy: 0.9384\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.1080 - accuracy: 0.9652\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0707 - accuracy: 0.9763\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0436 - accuracy: 0.9886\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0274 - accuracy: 0.9944\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0178 - accuracy: 0.9959\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0131 - accuracy: 0.9974\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0085 - accuracy: 0.9985\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0077 - accuracy: 0.9988\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0067 - accuracy: 0.9993\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0071 - accuracy: 0.9987\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 0.9993\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0039 - accuracy: 0.9991\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 0.9999\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 0.9996\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.7317 - accuracy: 0.8772\n",
      "Test score: 0.7317292094230652\n",
      "Test accuracy: 0.8771929740905762\n"
     ]
    }
   ],
   "source": [
    "# Dropout layers have the effect of making the training process noisy, forcing nodes within a layer to probabilistically take on \n",
    "# more or less responsibility for the inputs. This can have the effect of reducing overfitting and improving model generalization.\n",
    "\n",
    "'''from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dropout\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['LemmatizedQuestionBody']).toarray()\n",
    "\n",
    "# Encode target labels\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(df['LDATopic'])\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building the model\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "nn_model.add(Dropout(0.5))  # Add dropout layer after the first Dense layer\n",
    "nn_model.add(Dense(64, activation='relu'))\n",
    "nn_model.add(Dropout(0.5))  # Add dropout layer after the second Dense layer\n",
    "nn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the model\n",
    "nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "nn_model.fit(X_train, Y_train, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluating the model\n",
    "score, acc = nn_model.evaluate(X_test, Y_test)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72533321-af3b-4eb6-84d9-47212e0ed34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 2ms/step\n",
      "Confusion Matrix:\n",
      "[[ 189  223]\n",
      " [  57 1241]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.46      0.57       412\n",
      "           1       0.85      0.96      0.90      1298\n",
      "\n",
      "    accuracy                           0.84      1710\n",
      "   macro avg       0.81      0.71      0.74      1710\n",
      "weighted avg       0.83      0.84      0.82      1710\n",
      "\n",
      "Example predictions:\n",
      "True: 0, Predicted: 1\n",
      "True: 0, Predicted: 0\n",
      "True: 1, Predicted: 1\n",
      "True: 1, Predicted: 1\n",
      "True: 1, Predicted: 1\n",
      "True: 1, Predicted: 1\n",
      "True: 0, Predicted: 1\n",
      "True: 1, Predicted: 1\n",
      "True: 1, Predicted: 1\n",
      "True: 1, Predicted: 1\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 128)               640128    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 648,449\n",
      "Trainable params: 648,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Generate predictions on the test set\n",
    "Y_pred = nn_model.predict(X_test)\n",
    "Y_pred_classes = (Y_pred > 0.5).astype(int).flatten()  # convert probabilities to class labels\n",
    "\n",
    "# Print a confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, Y_pred_classes))\n",
    "\n",
    "# Print a classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, Y_pred_classes))\n",
    "\n",
    "# Print some example predictions\n",
    "print(\"Example predictions:\")\n",
    "for i in range(10):\n",
    "    print(f\"True: {Y_test[i]}, Predicted: {Y_pred_classes[i]}\")\n",
    "\n",
    "# Print a summary of the model's architecture\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82540b91-862b-4274-9339-778d1ebf3667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
