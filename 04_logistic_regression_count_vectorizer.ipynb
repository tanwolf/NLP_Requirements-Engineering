{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "892107eb-32f2-43e9-aeec-e55aba8b057b",
   "metadata": {},
   "source": [
    "**Project: Using NLP for Requirements Engineering for Data Management Software**\n",
    "\n",
    "Source data: Stackoverflow question and answers concerning Azure Data Factory\n",
    "\n",
    "Tags: azure-data-factory, adf \n",
    "\n",
    "Title keywords: azure data factory, adf\n",
    "\n",
    "Link to data source: https://data.stackexchange.com/stackoverflow/query/new\n",
    "\n",
    "Link to generated schema: https://dbdiagram.io/d/6448f5b26b3194705139098b\n",
    "\n",
    "Link to GitHub Repo: https://github.com/tanwolf/NLP_Requirements-Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7e340-b56c-4682-9def-17ba4a799cb5",
   "metadata": {},
   "source": [
    "**Purposes of this notebook:** \n",
    "- Train a Logistic Regression Model to correctly identify topics belonging to topic0/ \"Data Management in Pipelines\". The topic was identified through Latent Dirichilet Allocation   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b7bea7e-fff3-440f-b2d2-0ca12128f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('merged_adf_df_with_lda_topic1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22fcc30b-96f6-4c30-9150-61b8d8718474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.73       412\n",
      "          11       0.91      0.93      0.92      1298\n",
      "\n",
      "    accuracy                           0.87      1710\n",
      "   macro avg       0.83      0.82      0.82      1710\n",
      "weighted avg       0.87      0.87      0.87      1710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize a CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer and transform 'LemmatizedQuestionBody' into a feature matrix X\n",
    "X = vectorizer.fit_transform(df['LemmatizedQuestionBody'])\n",
    "\n",
    "# The target remains the same\n",
    "y = df['LDATopic']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a logistic regression model\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and print a classification report\n",
    "y_pred = logreg.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "''''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee1cb60-971b-46b5-a809-2d5a94410518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 291  121]\n",
      " [  93 1205]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Same setup as before...\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a592218-d9e9-4a8e-8f85-9193f9b02a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-1.8046\tdataflows      \t\t1.9717\tdoesnt         \n",
      "\t-1.7123\tdataflow       \t\t1.5091\tmyexpression   \n",
      "\t-1.5817\tfollowing      \t\t1.5038\tdatafactoryname\n",
      "\t-1.3450\tguidance       \t\t1.4720\tmydate         \n",
      "\t-1.3017\tannotation     \t\t1.2337\tcomplete       \n",
      "\t-1.2582\tcompression    \t\t1.1317\tsomeid         \n",
      "\t-1.2522\tflatten        \t\t1.1246\tmd             \n",
      "\t-1.2506\tregex          \t\t1.1213\tconnect        \n",
      "\t-1.2346\tcompare        \t\t1.0887\tapplication    \n",
      "\t-1.1564\tfed            \t\t1.0486\tsap            \n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefs_with_fns = sorted(zip(logreg.coef_[0], feature_names))\n",
    "top = zip(coefs_with_fns[:10], coefs_with_fns[:-(10 + 1):-1])\n",
    "for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "    print(\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b18c765a-df77-4464-96ef-94e20a73b952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.82807018 0.81461988 0.83382095 0.76711527 0.812756  ]\n",
      "Average cross-validation score:  0.8112764552301371\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "scores = cross_val_score(logreg, X, y, cv=5)\n",
    "print(\"Cross-validation scores: \", scores)\n",
    "print(\"Average cross-validation score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ba0c6c4-496c-4985-a42e-90cc3ff0bfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1685\n",
      "          11       0.99      1.00      0.99      5152\n",
      "\n",
      "    accuracy                           0.99      6837\n",
      "   macro avg       0.99      0.98      0.99      6837\n",
      "weighted avg       0.99      0.99      0.99      6837\n",
      "\n",
      "Training Accuracy:  0.9903466432645898\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "\n",
    "# Print a classification report for the training set\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "# Compute the accuracy on the training set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Training Accuracy: \", train_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0277578b-832b-466b-9c48-8a66493784eb",
   "metadata": {},
   "source": [
    "***GPT4 prompt:*** Summarize and anylze the results:\n",
    "\n",
    "***GPT4 result:*** The Logistic Regression model is used to classify the questions into two categories, class 0 and class 11.\n",
    "\n",
    "    Classification Report: The classification report shows that the model has an overall accuracy of 87%, which is quite good. The precision, recall, and f1-score for class 0 are 76%, 71%, and 73% respectively. For class 11, these metrics are 91%, 93%, and 92%. This shows that the model is performing better on class 11 than class 0, which is similar to the results obtained from the previous SVM model.\n",
    "\n",
    "    Confusion Matrix: The confusion matrix provides similar insights. The model correctly identified 291 instances of class 0, but misclassified 121 as class 11. Similarly, the model correctly identified 1205 instances of class 11 but misclassified 93 as class 0. This confirms that the model is performing better on class 11 than class 0.\n",
    "\n",
    "    Feature Importance: The model provides coefficients that correspond to the importance of each feature. The most influential words for class 0 seem to be \"dataflows\", \"dataflow\", \"following\", and others, whereas for class 11, the words \"doesnt\", \"myexpression\", \"datafactoryname\", and others seem to be the most influential.\n",
    "\n",
    "    Cross-validation scores: The cross-validation scores are fairly consistent, ranging from about 0.76 to 0.83, with an average of 0.81. This suggests that the model's performance is robust and not overly dependent on the particular division of the data into training and test sets.\n",
    "\n",
    "In conclusion, the Logistic Regression model performs well with an average accuracy of 81% in cross-validation. As with the previous SVM model, this model performs better on class 11 than on class 0. The feature importance analysis gives an insight into which words are most influential in classifying a question into each class. To improve the model's performance, especially for class 0, it may be beneficial to look into feature engineering or fine-tuning the model's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9736be0-e525-42e1-a1b5-1c08abf9798f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
