QuestionId,QuestionTitle,QuestionBody,QuestionTags,Date,ViewCount,Score,NumberOfAnswers,AnswerId,AnswerBody
"75698058","How to find correlation of two set of software requirements","<p>I have a thought to find correlation between given set of high level software requirements to customer requirement specification both of which are represented by English text. I want to do this to find which high level requirement corresponds to which customer requirement specification. Can anyone guide me how to do this? Are there any open source libraries to use?</p>
<p>I don't know much on machine learning or natural language processing, so have not tried anything yet</p>
","<machine-learning><nlp>","2023-03-10 15:34:07","16","0","1","75700898","<p>You can use many methods
One of them I like is using NLTK or spaCy to tokenize and preprocess the text, and then use scikit-learn to compute the similar.</p>
<p>Here is an example:</p>
<pre><code>import nltk

def split_sentences(text):
    words = nltk.word_tokenize(text)
    
    tagged_words = nltk.pos_tag(words)
    
    sentences = []
    
    buffer = []
    
    for word, tag in tagged_words:
        if tag == 'VBZ' or tag == 'VBP' or tag == 'VBG' or tag == 'VBN' or tag == 'VBD':
            if buffer:
                sentence = ' '.join(buffer)
                sentences.append(sentence)
                buffer = []
        else:
            buffer.append(word)
    
    if buffer:
        sentence = ' '.join(buffer)
        sentences.append(sentence)
    
    return sentences
</code></pre>
"
"75137480","Use dictionaries as requirements for if statements","<p>First of all, I`m sorry if I might ask this question and if it was already answered somewhere else. I couldnt find any solution for the following Problem:</p>
<p>I want to create a list where I apply multiple restricions. But instead of using over hundreads of if statements i just want to use a dictionary in one if statement to apply the requirements. So to say I want to use the keys of the dictionary as requirements and its values as factors for the data.</p>
<p>Lets take a look at a small example:</p>
<p>I want to create data for a countourplot where x/y range from [-50,50] in steps of 1 and the z function has requirements based on the if statements:</p>
<p>The following code is what works, but the more requirements I add the longer and more unreadalbe the code gets:</p>
<pre><code>x = np.linspace(-50 , 50, 100)
y = np.linspace(-50 , 50, 100)
z = []
z_0 = 100
for i in x:
   for j in y:
      if i**2 + j**2 &lt;= 10**2:
         z.append(1.9 * z_0)
      elif i**2 + j**2 &lt;= 20**2:
         z.append(1.5 * z_0)
      elif i**2 + j**2 &lt;= 30**2:
         z.append(1.4 * z_0)
      elif i**2 + j**2 &lt;= 40**2:
         z.append(1.05 * z_0)
      else
         z.append(z_0)
</code></pre>
<p>This would create a map with radial decreasing hight as a function of z on different positions. Is it possible to do this in the following way which is way less redundant? My main problem is how to assing the correct value.</p>
<pre><code>x = np.linspace(-50 , 50, 100)
y = np.linspace(-50 , 50, 100)
z = []
requirements_dict = {10:1,9, 20:1.5, 30:1.4, 40:1.05}
z_0 = 100
for i in x:
   for j in y:
      if i**2 + j**2 &lt;= (each key of the requirements_dict) :
         z.append( (corresponding value of the requirements dict)   * z_0)
      else
         z.append(z_0)
</code></pre>
<p>Thanks in advance for the help and sorry again if this question was already asked.</p>
","<python-3.x><dictionary><if-statement><requirements>","2023-01-16 17:09:21","38","0","1","75137627","<p>Is this what you're looking for?</p>
<p>EDIT:</p>
<pre><code>import numpy as np

x = np.linspace(-50 , 50, 100)
y = np.linspace(-50 , 50, 100)
z = []
requirements_dict = {10: 1.9, 20: 1.5, 30: 1.4, 40: 1.05}
z_0 = 100
for i in x:
    for j in y:
        for key, value in requirements_dict.items():
            if i**2 + j**2 &lt;= key:
                z.append(value * z_0)
                break
        else:
            z.append(z_0)
</code></pre>
"
"75111771","How to create a custom excel template for export customized work items for a project in Polarion?","<p>I am trying to create a custom export template for excel export of workitems in my polarion project but every time I upload a template it and when I select that template at the time of exporting it It shows me this error: &quot;Server error: java.lang.NullPointerException&quot;.
I tried to even make export template by using existing templates but it still shows me the same error.</p>
","<java><export-to-excel><requirements><polarion><system-requirements>","2023-01-13 16:13:42","72","-1","1","75113368","<p>To save yourself from trouble, it is easiest to make the template starting from one of the provided templates. Make sure you don't delete the sheet titled &quot;Polarion&quot;. In the &quot;Export Work Items&quot; dialog, use the &quot;Show template&quot; link to download an empty template.</p>
<p>In Excel, in the &quot;Polarion&quot; sheet and &quot;Sheet1&quot; sheet, configure your Work Item type and the fields that you want to export. Make sure all fields that you specify actually exist in your Work Item configuration. You may want to make changes step-by-step: make only a small change and test the template to make sure it still works, until you become more confident about the structure.</p>
<p>If you follow the instructions for your version of Polarion, it should work. See &quot;Customize export templates for Microsoft Excel&quot; in the Polarion help. On my system with 22R1, this is the direct help link: <a href=""http://localhost/polarion/help/topic/com.polarion.xray.doc.user/guide/xid1747724.html?cp=0_3_18_10"" rel=""nofollow noreferrer"">http://localhost/polarion/help/topic/com.polarion.xray.doc.user/guide/xid1747724.html?cp=0_3_18_10</a>. The Polarion help for 19.2 is available online: <a href=""https://docs.plm.automation.siemens.com/content/polarion/19.2/help/en_US/user_and_administration_help/administrators_guide/advanced_administration/customize_export_templates_for_microsoft_excel.html"" rel=""nofollow noreferrer"">https://docs.plm.automation.siemens.com/content/polarion/19.2/help/en_US/user_and_administration_help/administrators_guide/advanced_administration/customize_export_templates_for_microsoft_excel.html</a></p>
<p>If you've followed the instructions exactly and it still doesn't work, it's likely that something is wrong with your installation. You'll have to check the logs in <code>C:\Polarion\data\logs\main\</code> to see what is going wrong.</p>
"
"74837919","Alloy dynamic modelling with predicates","<p>I am trying to model in alloy a system where the users can make comments on forum threads. I want to describe with a predicate a situation where a new comment is added to a forum thread.</p>
<p>This is what I have done:</p>
<pre><code>//other signatures (including User, DateTime, ...)

sig ForumThread {
    title: one String,
    datePosted: one DateTime,
    author: one User,
    content: one String,
    comments: set Comment
}

sig Comment {
    content: one String,
    datePosted: one DateTime,
    author: one User,
}

//other signatures ...

fact allCommentsAreInAThread{
    all c: Comment | one t: ForumThread | c in t.comments
}

//other facts ...

pred addComment[t, t': ForumThread , c: Comment ] {
    t'.comments = t.comments + c
    t'.datePosted = t.datePosted
    t'.author = t.author
    t'.content = t.content
    t'.title = t.title
}
run addComment

//...
</code></pre>
<p>Now, this predicates is consistent (as the analyzer said). However, i think that it can be true only in trivial models, that are the ones where c is already in t.comments and where t is exactly t’. This, because the first fact says that a Comment must always have to be exactly in a ForumThread. Is what i am saying true? If yes, is there a way i can model what i am trying to do without eliminating the fact (since it wouldn't have sense to have comments that are in nothing)?</p>
","<model><logic><alloy><requirements>","2022-12-17 22:32:21","40","0","1","74848619","<blockquote>
<p>However, i think that it can be true only in trivial models, that are the ones where c is already in t.comments and where t is exactly t’.</p>
</blockquote>
<p>Indeed, because of <code>allCommentsAreInAThread</code>, which is a fact (= an axiom) so any model necessarily respects it.</p>
<blockquote>
<p>is there a way i can model what i am trying to do without eliminating the fact (since it wouldn't have sense to have comments that are in nothing)?</p>
</blockquote>
<p>You must remove the fact as, as you realized, it already imposes what you expect. Instead, you must <em>check</em> a property, which says that there's never a comment without a parent thread, in whichever <em>state</em> of your system. Hence, you need (1) a notion of state and (2) to check the property (here: an invariant) on any state.</p>
<p>There are two main ways to design a notion of state:</p>
<ol>
<li>The &quot;global state&quot; approach: you create a <code>State</code> sig (say) that gathers all state variables.</li>
<li>The &quot;local state&quot; approach: signatures contain both constant and time-varying fields.</li>
</ol>
<p>AFAIK, the latter approach is more frequent in Alloy.</p>
<p>Finally, notice Alloy 6 now has features that make it easier to model and specify state-related properties. You can find some information <a href=""https://haslab.github.io/formal-software-design/"" rel=""nofollow noreferrer"">here</a>.</p>
"
"74560990","PyCharm doesn't see installed packages","<p>After reimporting the project form VCS I'm trying to install packages listed in requirements.txt. Pycharm installs all packages (also I tried to do it manually; remove requirements.txt and install packages manually, then generate new requirements.txt; etc.). Installation completes successfully and installed packages not highlighted and present in the interpreter settings.
But every time I'm trying to run tests, e.g. <code>pytest tests/folder/test</code> I'm getting na error</p>
<pre><code>AttributeError: type object 'Test_**' has no attribute 'driver'
</code></pre>
<p>I suppose fixture which creates driver doesn't initiates\</p>
<p>Sometimes, doing exact the same actions I'm able to run tests successfully, but debugger refuses to work, returning the same error.</p>
<p>Struggling with that already a week, have no idea what to do.</p>
","<python-3.x><pycharm><pytest><virtualenv><requirements>","2022-11-24 12:42:48","55","0","1","74616479","<p>I found out that issue was related not to the PyCharm or virtualenv, but to the python 3.11. Revert to the python 3.10 and reinstall of virtualenv solved the problem</p>
"
"73705196","How to show interaction between two statuses on a diagram?","<p>Imagine there are two statuses that an application is operating with, e.g. order status and shipment status.</p>
<p>When the order status is placed, the shipment status is blank.
When the order status is &quot;paid&quot;, the shipment status is &quot;ready to ship&quot;.
Then the shipment status is being changed to &quot;assigned&quot; through &quot;shipped&quot;, &quot;on delivery&quot; and &quot;delivered&quot;.
Should the order status be set to &quot;Cancelled&quot; the &quot;shipped&quot; or &quot;on delivery&quot; shipment status is changed to &quot;being returned&quot; and then &quot;received at the warehouse&quot;.</p>
<p>What is the best way to describe the interaction between the two statuses on a diagram?</p>
<p>I know two types of diagrams that could be utilized here, but both have drawbacks for the task:</p>
<ol>
<li>Activity Diagram - will perfectly describe the use cases, but is hard to read</li>
<li>State Machine Diagram - can only describe one status, so there can be two state diagrams, but it won't be clear how the statuses interact with each other.</li>
</ol>
<p>What would you recommend?</p>
","<uml><analysis><diagram><requirements><system-requirements>","2022-09-13 15:00:26","66","2","1","73731045","<p>Your UML model contains two state machines. A UML model can be visualized by one or more UML diagrams. A UML diagram may visualize any subset of the UML model, or even the whole model (see UML specification version 2.5.1, Annex A). Therefore, it is allowed to show both state machines in one diagram.</p>
<p>The dependencies between two state machines can be modeled in two ways:</p>
<ol>
<li><p>Using 'signal send symbols' in one state machine to send a message to the other state machine. The other state machine uses these messages by means of 'signal receipt symbols'. See figure 14.32 of UML spec 2.5.1.</p>
</li>
<li><p>Using actions in one state machine and corresponding triggers in the other. This is the most convenient technique for your problem, as illustrated by the diagram fragment below. Actions are written behind a slash.</p>
</li>
</ol>
<p><a href=""https://i.stack.imgur.com/CRa11.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/CRa11.png"" alt=""two-machines-in-one-diagram"" /></a></p>
"
"73654054","Modeling UML Use Case Diagram for Library Online Management System","<p>I have a list of functionality that the system should have and I have created a case diagram for it, but I am not sure if it correspond to said functionality and want a second look on my solution. Hopefully it is readable and I appreciate any feedback on my trail of design.</p>
<p>Description of said functions:</p>
<blockquote>
<p>The system shall allow people to register as a student or faculty member. To sign up, users must provide their name, e-mail address, phone number, and a password. In addition, students add the name of their program and their student id; faculty members add the name of their department and their employee id.</p>
<p>A user shall be able to search for books, the library system shall indicate the availability for books. If available for loan, a logged in user shall be able to reserve a book for loan. When reserved, the librarian will move the book to a pick-up shelf. To loan a book, users shall login at the library in person, and checkout the books.</p>
<p>The library has an automated booth where users can leave the books and the system shall process the return, upon return, the system shall send a digital receipt sent to their e-mail address.
When a book is not returned in time, the system shall send a reminder e-mail with a fine for each day it is late.</p>
<p>The system shall allow users to extend the loan period of a loaned book at most two times. The system shall allow users to have at most five books on loan simultaneously. If a book is not available in current library, but is in another one, users can ask the system to transfer and vice versa. Books have a title, author, ISBN, edition, and shelf number denoting their location in the library. The library has varying stock for different books, it has a single copy for most books but up to ten physical copies for some popular books.</p>
<p>Librarians shall be able to add new books to the system and edit the information of existing books.</p>
</blockquote>
<p>The design :</p>
<p><a href=""https://i.stack.imgur.com/vvvE6.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/vvvE6.png"" alt=""enter image description here"" /></a></p>
<p><strong>Update based on feedback</strong>:
<a href=""https://i.stack.imgur.com/W2cku.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/W2cku.png"" alt=""enter image description here"" /></a></p>
","<uml><use-case><requirements><use-case-diagram>","2022-09-08 19:13:46","996","1","2","73654300","<p>I will not make a detailed review of your diagram, since this is very specific to your needs and will not help anybody else.  However,  I'd like to address some general issues that are frequent in these kind of diagrams:</p>
<ul>
<li><p>It appears in the requirements that users may be a student or  faculty member (or both?), whereas your diagram suggest that a user is another independent category of actors.</p>
</li>
<li><p>Having several actors for a use case is ambiguous.  It cannot always be avoided, but here, it's not clear if all the actors are involved at the same time for a search, or if they are involved one after the other, or if only one may be involved at a time.</p>
</li>
<li><p>Your diagram is a functional decomposition of the requirements.  For example, <code>Register</code> and <code>Verify registry</code> are not independent,  but the second belongs to the detailed decomposition of the first, without being an independent user goal (in fact, the verification doesn't make sense without the first). The same applies to all the verifications (&quot;maximum...&quot;) as well.   This is not forbidden but strongly discouraged as it leads to too detailed and complex diagrams.</p>
</li>
<li><p>Sometimes your diagram seems to be a sequence of action:  e.g. <code>Return a book</code> is followed by a <code>confirmation email</code>.  Use-case diagrams shall not show any sequence.  If you want to show the workflow, you need to use an activity diagram and not a use-case diagram.</p>
</li>
<li><p>extend corresponds to an optional use-case. Here, you seem to say that books are returned only for some loans.</p>
</li>
</ul>
<p>In conclusion,  simplify your diagram to show only user goals.  Avoid extend and include dependencies as much as possible, to keep it simple and understandable.  If you want to document details, document them in a narrative, not in the diagram.</p>
"
"73654054","Modeling UML Use Case Diagram for Library Online Management System","<p>I have a list of functionality that the system should have and I have created a case diagram for it, but I am not sure if it correspond to said functionality and want a second look on my solution. Hopefully it is readable and I appreciate any feedback on my trail of design.</p>
<p>Description of said functions:</p>
<blockquote>
<p>The system shall allow people to register as a student or faculty member. To sign up, users must provide their name, e-mail address, phone number, and a password. In addition, students add the name of their program and their student id; faculty members add the name of their department and their employee id.</p>
<p>A user shall be able to search for books, the library system shall indicate the availability for books. If available for loan, a logged in user shall be able to reserve a book for loan. When reserved, the librarian will move the book to a pick-up shelf. To loan a book, users shall login at the library in person, and checkout the books.</p>
<p>The library has an automated booth where users can leave the books and the system shall process the return, upon return, the system shall send a digital receipt sent to their e-mail address.
When a book is not returned in time, the system shall send a reminder e-mail with a fine for each day it is late.</p>
<p>The system shall allow users to extend the loan period of a loaned book at most two times. The system shall allow users to have at most five books on loan simultaneously. If a book is not available in current library, but is in another one, users can ask the system to transfer and vice versa. Books have a title, author, ISBN, edition, and shelf number denoting their location in the library. The library has varying stock for different books, it has a single copy for most books but up to ten physical copies for some popular books.</p>
<p>Librarians shall be able to add new books to the system and edit the information of existing books.</p>
</blockquote>
<p>The design :</p>
<p><a href=""https://i.stack.imgur.com/vvvE6.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/vvvE6.png"" alt=""enter image description here"" /></a></p>
<p><strong>Update based on feedback</strong>:
<a href=""https://i.stack.imgur.com/W2cku.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/W2cku.png"" alt=""enter image description here"" /></a></p>
","<uml><use-case><requirements><use-case-diagram>","2022-09-08 19:13:46","996","1","2","73659181","<p>To boil it down: this is no use case synthesis but functional decomposition. Use cases show added value for actors. Full stop. This is obviously the hardest thing to learn when finding use cases. They are like pearls you have to find. It's not about the how-to.</p>
<p>I recommend reading Bittner/Spence about use cases.</p>
"
"73633585","How can I specify dependency minimum and maximum version in setup.cfg?","<h2>Problem description</h2>
<p>I would want to define the install requirement for my pip package. Let's say FooLibrary's version should be &gt;=2 but &lt;3.2.</p>
<p>Currently, I have</p>
<pre><code>[options]
install_requires =
    FooLibrary &gt;= 2
</code></pre>
<h2>Question</h2>
<p>How can I add a rule for maximum version of the library together with the minimum version rule?</p>
","<python><dependencies><python-packaging><requirements>","2022-09-07 10:03:51","257","1","1","73633691","<p>Separate version requirements with commas.</p>
<p>So for example, in this case, <code>FooLibrary &gt;=2,&lt;3.2</code> works</p>
"
"73568216","How to calculate execution time in DXL","<p>I'm trying to make a program in DXL (IBM DOORS) and I have a doubt. I have several ideas about how to make the script, but I would like to know which one has the least cost in time.</p>
<p>For example (this isn't the real program that I want to do, but a triviality to exemplify what I ask), in the program below how can I know the time it takes me in seconds?</p>
<pre><code>Folder f = current Folder;

void ScanFolder(Folder f) {

    Item itm;

    for itm in f do {

        if (type(itm) == &quot;Folder&quot;) {

            print &quot;FOLDER: &quot; fullName(itm) &quot;\n&quot;;
            ScanFolder(folder(itm));

        }

        else if (type(itm) == &quot;Formal&quot;) {

            print &quot;MODULE: &quot; fullName(itm) &quot;\n&quot;;

        }

        else {

            ;

        }

    }

}
</code></pre>
","<performance><time><execution-time><requirements><ibm-doors>","2022-09-01 10:56:53","78","1","1","73568942","<p>If seconds is detailed enough, you can use <code>intOf (today())</code> as start and end time. In case you need millisecods, there's an undocumented perm <code>int getTickCount_ ()</code></p>
"
"73295093","How to draw a use-case diagram for the given context?","<p>Given the following description of a tracking request to DHL</p>
<blockquote>
<p>In the age of Corona, we order many things online. The delivery does not
always work out as planned, so we are interested in getting (more) information
about the delivery.<br />
<br />
The DHL packet service has a comprehensive web service where it
provides information on shipping and receiving packages. Among
other things, page visitors can search for contact information on
the DHL webservice. Another option is to contact DHL via a chat.
Requests in the chat are answered automatically by a DHL AI, one
instance of the DHL webservice. A visitor can send a request (via
the chat), which includes also entering the consignment number of
the package to the DHL AI. Then, in order to get information about
the shipment, the visitor needs to authenticate in the webservice,
which promotes the visitor to a customer and the DHL AI is allowed
to reply to the chat request. In case the DHL AI cannot answer the
request, it forwards the request to a DHL employee. To shorten the
waiting time the customer can optionally contact the DHL employee
via phone.</p>
</blockquote>
<p>How to draw the use-case diagram? Is this correct:
<a href=""https://i.stack.imgur.com/qF8l1.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qF8l1.png"" alt=""enter image description here"" /></a></p>
<p>and how would I model the &quot;... optionally contact the DHL employee via phone&quot; use case? Would this use case extend the forward request use case? Can we then just associate the customer with the extended use case like this</p>
<p><a href=""https://i.stack.imgur.com/MuNOk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MuNOk.png"" alt=""Use-case diagram extended"" /></a></p>
<p>but then wouldnt the &quot;contact DHL via chat&quot; include the &quot;send request&quot; use case?</p>
","<uml><use-case><requirements><use-case-diagram>","2022-08-09 16:20:58","137","2","1","73297684","<p>A use case normally should correspond to a user goal, and unless it's an extension, it should also make sense independently of other use-cases. In this regard:</p>
<ul>
<li><code>Reply to request</code>  does not make any sense on its own.  So this &quot;use case&quot; is probably a detail of the use-case <code>Contact DHL</code>.  The DHL AI would then be a secondary actor of the <code>Contact DHL</code> use-case.</li>
<li><code>Send request</code> seems likewise to be a detail of how to contact the DHL agent.</li>
<li>Details such as <code>Enter consignment number</code> or <code>send request</code> are user interface detail.  Use-case should not be used to model user-interface. This is a design topic, and putting it in the use-case would force to use one specific user-interface approach without considering better alternatives.</li>
<li>Authenticate is not a use-case.  It's a constraint.  Imagine that you have a system with Single Sign On (SSO):  an authentication use case would then make no sense since there is no interaction with an actor to achieve it.</li>
</ul>
<p>So keep the use-case as simple as possible:</p>
<ul>
<li>if you start to think about the details of the scenario, and successive steps, you're no longer modeling a use-case, but a control flow:  use an activity diagram fro this level of detail.</li>
<li>if you start to take a use-case and then decompose it into smaller cases based on the narrative,  there are big chances that you'll be mislead to do functional decomposition.  This is not recommended for use-cases, since it leads to very detailed diagrams.</li>
</ul>
<p>Now to the optional use-case: optional typically suggest to use an extension.  But does <code>Contact by phone</code> really extend the <code>Contact via chat</code>?  I believe these two forms of contact are two different things.  I therefore see two approaches:</p>
<ol>
<li>Just make a use-case <code>Contact DHL</code>  and in the description of this use-case you explain that the contact can be via Phone or via Chat. This is my favourite approach.</li>
<li>Make a use-case <code>Contact DHL</code> for the general case.  Make to specialisations <code>Contact DHL by chat</code> and <code>Contact DHL by phone</code> that each could implement the general case as best fits.  This approach is more complicated, but it allows to take into account more fundamental differences between the specialisations, such as the fact that an AI actor is involved in the chat and a human operator is involved on the phone.</li>
</ol>
"
"73269786","APK crash after converting with Buildozer","<p>After I convert Python To APK using Buildozer my APK file crashes
is there something wrong in my requirements line
requirements = python3,kivy,kivymd,psutil,speedtest,pillow</p>
<pre><code>import datetime
import threading
import random
from time import sleep
import psutil
import speedtest
from kivymd.app import MDApp
from kivy.lang import Builder
from kivy.core.window import Window
from kivy.uix.screenmanager import ScreenManager, Screen
from get_size import get_size
from get_size_bits import get_size_bits
from kivymd.uix.list import OneLineListItem, TwoLineListItem, MDList
</code></pre>
","<kivy><apk><kivymd><buildozer><requirements>","2022-08-07 17:52:08","115","0","2","73269964","<p>You can use ADB to debug your APK file and see what is causing it to crash.</p>
<p>Android Debug Bridge is a tool that helps you debug Android based devices. The daemon on the Android device connects to the server on the host PC via USB.</p>
<p>You need to enable USB debugging on your Android device if you want to connect it to a computer and use it for development purposes. To do this, you need to enter the &quot;Developer Settings&quot; window and enable the USB debugging option. Once you have done this, you can connect your Android device to your computer using a USB cable.</p>
"
"73269786","APK crash after converting with Buildozer","<p>After I convert Python To APK using Buildozer my APK file crashes
is there something wrong in my requirements line
requirements = python3,kivy,kivymd,psutil,speedtest,pillow</p>
<pre><code>import datetime
import threading
import random
from time import sleep
import psutil
import speedtest
from kivymd.app import MDApp
from kivy.lang import Builder
from kivy.core.window import Window
from kivy.uix.screenmanager import ScreenManager, Screen
from get_size import get_size
from get_size_bits import get_size_bits
from kivymd.uix.list import OneLineListItem, TwoLineListItem, MDList
</code></pre>
","<kivy><apk><kivymd><buildozer><requirements>","2022-08-07 17:52:08","115","0","2","73270489","<p>According to buildozer documentation you can use</p>
<pre><code>buildozer android deploy run logcat
</code></pre>
<p>this command can help you directly deploy to the android device and see the logcat in order to see what is crashing. Read all details <a href=""https://buildozer.readthedocs.io/en/latest/quickstart.html#run-my-application"" rel=""nofollow noreferrer"">here</a>.</p>
<p>Additionally, buildozer is based on python for android so you can also see if any of that troubleshooting help you to identify the crash
<a href=""https://python-for-android.readthedocs.io/en/latest/troubleshooting/"" rel=""nofollow noreferrer"">https://python-for-android.readthedocs.io/en/latest/troubleshooting/</a></p>
"
"73255403","Can an animal be an actor in use case diagram?","<p>I am developing a use case diagram for dog veterinary. However, I was confused that whether I should use dog as an actor or not as it cannot communicate with the system. However, everything that system does is totally dependent on dog like, checking, giving injections e.t.c.</p>
","<uml><software-design><use-case><requirements><use-case-diagram>","2022-08-05 21:22:36","88","3","2","73255600","<p>I would suppose it to be a <em>secondary actor</em>. That means it will take part in a use case but not starting it. You can leave it simply out or if you intend to differntiate between different animals you can also use general forms (like <em>mamal</em>).</p>
<p>Indeed an actor is someone/thing that gets added value from the system under consideration. I would think that a pet feeding has also an animal as primary actor. Probably not the case here, but just think of who gets the added value: that's an (primary) actor.</p>
"
"73255403","Can an animal be an actor in use case diagram?","<p>I am developing a use case diagram for dog veterinary. However, I was confused that whether I should use dog as an actor or not as it cannot communicate with the system. However, everything that system does is totally dependent on dog like, checking, giving injections e.t.c.</p>
","<uml><software-design><use-case><requirements><use-case-diagram>","2022-08-05 21:22:36","88","3","2","73255771","<h2>What is an actor?</h2>
<p>The key is to define precisely the system under consideration (called the <em><strong>subject</strong></em> in UML-speak), since this determines what is or is not an actor:</p>
<blockquote>
<p>Each UseCase specifies some behavior that a <em><strong>subject</strong></em> can perform <em><strong>in collaboration with</strong></em> one or more <strong>Actors</strong>.<br />
(...) An <strong>Actor</strong> models a type of role played by an entity that <em><strong>interacts with the subjects</strong></em> of its associated UseCases (e.g., by exchanging signals and data). Actors may represent roles played by human users, external hardware, or other systems.</p>
</blockquote>
<p>A more general requirement analysis concept is the <em><strong>stakeholder</strong></em>.  All the actors are stakeholders, but there may be stakeholders that are not be actors, for example, if they benefit from a system indirectly.</p>
<h2>Is the dog an actor?</h2>
<p>It depends on the system under consideration.  The main cases are:</p>
<ul>
<li><p>The system is an <strong>app only used by the veterinary</strong>: the dog is <strong>not an actor</strong>.  The system supports the veterinary to achieve his/her goals.  There is no direct interaction between the dog and the system (except by accident, if he jumps on the keyboard). The dog nevertheless benefits indirectly from the system, so you may consider it as a stakeholder (should not be represented on the diagram)</p>
</li>
<li><p>The system is composed of a veterinary <strong>app and equipment that exchanges signals with the dog</strong> (e.g. microphone for AI barking analysis, camera, cardiovascular monitoring electrodes, echographic scanner...). The dog is an actor, even if the dog is passive in the interaction and does not realise that there is a computer involved. The dog is a <strong>secondary actor</strong> because the use-case supports primarily the goals of the veterinary.</p>
</li>
<li><p>The system is the <strong>veterinary clinic</strong>:  You are then making a <strong>business analysis</strong>.  The dog owner would be a primary actor, since he/she interacts with the clinic for achieving his/her goals, i.e. keeping his/her best companion in good health.  The dog would be a secondary actor since it would also interact with the clinic for the use-cases of the owner (wilfully or not). But in such an analysis, the veterinary would be part of the system under consideration and not an actor.</p>
</li>
</ul>
<p>In view of the wording of your question, you're most probably in the first case.</p>
"
"73242470","Transform conda-generated requirements.txt file to a format that works with pip","<p>My goal is to transform conda generated requirement.txt files to .txt files that can be used with pip. I know about the requirement.txt files that are conda generated but I am working on a cluster and can't use conda.</p>
<ol>
<li>Is there any procedure that can transform such files into files that are pip compatible?</li>
<li>Is there a set of rules that would allow me to decompose manually the conda generated requirement.txt files into pip compatible requirement.txt files? For example, if the following line is present in the (conda generated) requirements.txt file,</li>
</ol>
<p><em>python3-sklearn-lib=0.18-5~pn0</em></p>
<p>I know that</p>
<ol>
<li>&quot;=&quot; should become &quot;==&quot;,</li>
<li>&quot;python3-&quot; should disappear</li>
<li>&quot;sklearn&quot; should become &quot;scikit-learn&quot;</li>
</ol>
<p>But I don't know in this example what is the signification of &quot;~pn0&quot; and how I should &quot;translate&quot; that for the pip requirements.txt file.</p>
<p>I am aware of the question addressed <a href=""https://stackoverflow.com/questions/48787250/set-up-virtualenv-using-a-requirements-txt-generated-by-conda"">here</a> but my situation is different: I have the conda generated requirements.txt files and try to transform them into pip compatible files.</p>
","<pip><conda><requirements>","2022-08-04 21:41:22","94","0","1","73252349","<p><strong>No and no.</strong> The relation between a Conda package name to the PyPI package name is effectively arbitrary since there are no formal rules for mapping them. Sometimes they are equal; sometimes they involve prefixes/suffixes like <code>py</code> or <code>python</code>, with and without hyphens. Further, many Conda packages are not Python packages. A trivial example is <code>python</code> itself. Since there is nothing in the metadata of the packages to indicate the PyPI equivalent (if any), it is impossible to determine this without an actual brute force iteration over all the packages to extract this mapping. Perhaps someone might generate such a database someday, but for now I am unaware of its existence.</p>
<p>If you must have a pip requirements file, then export that from the environment, as in <a href=""https://stackoverflow.com/q/50777849/570918"">this thread</a>. If you only have the file from Conda, but no environment, then the easiest path is probably to recreate the environment using Conda, then do the <code>pip list --format=freeze</code>.</p>
<p>I'd also note that I agree with the comments: it sounds like the question is solving the wrong problem. Conda is fully operational without elevated privileges and is almost ubiquitously used on HPC servers I use. Look into installing <a href=""https://github.com/conda-forge/miniforge#miniforge"" rel=""nofollow noreferrer"">Miniforge</a>.</p>
"
"73011599","How to Insert Work Item in a LiveDoc using web-service client api in Polarion?","<p>I have a question about the Polarion SDK API. I am trying to insert WorkItems in a LiveDoc using webservices api. The webservics have apis for creating a workitem within the doc/module or move item but there is no api for just inserting the existing workItem into the Live/doc/module. Is there any work around? Again, the question is about doing this task using webService client(which every user has access to) and not using servlet side IWorkItem interface.</p>
","<api><web-services><requirements><siemens><polarion>","2022-07-17 12:03:07","278","0","1","73850908","<p>In the API you find the method:</p>
<pre><code>moveWorkItemToDocument
</code></pre>
<p>The Documentation states:</p>
<blockquote>
<p>Moves a Work Item to a specific position in a Document. If the Work
Item is not yet inside the Document it will be moved into the
Document. Modules are also supported.</p>
<p>@param <strong>workItemURI</strong> The URI of
the Work Item to be moved.</p>
<p>@param <strong>documentURI</strong> The URI of the Document.</p>
<p>@param <strong>parentWorkItemURI</strong> The URI of the parent Work Item or {@code
null} to insert it as the root.</p>
<p>@param <strong>position</strong> The desired position in the list of children or a value &lt; 0 to insert the Work Item at the end. (If the old and new parent are the same, then the moved Work Item is not counted.)</p>
<p>@param <strong>retainDocumentFlow</strong> {@code true} to retain the
position of the moved Work Item in the document flow, even if it means
changing the parent. {@code false} to keep the desired parent, even if
it means moving the Work Item to a different position.</p>
<p>@since 3.7.0</p>
</blockquote>
"
"72975638","Update my app in Google Play with significant changes","<p>Now my company wants to update app with significant changes.
In new app version will change absolutely whole design and internal logic (code).</p>
<p>Will the market allow such an application to be released? Wouldn't that be an intellectual property infringement?
I would like to see official links with information about it.</p>
","<android><google-play><requirements>","2022-07-14 05:31:41","37","0","1","72975830","<p>Updating an app and completely replacing everything about it is fine.  Sometimes you rewrite apps, that's ok.  The only requirement is that the signing key remain the same, and the version code increase.</p>
<p>As for UP infringement-  if your company owned the original app, how would that even remotely be IP infringement?  You own the rights to the IP, that includes the right to no longer offer it for download, or for you to reuse the name for a new app.</p>
"
"72897880","how can I include a python wheel file stored in Jfrog pypi repository in a requirement.txt","<p>how can I include a python wheel file stored in our private Artifactory PyPI repository in a requirement.txt? Our Artifactory is self-hosted and not cloud</p>
<p>I have a python app packaged into a wheel file and pushed to self-hosted Jfrog server PyPI Artifactory. How can I include it in the requirement.txt file so that the wheel file can be downloaded from the Artifactory and installed it and other dependencies listed in the requirement.txt?</p>
<p>We want to build a docker image of the application but need the wheel file to be included in the requirement.txt</p>
","<python-3.x><dependencies><artifactory><pypi><requirements>","2022-07-07 12:32:12","310","2","1","72898229","<p>Artifactory for python use a pypi repo so it work just like a regular pypi private server.</p>
<p>Official <a href=""https://www.jfrog.com/confluence/display/JFROG/PyPI+Repositories"" rel=""nofollow noreferrer"">Artifactory pypi guide</a></p>
<p>example from the doc:</p>
<pre><code>--index-url http://localhost:8081/artifactory/api/pypi/pypi-local/simple
PyYAML==3.11
argparse==1.2.1
frog-bar==0.2
frog-fu==0.2a
nltk==2.0.4
wsgiref==0.1.2
</code></pre>
<p>Be mindfull that for every different pypi repo you will need a new requirements file</p>
<p>The cleaner solution is to use pipenv with Pipfile and Pipfile.lock in this case, it allow you to have multiple pypi repo in the same file.</p>
"
"72771388","Versions not found when installing from requirements-file with pip in venv","<p>I want to make a 'copy' of my python virtual environment, which is a venv, in another directory (on a different machine) following <a href=""https://stackoverflow.com/questions/69113607/how-to-clone-a-venv-virtual-environment"">this post</a>. But I run into some problems for which I found no solution elsewhere and I don't know what happens:</p>
<p><strong>My steps:</strong>
I do <code>pip freeze &gt; venv_requirements.txt</code> and copy that file over to the other directory. There I make a new venv with <code>python3 -m venv ./venvLocal</code> and activate it. Next I run <code> python3 -m pip install -r venv_requirements.txt</code>.</p>
<p><strong>The problem:</strong> For multiple packages I get the error <code>Could not find a version that satisfies the requirement ... No matching distribution found for ...</code>.</p>
<p><strong>What I tried</strong>: 1. The version of pip in the original venv was older that the one in my new venv. I downgraded pip to the same version as the original, but the problem persisted, 2. I installed the packages for which the stated version could not be found by hand with <code>pip install ..</code>. The installation worked fine, but when running my code afterwards I got many error messages that modules are not found or that there are problems within the modules.</p>
<p><strong>Further:</strong> 1. <code>which pip</code> gives me (correctly) the one in my venv, 2. the original venv was created with exact the same command as the second one., 3. The original and new venv are on different (linux) machines, connected via ssh.</p>
","<python><pip><python-venv><requirements>","2022-06-27 11:32:02","77","0","1","72773418","<p>I found the reason for the problems: It was an issue with the python version: While I updated python to the same version as on the machine with the original venv, I did not change the symlink (<a href=""https://phoenixnap.com/kb/upgrade-python"" rel=""nofollow noreferrer"">like eg. described here</a>) and thus the new environment had been made with the old python version.</p>
"
"72468099","pip install from GitHub source fails to install dependencies defined in repository's requirements.txt","<p>I'm trying to fully install a <a href=""https://github.com/dpriskorn/OpenAlexAPI"" rel=""nofollow noreferrer"">Github repository</a> in my package. The item is added properly to my <code>setup.cfg</code> file:</p>
<pre><code>install_requires =
    requests&gt;=2.27.0, &lt;3.0.0
    rich&gt;=12.3.0, &lt;13.0.0
    pydantic&gt;=1.9.0, &lt;2.0.0
    openalexapi @ git+https://github.com/dpriskorn/OpenAlexAPI.git@master#egg=openalexapi
</code></pre>
<p>A <code>pip install -e .</code> installs <code>openalexapi</code> but it does not pull the list of dependencies in their requirements.txt. As such, it fails to install <code>backoff</code> and returns the following error:</p>
<pre class=""lang-py prettyprint-override""><code>Python 3.10.0 (default, Oct  7 2021, 04:19:18) [Clang 10.0.0 ]
Type 'copyright', 'credits' or 'license' for more information
IPython 8.4.0 -- An enhanced Interactive Python. Type '?' for help.

In [1]: from openalexapi import works
---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
Input In [1], in &lt;cell line: 1&gt;()
----&gt; 1 from openalexapi import works

File ~/codes/PPPL/promotion-analysis/venv/lib/python3.10/site-packages/openalexapi/__init__.py:7, in &lt;module&gt;
      4 import logging
      5 from typing import Optional, List
----&gt; 7 import backoff  # type: ignore
      8 import requests
      9 from pydantic import BaseModel, EmailStr
</code></pre>
<p>I know that one can do <code>pip install -r https://path/to/requirements.txt</code> but was wondering if there is a way to trigger pulling the dependencies automatically.</p>
","<python-3.x><pip><requirements>","2022-06-01 21:12:04","55","0","1","72468245","<p>When not explicitly (<code>pip install -r requirements.txt</code>) asked <code>pip install</code> never implicitly uses <code>requirements.txt</code>.</p>
<p>Dependencies are listed in wheels' metadata or in source distributions in <code>setup.cfg</code>/<code>setup.py</code>. And BTW said metadata is generated from <code>setup.cfg</code>/<code>setup.py</code> which must explicitly read <code>requirements.txt</code>.</p>
<p>It's not the case with <code>openalexapi</code> code so the only way to use its <code>requirements.txt</code> is to do explicitly</p>
<pre><code>pip install -r https://raw.githubusercontent.com/dpriskorn/OpenAlexAPI/master/requirements.txt
</code></pre>
"
"72462732","meta.yaml: how to require one from a list of packages","<p>Is there a way to code a requirements section in a meta.yaml file where any one package from a list of choices will satisfy the requirement? This is where different packages provide the same needed capability and there is no reason to specify a particular choice.</p>
<p>In my case the conda svn package and the conga-forge subversion package provide the same tool and either is fine, but an analogous case would be where either PIL or Pillow would be required so I want to have something like:</p>
<pre><code>requirements:
  run:
    - python&gt;=3.7
    - pil or pillow
</code></pre>
<p>Is this possible?</p>
","<python><conda><requirements><conda-build>","2022-06-01 13:31:48","74","1","1","72465317","<p>The closest thing to this is <a href=""https://docs.conda.io/projects/conda-build/en/latest/resources/variants.html"" rel=""nofollow noreferrer""><em>build variants</em></a>. This would entail issuing a separate build for each variant. Setting aside that the example here is contrived (<code>pil</code> is outdated and only available for Python 2.7 on Conda), but it'd be something</p>
<p><strong>conda_build_config.yaml</strong></p>
<pre><code>pil_variant:
  - pil
  - pillow
</code></pre>
<p><strong>meta.yaml</strong></p>
<pre class=""lang-yaml prettyprint-override""><code>requirements:
  run:
    - python&gt;=3.7
    - {{ pil_variant }}
</code></pre>
"
"72450552","How can I add python-dev package to requirements.txt?","<p>I am trying add the <code>python-dev</code> package to my requirements.txt file, but I must be using the wrong package name. I have tried:</p>
<p>python3.7-dev</p>
<p>python-dev</p>
<p>py-dev</p>
","<python><requirements>","2022-05-31 15:33:25","286","-2","2","72450658","<p>I guess there's great explanation about how to install it:</p>
<p><a href=""https://stackoverflow.com/questions/6230444/how-to-install-python-developer-package"">How to install python developer package?</a></p>
<p>For it's installing you should use your operation system package manager, such as:
yum, dnf, apt-get, brew or kinda</p>
"
"72450552","How can I add python-dev package to requirements.txt?","<p>I am trying add the <code>python-dev</code> package to my requirements.txt file, but I must be using the wrong package name. I have tried:</p>
<p>python3.7-dev</p>
<p>python-dev</p>
<p>py-dev</p>
","<python><requirements>","2022-05-31 15:33:25","286","-2","2","72450704","<p>If you want to install package at OS level you should seriously consider using a docker container to deploy/release your application.</p>
<p>Here is a snippet:</p>
<pre><code>FROM python

RUN apt-get install python-dev
RUN pip install -r requirements.txt

...
</code></pre>
"
"72440037","Could not find a version that matches protobuf?","<p>I need to check my dependencies with this command:</p>
<pre><code>pipreqs ./myPorjectFolder --savepath requirements.in --force &amp;&amp; pip-compile

</code></pre>
<p>This command used to work just fine. However, I am now received this error:</p>
<pre><code>INFO: Successfully saved requirements file in requirements.in
Could not find a version that matches protobuf&lt;4.0.0dev,==4.21.1,&gt;=3.15.0 (from -r requirements.in (line 4))
Tried: 2.0.3, 2.3.0, 2.4.1, 2.5.0, 2.6.0, 2.6.1, 3.0.0, 3.0.0, 3.1.0, 3.1.0.post1, 3.1.0.post1, 3.2.0, 3.2.0, 3.3.0, 3.4.0, 3.4.0, 3.5.0.post1, 3.5.0.post1, 3.5.1, 3.5.1, 3.5.2, 3.5.2, 3.5.2.post1, 3.5.2.post1, 3.6.0, 3.6.0, 3.6.1, 3.6.1, 3.7.0, 3.7.0, 3.7.1, 3.7.1, 3.8.0, 3.8.0, 3.9.0, 3.9.0, 3.9.1, 3.9.1, 3.9.2, 3.9.2, 3.10.0, 3.10.0, 3.11.0, 3.11.0, 3.11.1, 3.11.1, 3.11.2, 3.11.2, 3.11.3, 3.11.3, 3.12.2, 3.12.2, 3.12.4, 3.12.4, 3.13.0, 3.13.0, 3.14.0, 3.14.0, 3.15.0, 3.15.0, 3.15.1, 3.15.1, 3.15.2, 3.15.2, 3.15.3, 3.15.3, 3.15.4, 3.15.4, 3.15.5, 3.15.5, 3.15.6, 3.15.6, 3.15.7, 3.15.7, 3.15.8, 3.15.8, 3.16.0, 3.16.0, 3.17.0, 3.17.0, 3.17.1, 3.17.1, 3.17.2, 3.17.2, 3.17.3, 3.17.3, 3.17.3, 3.18.0, 3.18.0, 3.18.0, 3.18.1, 3.18.1, 3.18.1, 3.19.0, 3.19.0, 3.19.0, 3.19.1, 3.19.1, 3.19.1, 3.19.2, 3.19.2, 3.19.2, 3.19.3, 3.19.3, 3.19.3, 3.19.4, 3.19.4, 3.19.4, 3.20.0, 3.20.0, 3.20.0, 3.20.1, 3.20.1, 3.20.1, 4.21.0, 4.21.0, 4.21.0, 4.21.0, 4.21.1, 4.21.1, 4.21.1, 4.21.1
Skipped pre-versions: 2.0.0b0, 3.0.0a2, 3.0.0a3, 3.0.0b1, 3.0.0b1.post1, 3.0.0b1.post2, 3.0.0b2, 3.0.0b2, 3.0.0b2.post1, 3.0.0b2.post1, 3.0.0b2.post2, 3.0.0b2.post2, 3.0.0b3, 3.0.0b4, 3.0.0b4, 3.2.0rc1, 3.2.0rc1, 3.2.0rc1.post1, 3.2.0rc1.post1, 3.2.0rc2, 3.2.0rc2, 3.7.0rc2, 3.7.0rc2, 3.7.0rc3, 3.7.0rc3, 3.8.0rc1, 3.8.0rc1, 3.9.0rc1, 3.9.0rc1, 3.10.0rc1, 3.10.0rc1, 3.11.0rc1, 3.11.0rc1, 3.11.0rc2, 3.11.0rc2, 3.13.0rc3, 3.13.0rc3, 3.14.0rc1, 3.14.0rc1, 3.14.0rc2, 3.14.0rc2, 3.14.0rc3, 3.14.0rc3, 3.15.0rc1, 3.15.0rc1, 3.15.0rc2, 3.15.0rc2, 3.16.0rc1, 3.16.0rc1, 3.16.0rc2, 3.16.0rc2, 3.17.0rc1, 3.17.0rc1, 3.17.0rc2, 3.17.0rc2, 3.18.0rc1, 3.18.0rc1, 3.18.0rc1, 3.18.0rc2, 3.18.0rc2, 3.18.0rc2, 3.19.0rc1, 3.19.0rc1, 3.19.0rc1, 3.19.0rc2, 3.19.0rc2, 3.19.0rc2, 3.20.0rc1, 3.20.0rc1, 3.20.0rc1, 3.20.0rc2, 3.20.0rc2, 3.20.0rc2, 3.20.1rc1, 3.20.1rc1, 3.20.1rc1, 4.0.0rc1, 4.0.0rc1, 4.0.0rc2, 4.0.0rc2, 4.21.0rc1, 4.21.0rc1, 4.21.0rc1, 4.21.0rc1, 4.21.0rc2, 4.21.0rc2, 4.21.0rc2, 4.21.0rc2
There are incompatible versions in the resolved dependencies:
  protobuf==4.21.1 (from -r requirements.in (line 4))
  protobuf&lt;4.0.0dev,&gt;=3.15.0 (from google-api-core==2.8.1-&gt;google_api_python_client==2.49.0-&gt;-r requirements.in (line 2)
</code></pre>
<p>The <code>requirements.in</code> file it is referencing contains the following:</p>
<pre><code>filelock==3.7.0
google_api_python_client==2.49.0
google_auth_oauthlib==0.5.1
protobuf==4.21.1
scipy==1.8.1
sentry_sdk==1.5.12
</code></pre>
<p>I <a href=""https://pypi.org/project/protobuf/4.21.1/#description"" rel=""nofollow noreferrer"">checked pypi</a> and clearly, <code>protobuf==4.21.1</code> is there.</p>
<p>Why is this problem happening?</p>
<p>Generally, I've had problems with protobuf.</p>
<p>If I am not mistaken, isn't the problem that <code>pipreqs</code> says I need <code>4.21.1</code> but the software requires it to be between <code>4.0.0</code> and <code>3.15.0</code>? Obviously, that is an invalid condition.</p>
<p>How can I get <code>pipreqs</code> to require the correction version such as <code>3.20.1</code>?</p>
","<python><python-3.x><protocol-buffers><requirements>","2022-05-30 21:07:21","4522","1","1","72452878","<p>It appears the package version condition is not possible.</p>
<p>The conditions are:</p>
<ul>
<li>3.15.0 &lt; Version &lt; 4.0.0 (from <code>Gmail API</code>)</li>
<li>Version == 4.21.1 (from <code>pipreqs</code>?)</li>
</ul>
<p>I'm not certain why <code>pipreqs</code> is generating a <code>requirements.in</code> file that says <code>protobuf==4.21.1</code> when the <code>Gmail API</code> requires something between 3.15.0 and 4.0.0.</p>
<p>I ended up manually replacing the <code>protobuf==4.21.1</code> in the <code>requirements.in</code> file, and separated the <code>pipreqs</code> and <code>pip-compile</code> commands so that I could modify the intermediate <code>requirements.in</code> file before being passed into <code>pip-compile</code>, which is where the error was occurring.</p>
<pre><code>os.system(&quot;pipreqs ./myProject --savepath requirements.in --force&quot;)
lines = None
with open('requirements.in', 'r') as FID: 
    lines = FID.readlines()
    for index,line in enumerate(lines ): 
        if 'protobuf' in line: 
            lines[index] = 'protobuf==3.20.1\n'

with open('requirements.in', 'w') as FID: 
    FID.writelines(lines)
    
os.system(&quot;pip-compile&quot;)
</code></pre>
"
"72405577","How to generate ""global documentation"" with doxygen","<p>I have a fair understanding of both how to document code and how to write &quot;generic documentation&quot; using <code>@mainpage</code>, <code>@page</code>, <code>@subpage</code> and related tags.</p>
<p>I would need to include requirements/specification documentation for the code.</p>
<p>My problem is to keep this kind of documentation (conceptually distinct from code documentation) close to code implementing functionality (i.e.: at least in the same file, sometimes even near specific classes/functions/methods) but still be able to collect it in an orderly fashion and present it in the <code>@mainpage</code>, outside file/class hierarchy.</p>
<p>What I would ideally need is to be able to place specific <code>@page</code>, <code>@section</code>, <code>@subsection</code> etc. randomly in the various source files and then be able to <code>@include</code> them in a specific order into <code>@mainpage</code> or some other <code>@subpage</code>.</p>
<p>Even better would be to be able to include the <em>same</em> snippet in both class/function full doc (not <code>@brief</code>, of course) and in the &quot;front matter&quot; linked in <code>@mainpage</code>.</p>
<p>Global effect I need to have is to have a &quot;specification document&quot; where I detail what the various parts of the code need to implement and then the &quot;normal class/function/whatever&quot; documentation doxygen id very good at providing.</p>
<p>The catch (i.e.: what I don't know how to do) is I would like to keep &quot;specification&quot; and implementation together in the source, but separate them in documentation, i.e.:</p>
<ol>
<li>General Description: easy, this goes into <code>@mainpage</code></li>
<li>Requirements: most likely at top of source file implementing them, how do I link/include in main page?</li>
<li>Specification: either right after Requirements at top of file or somewhere near class/function implementing it; also here I don't know how to link/include in &quot;front matter&quot; AKA: <code>@mainpage</code>.</li>
<li>Normal code documentation: here only thing I don't know is how include in class/function description the same &quot;doc snippet&quot; already used for (2) and (3).</li>
</ol>
<p>Is this possible?</p>
<p>If so, what's the best practice?</p>
<p><strong>Note</strong>: I could get the effect using a separate file for each &quot;doc snippet&quot; and then <code>@include</code>ing it in the right places, but that would defeat the whole purpose that's keep Requirements/Specification/code together while separating them in different sections in the resulting documentation.</p>
<p><strong>Update</strong>: following @albert comment I tried the following:</p>
<ul>
<li>in a standard Doxygen comment I added markers:</li>
</ul>
<pre><code>/**
 * Initialization function.
 *
 * [AM_init]
 * It needs to do a long series of tests to ensure AM can actually work.
 *
 * It should also allocate all dynamic memory needed to avoid runtime failures.
 *
...
 * It will be responsibility of system-level daemon to take appropriate action.
 * [AM_init]
 *
 *
 * @param ip_addr
 * @param port
 * @return
 */
static uint32_t AM_init(const char* ip_addr, uint16_t port) {
...
</code></pre>
<ul>
<li>in the &quot;front matter&quot; definition I have (among other things):</li>
</ul>
<pre><code>/**
@page __init Initialization
@snippet{doc} CommandHandler.c AM_init
*/
</code></pre>
<ul>
<li>The function documentation is rendered correctly (i.e.: the markers are removed)</li>
<li>OTOH the initialization page is &quot;somewhat incomplete&quot;:</li>
</ul>
<pre><code>
Initialization

    It needs to do a long series of tests to ensure AM can actually work.
</code></pre>
<p>that's it.</p>
<p>Apparently the tag <em>is</em> found, but only the first line is actually included.</p>
<p><strong>Further Update</strong>: Following @albert answer (accepted) I had success, but the following caveats:</p>
<ul>
<li>Included snippet (<code>[AM_init]</code>) <em>must</em> be in a standard comment, not a doxygen one, otherwise snippet ends up included twice.</li>
<li>Included snippet <em>must not</em> have leading <code>*</code> (very common in &quot;standard comments&quot;.</li>
<li>Included comments <em>should</em> have HTML controls (e.g.: <code>&lt;br/&gt;</code> for line termination) because Markdown constructs (&quot;double newline&quot;, in the above case) are <strong>not</strong>recognized.</li>
</ul>
<p>In retrospect I think &quot;Note&quot; in Doxygen <code>\snippet['{'option'}'] &lt;file-name&gt; ( block_id )</code> documentation addresses, more or less all the above, but I find it very cryptic and I would never have understood the implications without my nose being rubbed into them.</p>
<p>The last one is very annoying because I use a lot Lists and Tables and while HTML syntax is much more powerful, it is also much more difficult to write and to read in sources.</p>
<p>Finding a way to lift this limitation would be &quot;very nice&quot;.</p>
","<doxygen><specifications><requirements>","2022-05-27 12:38:55","187","3","1","72408368","<p>With the following code and the current doxygen version (1.9.4 (5d15657a55555e6181a7830a5c723af75e7577e2)) but also with the 1.9.1 (ef9b20ac7f8a8621fcfc299f8bd0b80422390f4b) version, I get good result:</p>
<p><strong>bb.h</strong></p>
<pre><code>/// \file

/**
@page __init Initialization
@snippet{doc} CommandHandler.c AM_init
*/
</code></pre>
<p><strong>CommandHandler.c</strong></p>
<pre><code>/// \file

/**
 * Initialization function.
 */

/* [AM_init]
   It needs to do a long series of tests to ensure AM can actually work.&lt;br&gt;

   It should also allocate all dynamic memory needed to avoid runtime failures.&lt;br&gt;

   It will be responsibility of system-level daemon to take appropriate action.&lt;br&gt;
   [AM_init]
 */
/**
 * \snippet{doc} this AM_init
 *
 * @param ip_addr
 * @param port
 * @return
 */
static uint32_t AM_init(const char* ip_addr, uint16_t port){}
</code></pre>
<p><strong>Doxyfile</strong></p>
<pre><code>EXTRACT_STATIC = YES
EXAMPLE_PATH = .
QUIET = YES
</code></pre>
<p>Note: OP rightfully mentioned in <strong>further update</strong> that there are some things to take care of:</p>
<ul>
<li>Included snippet ([AM_init]) must be in a standard comment, not a doxygen one, otherwise snippet ends up included twice.</li>
<li>Included snippet must not have leading * (very common in &quot;standard comments&quot;.</li>
<li>Included comments should have HTML controls (e.g.: <br/> for line termination) because Markdown constructs (&quot;double newline&quot;, in the above case) are <strong>not</strong> recognized.</li>
</ul>
"
"72361611","Anaconda3 - cp1251.py: 'charmap' codec can't decode byte 0x98 in position 1130: character maps to <undefined>","<p>I'm trying to install packages from requirements.txt with PIP inside a PIP created environment for YOLOv5 and stumble upon this message.</p>
<pre><code>&gt; File &quot;C:\Users\username\anaconda3\lib\encodings\cp1251.py&quot;, line 23, in decode
&gt;     return codecs.charmap_decode(input,self.errors,decoding_table)[0] UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position
&gt; 1130: character maps to &lt;undefined&gt;
</code></pre>
<p>Also this message erupts when trying to update PIP.</p>
","<python><pip><anaconda><conda><requirements>","2022-05-24 10:53:27","437","1","1","72361612","<p>Desperately deleting cp1251.py file in the directory I solved the problem.</p>
<p>Can somebody clarify why this worked ?</p>
"
"72258237","Why do we differentiate between functional and non functional requirements","<p>I understand the <a href=""https://stackoverflow.com/questions/16475979/what-is-the-difference-between-functional-and-non-functional-requirements"">difference</a> between functional and non functional requirements.</p>
<ul>
<li><p>What I never understood is, why do we make this differentiation?</p>
</li>
<li><p>(Rephrased) When I design a solution, why is it useful to distinguish between these two?</p>
</li>
</ul>
","<architecture><requirements>","2022-05-16 11:08:23","128","1","1","72258825","<p>They are usually raised by different stakeholders. The quality attributes (what you called non-functionals) are mostly raised by the technology people and are somehow assumed by business owners</p>
"
"72226418","Regex to match code with fixed country code and variable wildcard usage","<p>I need to implement a regex which cover several requirements. These are the following:</p>
<ul>
<li>A length restriction to <strong>max 8 chars</strong> should be done (with or
without wildcard). In any case the code is never longer than 8 chars.</li>
<li>When wildcard is given also lower then 8 digits is allowed. Without
wildcard exactly 8 digits are needed.</li>
<li>allowed characters are: <strong>0-9A-Za-z</strong>* (all digits, all chars, asterix as wildcard)</li>
<li>pure wildcard must be possible</li>
<li>else the first two digits <strong>must contain a 2 chars</strong> country code
(alpha-numeric) and then <strong>only</strong> number or wildcards are allowed.</li>
<li>after country code wildcard can be used at any place (in the middle, at the end, mutliple asterix/wildcards after each other also allowed)</li>
</ul>
<p>I tried many things so far and thought about Lookahead/Lookbehind because of the asterix and the max. length.
My latest state which covers the most of the requirements is the following:</p>
<pre><code>^([A-Za-z]{2}[0-9*]{0,6}|\*)$
</code></pre>
<p>check the <a href=""https://regex101.com/r/L6HaDG/1"" rel=""nofollow noreferrer"">live demo with right/wrong combo</a></p>
<p>But in this example a code without asterix/wildcard is possible with less than 8 chars -&gt; that's wrong.</p>
<p>Thanks a lot for any help in advance :)</p>
","<regex><expression><wildcard><maxlength><requirements>","2022-05-13 08:15:59","85","1","1","72226960","<p>You can use</p>
<pre class=""lang-none prettyprint-override""><code>^(?!.*\*\*$)(?!.{9})(?:[A-Za-z]{2}(?:\d*(?:\*\d*)+|\d{6})|\*)$
</code></pre>
<p>See the <a href=""https://regex101.com/r/L6HaDG/2"" rel=""nofollow noreferrer"">regex demo</a>.</p>
<p><em>Details</em>:</p>
<ul>
<li><code>^</code> - start of string</li>
<li><code>(?!.*\*\*$)</code> - no two <code>**</code> at the end of string allowed</li>
<li><code>(?!.{9})</code> - the string must contain less than 9 chars other than line break chars</li>
<li><code>(?:[A-Za-z]{2}(?:\d*(?:\*\d*)+|\d{6})|\*)</code> - one of the two alternatives:
<ul>
<li><code>[A-Za-z]{2}(?:\d*(?:\*\d*)+|\d{6})</code> - two letters and then  either  six digits or zero or more digits followed with one or more sequences of an asterisk and zero or more digits</li>
<li><code>|</code>  - or</li>
<li><code>\*</code> - an asterisk</li>
</ul>
</li>
<li><code>$</code> - end of string.</li>
</ul>
"
"72218694","pip-compile error using Anaconda - File ""/opt/anaconda3/bin/pip-compile"", line 8, in <module> sys.exit(cli())","<p>My pip version is 22.0.4. I had the most recent version but had to downgrad because I noticed the same error mentioned here: <a href=""https://github.com/jazzband/pip-tools/issues/1617"" rel=""nofollow noreferrer"">https://github.com/jazzband/pip-tools/issues/1617</a>)</p>
<p>When I try to run pip-compile to update the requirements.txt file but I keep seeing the below error:</p>
<pre><code>(base) krs@me-user ds-airflow % pip-compile
WARNING:pip._internal.metadata.base:Ignoring invalid distribution -rllib3 (/opt/anaconda3/lib/python3.8/site-packages)
WARNING:pip._internal.metadata.base:Ignoring invalid distribution -otocore (/opt/anaconda3/lib/python3.8/site-packages)
WARNING:pip._internal.metadata.base:Ignoring invalid distribution -ix (/opt/anaconda3/lib/python3.8/site-packages)
WARNING:pip._internal.metadata.base:Ignoring invalid distribution - (/opt/anaconda3/lib/python3.8/site-packages)
Traceback (most recent call last):
  File &quot;/opt/anaconda3/bin/pip-compile&quot;, line 8, in &lt;module&gt;
    sys.exit(cli())
  File &quot;/opt/anaconda3/lib/python3.8/site-packages/click/core.py&quot;, line 829, in __call__
    return self.main(*args, **kwargs)
  File &quot;/opt/anaconda3/lib/python3.8/site-packages/click/core.py&quot;, line 782, in main
    rv = self.invoke(ctx)
  File &quot;/opt/anaconda3/lib/python3.8/site-packages/click/core.py&quot;, line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File &quot;/opt/anaconda3/lib/python3.8/site-packages/click/core.py&quot;, line 610, in invoke
    return callback(*args, **kwargs)
  File &quot;/opt/anaconda3/lib/python3.8/site-packages/click/decorators.py&quot;, line 21, in new_func
    return f(get_current_context(), *args, **kwargs)
  File &quot;/opt/anaconda3/lib/python3.8/site-packages/piptools/scripts/compile.py&quot;, line 313, in cli
    repository = PyPIRepository(pip_args, cache_dir=cache_dir)
  File &quot;/opt/anaconda3/lib/python3.8/site-packages/piptools/repositories/pypi.py&quot;, line 93, in __init__
    self._setup_logging()
  File &quot;/opt/anaconda3/lib/python3.8/site-packages/piptools/repositories/pypi.py&quot;, line 451, in _setup_logging
    assert isinstance(handler, logging.StreamHandler)
AssertionError
</code></pre>
<p>EDIT: I just tried running: <code>pip-compile --upgrade</code></p>
<pre><code>  File &quot;/opt/anaconda3/bin/pip-compile&quot;, line 8, in &lt;module&gt;
    sys.exit(cli())
  File &quot;/opt/anaconda3/lib/python3.8/subprocess.py&quot;, line 512, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['/opt/anaconda3/bin/python3', '/opt/anaconda3/lib/python3.8/site-packages/pep517/in_process/_in_process.py', 'get_requires_for_build_wheel', '/var/folders/2b/d94v_0s54rxfx2ylxg20xh5c0000gn/T/tmp2o517hrt']' returned non-zero exit status 1.
</code></pre>
<p>EDIT EDIT:
I've run <code>conda list '(pip|click)'</code> and see the following, but my requirements.txt file has hundreds of packages:</p>
<pre><code># packages in environment at /opt/anaconda3:
#
# Name                    Version                   Build  Channel
click                     7.1.1                    pypi_0    pypi
click-default-group       1.2.2                    pypi_0    pypi
clickclick                20.10.2                  pypi_0    pypi
pip                       20.2.4                   pypi_0    pypi
pip-tools                 6.6.0                    pypi_0    pypi
</code></pre>
","<python><pip><anaconda><conda><requirements>","2022-05-12 15:54:16","267","0","1","72232819","<p>The version combination of <code>pip=20.2.4</code> and <code>pip-tools=6.6.0</code> is <a href=""https://pypi.org/project/pip-tools/#versions-and-compatibility"" rel=""nofollow noreferrer"">not compatible</a>. Either upgrade <code>pip</code> to <code>&gt;=21.2</code>, or downgrade <code>pip-tools</code> to 5.5.</p>
"
"72117772","User story for drag and drop feature","<p>Can anyone help me create a User Story for the dragging and dropping feature, where I can drag and drop projects from &quot;New Project&quot; to &quot;In progress&quot; etc Column</p>
","<user-interface><drag-and-drop><requirements><user-stories>","2022-05-04 18:24:43","95","2","1","73005985","<p><a href=""https://en.wikipedia.org/wiki/User_story"" rel=""nofollow noreferrer"">User-stories</a> describes a feature from the user's point of view, making clear what the user wants to achieve.  We cannot invent stories for your users: normally, you should discuss this with your users.  But if you're learning and it could help, here an hypothetical example:</p>
<blockquote>
<p><strong>As a</strong> <em>project manager</em> <strong>I can</strong> <em>drag a project icon in the &quot;new project&quot; column across my kanban board and drop it on the &quot;in progress&quot; column</em>, <strong>so that</strong> <em>I can easily and intuitively communicate that a project was started and is still going on.</em></p>
</blockquote>
<p>Be aware that referring explicitly to a drag and drop seems very detailed and might not leave much room to propose better solutions. In this regard, you need to keep in mind that a story is not a detailed specification.  It's just <a href=""https://www.agilealliance.org/user-story-conversations/"" rel=""nofollow noreferrer"">a placeholder for a conversation</a>.  Personally, I'd rather go for something simpler like:</p>
<blockquote>
<p><strong>As a</strong> <em>project manager</em> <strong>I can</strong> <em>easily chose a project to launch and show that it is currently in-progress</em>, <strong>so that</strong> <em>the other users know on which project they may work.</em></p>
</blockquote>
<p>I would then discuss with the user about the details of the story.  Maybe drag and drop is the way to go. Maybe keyboard control (tab to select, space to chose target) is needed for <strong><a href=""https://www.w3.org/blog/wai-components-gallery/widget/accessible-drag-and-drop/"" rel=""nofollow noreferrer"">accessibility reasons</a></strong>.  But perhaps I'll discover that some users prefer to update the status in the project card if it's on the screen.</p>
<p>Anyhow, during this conversation <a href=""https://www.mountaingoatsoftware.com/agile/user-stories"" rel=""nofollow noreferrer"">you'd write down all the expectations, positive and negative, for the acceptance criteria</a>.  For example:</p>
<ul>
<li>Dragging from &quot;new&quot; and dropping on &quot;new&quot; cancels the drag&amp;drop operation</li>
<li>When dragging from &quot;new&quot; a visual feedback should be given to show the project moving</li>
<li>During the dragging,  the use of the escape button may cancel the operation.</li>
<li>When the project is dropped by accident,  the user may undo the operation.</li>
<li>When the project is successfully dropped on the &quot;in progress&quot; column,  any open view of the project card should be immediately opened to show the new status of the project.</li>
<li>Attempting to drag a project, of which the user is not responsible, should lead to an error message about missing authorisations, etc.. .</li>
</ul>
"
"72058400","Unable to deploy fbprophet in heroku","<p>I am unable to deploy fbprophet time series model into heroku. Locally, it works well.</p>
<p>The requirements.txt file contains as follows.</p>
<pre><code>numpy
pandas
matplotlib
pystan==2.19.1.1
streamlit
plotly
fbprophet
</code></pre>
<p>Tried:
Kept default pystan without giving the version. Did not work. Error in CLI showing &quot;Pystan loading&quot;.</p>
<p>Error:</p>
<pre><code>Failed to build pystan fbprophet
Running setup.py install for pystan: started
</code></pre>
<p>No response after this.</p>
","<heroku><deployment><time-series><requirements><facebook-prophet>","2022-04-29 13:01:25","106","0","1","72256434","<p>fbprophet is older version try using prophet, if it doesn't work you can install prophet through prebuilt wheels <a href=""https://pypi.org/project/prophet-prebuilt/1.0.2/#files"" rel=""nofollow noreferrer"">https://pypi.org/project/prophet-prebuilt/1.0.2/#files</a></p>
"
"71726676","Error comes while installation of random module of python","<pre><code>ERROR: Could not find a version that satisfies the requirement python-random (from versions: none)
ERROR: No matching distribution found for python-random
</code></pre>
","<python><pip><requirements>","2022-04-03 14:10:03","481","-3","1","71726752","<p>You don't have to install the <a href=""https://docs.python.org/3/library/random.html"" rel=""nofollow noreferrer""><code>random</code></a> module, since it's a <a href=""https://docs.python.org/3/py-modindex.html"" rel=""nofollow noreferrer""><code>built-in</code></a> module and it comes with the standard Python installation.</p>
<hr />
<p>If you want to use its functions and classes, you just have to <a href=""https://docs.python.org/3/reference/import.html"" rel=""nofollow noreferrer""><code>import</code></a> it:</p>
<pre><code># main.py
import random
print(random.randint(0, 100)) # 42
</code></pre>
"
"71724961","RegExe Reqtify : capturing multilines Requirements","<p>I'm new here and I'm also a beginner in <code>regex</code>.</p>
<p>I'm using <code>Reqtify</code> to match and capture Requirements from a PDF file.</p>
<p><strong>Here the example of the file content:</strong></p>
<pre><code>**Requirement1** 

Text of the first requirement bla bla 

Second line of the first requirement.

**Requirement2** 

Text of the second requirement, no second line

**Heading 2[Distributed]**

**Requirement3** 
Text of the third requirement

Second line of the third requirement 

Third line of the third requirement 

**Heading 1[Distributed]**

**Requirement4**
 
Text of the 4th requirement

Second line of the 4th requirement 

Third line of the 4th requirement 

**Heading3[Distributed]**
[...]
</code></pre>
<p><strong>Here what i want for the Requirement3 for example :</strong></p>
<pre><code>Text of the third requirement
Second line of the third requirement 
Third line of the third requirement 
</code></pre>
<p>As can you see the file mixes requirements and different heading (1,2,3 etc).</p>
<p>My first idea was to capture each requirement until the line which ends with *<strong>&quot;]&quot;</strong>.</p>
<p>So my regex pattern is:</p>
<pre><code>(^Requirement\d+).*$\n(\s\S]*?)^.*Distributed\]$ 
</code></pre>
<p>But it doesn't work well (see picture below).</p>
<p><a href=""https://i.stack.imgur.com/yrK0B.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yrK0B.png"" alt=""enter image description here"" /></a></p>
<p>My second idea is to have different <strong>end of the multiline</strong>, something like this:</p>
<pre><code>(^Requirement\d+).*$\n(\s\S]*?)**^.*Distributed\]$|^Heading\d+**
</code></pre>
<p>But it doesn't work at all, i know that the regex syntax isn't right.</p>
<p><strong>Can someone, please, help with the two ideas?</strong></p>
<p>Thank you for your time.</p>
<p>Also, if you have documentation about regex in Reqtify I would love to read it.</p>
<p>PS: I use regex101 to test my expression.</p>
<hr />
<p>Thank to @GreyMurav I can capture what I want. However I noticed that in the file, in each page there  are a header and a footer, so in some requirement they are captured.</p>
<p>The header its like this :</p>
<p>'#TABLE</p>
<p>'#TR|1 bla bla bla bla</p>
<p>'#TR[1...................... Distributed|5 page 5/102</p>
<p>SO you can have something like this :
Requirements 5</p>
<p>First line of the requirement</p>
<p>*#TABLE</p>
<p>#TR|1 bla bla bla bla</p>
<p>#TR[1...................... Distributed|5 page 5/102*</p>
<p>The rest of the requirement bla bla.</p>
<p>Here what I tried :</p>
<ol>
<li>add a non-capturing group '''
(?:^#TABLE\nTR.*\n#TR.<em>Distributed.</em>$)
''' I tried to place it everywhere but It doesnt work.</li>
<li>In Reqtify you can apply a sub-exopression to a group. But it doesn't work eather.</li>
</ol>
<p>How can I solve this problem?</p>
<p>Thank you for your time.</p>
","<regex><requirements>","2022-04-03 10:20:10","254","1","1","71725083","<p>You can use a pattern that captures all lines after matching Requirement stops matching until a line start with <code>Requirement</code> or contains <code>[Distributed]</code></p>
<pre><code>^Requirement\d+\s*\n((?:(?!^Requirement\d|.*?\[Distributed]).*(?:\n|$))*)
</code></pre>
<p>The pattern matches:</p>
<ul>
<li><code>^</code> Start of string</li>
<li><code>Requirement\d+\s*\n</code></li>
<li><code>(</code> Capture <strong>group 1</strong>
<ul>
<li><code>(?:</code> Non capture group
<ul>
<li><code>(?!^Requirement\d|.*?\[Distributed])</code> Assert that the string does not start with Requirement and a digit and does not contain [Distributed]</li>
<li><code>.*</code> Match the whole line</li>
<li><code>(?:\n|$)</code> Match a newline or assert the end of the string</li>
</ul>
</li>
<li><code>)*</code> Close the non capture group an optionally repeat to match all lines</li>
</ul>
</li>
<li><code>)</code> Close group 1</li>
</ul>
<p>See a <a href=""https://regex101.com/r/DK2Dgg/1"" rel=""nofollow noreferrer"">regex101 demo</a></p>
"
"71586500","Create a folder in DXL - DOORS","<p>I am trying to make a script that will copy the contents of one project to another (ie folders and modules) in DXL. To do it, I have seen that there is the create function,</p>
<pre><code>create(string name, string description)
</code></pre>
<p>which creates a folder... But from what I see, it creates it in the current directory where I run the script.</p>
<p>Is there any way that running the script in the <strong>M</strong> module, from the <strong>C</strong> folder of the <strong>P</strong> project, generates a folder with the <strong>same name C</strong> but inside the <strong>new NP project</strong>?</p>
<p>Thanks:)</p>
","<scripting><ibm-cloud><requirements><ibm-doors>","2022-03-23 11:34:09","148","0","1","71586920","<p>from the DXL manual: <code>The name argument can be an absolute or relative name, and may include the path.</code>. So, you might have a loop like</p>
<pre><code>Project P = project ('/P')
Item i
for i in P do {
   if (type i == 'Folder') {
      string nName = name i
      create (&quot;/NP/&quot; sName, &quot;&quot;)
   }
   // recursively copy the content of the folder
}
</code></pre>
<p>Also, depending on your needs, you might want to have a look at <code>clipCopy</code> and <code>clipPaste</code>, which duplicates an entire hierarchy.</p>
"
"70885058","can't install modified pafy version in heroku django","<p>I made a django app with pafy (I used the modified version, because the official one gives errors check this <a href=""https://github.com/mps-youtube/pafy/pull/305"" rel=""nofollow noreferrer"">https://github.com/mps-youtube/pafy/pull/305</a>) and when I push it to heroku I get errors
here's the requirements.txt file</p>
<pre><code># asgiref @ file:///tmp/build/80754af9/asgiref_1625643473416/work
beautifulsoup4==4.10.0
certifi==2021.10.8
dj-database-url==0.5.0
# Django @ file:///tmp/build/80754af9/django_1625585912945/work
django-bootstrap-datepicker-plus==4.0.0
django-bootstrap4==21.2
django-heroku==0.3.1
Faker==11.3.0
gunicorn==20.1.0
# psycopg2 @ file:///tmp/build/80754af9/psycopg2_1612298595717/work
python-dateutil==2.8.2
pytz==2021.3
six==1.16.0
soupsieve==2.3.1
# sqlparse @ file:///tmp/build/80754af9/sqlparse_1602184451250/work
text-unidecode==1.3
# typing-extensions @ file:///tmp/build/80754af9/typing_extensions_1631814937681/work
whitenoise==5.3.0
# pafy==0.5.5
# youtube_dl==2021.12.17
youtube-dl==2021.6.6
pafy
-e git+git://github.com/Cupcakus/pafy.git@develop#egg=pafy
</code></pre>
<p>I tried removing pafy, tried other versions but it doesn't solve it
here's the log</p>
<pre><code>-----&gt; Building on the Heroku-20 stack
-----&gt; Using buildpack: heroku/python
-----&gt; Python app detected
-----&gt; Using Python version specified in runtime.txt
-----&gt; Requirements file has been changed, clearing cached dependencies
-----&gt; Installing python-3.9.10
-----&gt; Installing pip 21.3.1, setuptools 57.5.0 and wheel 0.37.0
-----&gt; Installing SQLite3
-----&gt; Installing requirements with pip
       Obtaining pafy from git+git://github.com/Cupcakus/pafy.git@develop#egg=pafy (from -r /tmp/build_9f9c42b0/requirements.txt (line 24))
         Cloning git://github.com/Cupcakus/pafy.git (to revision develop) to /app/.heroku/src/pafy
         Running command git clone --filter=blob:none -q git://github.com/Cupcakus/pafy.git /app/.heroku/src/pafy
         Resolved git://github.com/Cupcakus/pafy.git to commit 45f0deb067bf7c420cdf83a0529fd5274c12de18
         Preparing metadata (setup.py): started
         Preparing metadata (setup.py): finished with status 'error'
         ERROR: Command errored out with exit status 1:
          command: /app/.heroku/python/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '&quot;'&quot;'/app/.heroku/src/pafy/setup.py'&quot;'&quot;'; __file__='&quot;'&quot;'/app/.heroku/src/pafy/setup.py'&quot;'&quot;';f = getattr(tokenize, '&quot;'&quot;'open'&quot;'&quot;', open)(__file__) if os.path.exists(__file__) else io.StringIO('&quot;'&quot;'from setuptools import setup; setup()'&quot;'&quot;');code = f.read().replace('&quot;'&quot;'\r\n'&quot;'&quot;', '&quot;'&quot;'\n'&quot;'&quot;');f.close();exec(compile(code, __file__, '&quot;'&quot;'exec'&quot;'&quot;'))' egg_info --egg-base /tmp/pip-pip-egg-info-eu9a5bj6
              cwd: /app/.heroku/src/pafy/
         Complete output (16 lines):
         Traceback (most recent call last):
           File &quot;/app/.heroku/src/pafy/pafy/pafy.py&quot;, line 48, in &lt;module&gt;
             import youtube_dl
         ModuleNotFoundError: No module named 'youtube_dl'
         
         During handling of the above exception, another exception occurred:
         
         Traceback (most recent call last):
           File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
           File &quot;/app/.heroku/src/pafy/setup.py&quot;, line 13, in &lt;module&gt;
             from pafy import __version__
           File &quot;/app/.heroku/src/pafy/pafy/__init__.py&quot;, line 7, in &lt;module&gt;
             from .pafy import new
           File &quot;/app/.heroku/src/pafy/pafy/pafy.py&quot;, line 51, in &lt;module&gt;
             raise ImportError(
         ImportError: pafy: youtube-dl not found; you can use the internal backend by setting the environmental variable PAFY_BACKEND to &quot;internal&quot;. It is not enabled by default because it is not as well maintained as the youtube-dl backend.
         ----------------------------------------
       WARNING: Discarding git+git://github.com/Cupcakus/pafy.git@develop#egg=pafy. Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.
       Collecting beautifulsoup4==4.10.0
         Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)
       Collecting certifi==2021.10.8
         Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)
       Collecting dj-database-url==0.5.0
         Downloading dj_database_url-0.5.0-py2.py3-none-any.whl (5.5 kB)
       Collecting django-bootstrap-datepicker-plus==4.0.0
         Downloading django_bootstrap_datepicker_plus-4.0.0-py3-none-any.whl (16 kB)
       Collecting django-bootstrap4==21.2
         Downloading django_bootstrap4-21.2-py3-none-any.whl (24 kB)
       Collecting django-heroku==0.3.1
         Downloading django_heroku-0.3.1-py2.py3-none-any.whl (6.2 kB)
       Collecting Faker==11.3.0
         Downloading Faker-11.3.0-py3-none-any.whl (1.2 MB)
       Collecting gunicorn==20.1.0
         Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)
       Collecting python-dateutil==2.8.2
         Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)
       Collecting pytz==2021.3
         Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)
       Collecting six==1.16.0
         Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)
       Collecting soupsieve==2.3.1
         Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)
       Collecting text-unidecode==1.3
         Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)
       Collecting whitenoise==5.3.0
         Downloading whitenoise-5.3.0-py2.py3-none-any.whl (19 kB)
       Collecting youtube-dl==2021.6.6
         Downloading youtube_dl-2021.6.6-py2.py3-none-any.whl (1.9 MB)
       Collecting pafy
         Downloading pafy-0.5.5-py2.py3-none-any.whl (35 kB)
       Collecting django&lt;5,&gt;=2
         Downloading Django-4.0.1-py3-none-any.whl (8.0 MB)
       Collecting psycopg2
         Downloading psycopg2-2.9.3.tar.gz (380 kB)
         Preparing metadata (setup.py): started
         Preparing metadata (setup.py): finished with status 'done'
       ERROR: Exception:
       Traceback (most recent call last):
         File &quot;/app/.heroku/python/lib/python3.9/site-packages/pip/_internal/cli/base_command.py&quot;, line 164, in exc_logging_wrapper
           status = run_func(*args)
         File &quot;/app/.heroku/python/lib/python3.9/site-packages/pip/_internal/cli/req_command.py&quot;, line 205, in wrapper
           return func(self, options, args)
         File &quot;/app/.heroku/python/lib/python3.9/site-packages/pip/_internal/commands/install.py&quot;, line 338, in run
           requirement_set = resolver.resolve(
         File &quot;/app/.heroku/python/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/resolver.py&quot;, line 92, in resolve
           result = self._result = resolver.resolve(
         File &quot;/app/.heroku/python/lib/python3.9/site-packages/pip/_vendor/resolvelib/resolvers.py&quot;, line 482, in resolve
           state = resolution.resolve(requirements, max_rounds=max_rounds)
         File &quot;/app/.heroku/python/lib/python3.9/site-packages/pip/_vendor/resolvelib/resolvers.py&quot;, line 374, in resolve
           failure_causes = self._attempt_to_pin_criterion(name)
         File &quot;/app/.heroku/python/lib/python3.9/site-packages/pip/_vendor/resolvelib/resolvers.py&quot;, line 228, in _attempt_to_pin_criterion
           raise InconsistentCandidate(candidate, criterion)
       pip._vendor.resolvelib.resolvers.InconsistentCandidate: Provided candidate LinkCandidate('https://files.pythonhosted.org/packages/74/69/829919eeadff695338f98fa12bb99e45490761a2010c8d688d88b6df194a/pafy-0.5.5-py2.py3-none-any.whl#sha256=769e35aa6988686d47fa2ab235d15c9952c7873c470f6a6b05cf6bcd93e62515 (from https://pypi.org/simple/pafy/)') does not satisfy SpecifierRequirement('pafy'), UnsatisfiableRequirement('pafy')
 !     Push rejected, failed to compile Python app.
 !     Push failed
</code></pre>
<p>EDIT: The problem was that I couldn't install youtube-dl before installing pafy (I was installing a specific version because of the bug that occured in pafy after youtube disabled the dislike count so I had to install another version) so I moved to pythonanywhere.com where I could use the terminal to install it manually and it worked fine.</p>
","<python><django><heroku><pip><requirements>","2022-01-27 20:07:23","207","0","1","70906459","<p>I moved to pythonanywhere.com and it works fine now</p>
"
"70750487","What should look like to be my requirements.txt file?","<p>I want to deploy a python script on Heroku cloud via GitHub and I am using these python libraries, Module, API</p>
<pre><code>from amazon_paapi import AmazonApi
import base64
import requests
import random
import time
</code></pre>
<p>What should look like to be my requirements.txt file?</p>
","<python-3.x><github><heroku><requirements>","2022-01-18 04:59:50","38","-2","1","70750552","<p>As base64, random and time are default libraries, your requirements.txt should look like:</p>
<pre><code>python-amazon-paapi
requests
</code></pre>
<p>You can have a requirements.txt with or without version specifiers. For example:</p>
<pre><code>[package name] == 0.6.1             # Version Matching. Must be version 0.6.1
[package name] &gt;= 4.1.1             # Minimum version 4.1.1
[package name] != 3.5               # Version Exclusion. Anything except version 3.5
[package name]                      # no specified version
[package name]                      # no specified version
</code></pre>
"
"70690092","Clients requirements on use case diagram","<p>I want to create a use case diagram based on customer requirements (pnline food ordering system), which are for example</p>
<ol>
<li>ensure on-time delivery</li>
<li>process and package orders</li>
<li>promote the pizza shop</li>
</ol>
<p>How can I put these requirements on use case diagram? Could you please explain on specific example?</p>
<p>for 1) could it be like that:
display order details &lt; inlcude &gt; display time left to prepare order</p>
","<uml><diagram><use-case><requirements><use-case-diagram>","2022-01-13 00:32:58","113","3","3","70690240","<p>Use cases describe operations, requirements are part of operations' restrictions.</p>
<p>First, model the operations or activities of the customer, then add the requirements as constraints of each use case.</p>
"
"70690092","Clients requirements on use case diagram","<p>I want to create a use case diagram based on customer requirements (pnline food ordering system), which are for example</p>
<ol>
<li>ensure on-time delivery</li>
<li>process and package orders</li>
<li>promote the pizza shop</li>
</ol>
<p>How can I put these requirements on use case diagram? Could you please explain on specific example?</p>
<p>for 1) could it be like that:
display order details &lt; inlcude &gt; display time left to prepare order</p>
","<uml><diagram><use-case><requirements><use-case-diagram>","2022-01-13 00:32:58","113","3","3","70694712","<p>There are a couple of ways how to model that. The first step is always to read and understand the requirements. So putting them in some sort of order is vital. There are dedicated tools to deal with that and they may or may not be helpful (I'm talking of DOORS and the like). A more simple way is to create a profile for requirements management in UML that contains requirements elements where you can reference the customer documents and already put them in a certain structure.</p>
<p>Now in the next step you <em>synthesize</em> these requirements to use cases. That is you pinpoint the added values and make them visible. Actors and UCs shall be clearly visible.</p>
<p>Once you have done that you relate UC and requirement elements with realize relations (or some other stereotyped dependency depending on the profile you use). This way you have a nice traceability that connects requirements and UC for the upcoming design steps.</p>
<p>A more simple approach would be to just attach constraints to an elaborated UC model containing requirement text. That could be done for simple (school) projects. Though it's unlikely you find that in the industry. Either you go to war (see above) or you have just a little chit-chat with some insults.</p>
<hr />
<p>Regarding the synthesis of UCs I recommend to read Bittner/Spence about Use Case Modeling. The best read you can find.</p>
"
"70690092","Clients requirements on use case diagram","<p>I want to create a use case diagram based on customer requirements (pnline food ordering system), which are for example</p>
<ol>
<li>ensure on-time delivery</li>
<li>process and package orders</li>
<li>promote the pizza shop</li>
</ol>
<p>How can I put these requirements on use case diagram? Could you please explain on specific example?</p>
<p>for 1) could it be like that:
display order details &lt; inlcude &gt; display time left to prepare order</p>
","<uml><diagram><use-case><requirements><use-case-diagram>","2022-01-13 00:32:58","113","3","3","70699701","<p>Your requirement examples seem to correspond to goals. This is a good start for thinking about use-cases, leaving full freedom about how to best achieve the goals:</p>
<ul>
<li>Your example: <em><strong>process and package order</strong></em> is a popular use-case for company staff to satisfy their clients. It raises however a question: will there be a use case for the customers to order?</li>
</ul>
<p>A use case represents a set of behaviors offered by a system,  with observable result, that is if value for actors or other stakeholders. You need to make sure that your chose requirements meet these criteria;  not all requirements are suitable for a use case diagram.</p>
<ul>
<li>Your example: <em><strong>promote the pizza shop</strong></em> is a popular business goal. It is however unclear if this is a side effect (or wishful thinking) or if the system actively promotes the shop, and who could be the primary actor.</li>
</ul>
<p>Last but not least, a use-case involves actors. You need to identify those. And you should consider rewording the use-case from the perspective of the primary actor.</p>
<ul>
<li>In your example, is it really the system that <em><strong>ensure a timely delivery</strong></em>? Or isnt't it more that the system helps some delivery agent to proceed with the right deliveries at the right moment? In this case, consider rewording into: <em><strong>deliver packages in time</strong></em>.</li>
</ul>
<p>The resulting use-case diagram should provide the big picture. Keep in mind that it makes no sense to graphically all the requirements: some narrative would describe each use case with more explanations about requirements, constraints and expectations.</p>
"
"70414560","How can I create a requirements.txt in Google colab?","<p>I have already tested the following:</p>
<p>!pip freeze &gt; requirements.txt --&gt; saves all packages in the environment</p>
<p>pipreqs --&gt; returns an empty file</p>
<p>I need a compilation of all <strong>imported packages</strong> with the corresponding version. How can I do this in Google Colab without getting all installed packages?</p>
","<python><package><google-colaboratory><python-import><requirements>","2021-12-19 19:13:56","4117","6","2","70414720","<p>You can get a list of all imported modules by doing:</p>
<pre><code>import sys
print(sys.modules.keys())
</code></pre>
"
"70414560","How can I create a requirements.txt in Google colab?","<p>I have already tested the following:</p>
<p>!pip freeze &gt; requirements.txt --&gt; saves all packages in the environment</p>
<p>pipreqs --&gt; returns an empty file</p>
<p>I need a compilation of all <strong>imported packages</strong> with the corresponding version. How can I do this in Google Colab without getting all installed packages?</p>
","<python><package><google-colaboratory><python-import><requirements>","2021-12-19 19:13:56","4117","6","2","75304671","<p>Yes, I had similar issue when using</p>
<pre><code>!pip freeze &gt; requirements.txt
</code></pre>
<p>you get all the packages initially installed in colab.</p>
<p>You can try to install session_info at the beginning:</p>
<pre><code>!pip install session-info
</code></pre>
<p>Then imports all you need and run this to see what was imported:</p>
<pre><code>import session_info
session_info.show()
</code></pre>
<p>Update:</p>
<p>This command might give you a glimpse but it doesn't seem very complete. I quickly went back to the old way, added the dependency in a local python project and used one of these 2:</p>
<pre><code>pip freeze &gt; requirements.txt
pip list --format=freeze &gt; requirements.txt
</code></pre>
"
"70343657","How do I depict this situation in a use-case diagram?","<p>Consider a scenario as such:<br/>
A university ABC allocates 2 lecturers to a course (a main lecturer and a substitute lecturer). The job of the substitute lecturer is to conduct lectures whenever the main lecturer cannot attend. Thus, both lecturers need not be present at the same time to conduct a lecture.
<br/>
<br/>
How do I show that either the main lecturer or the substitute lecturer offers lectures at a time?
<br/><br/>
What I drew :
<br/><a href=""https://i.stack.imgur.com/R5gea.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/R5gea.png"" alt=""Image"" /></a>
<br/><br/>
However, the idea depicted in the scenario isn't consistent here because, at the same time it is possible for both lecturers to offer the lecture.
<br/>
How do I correct this?</p>
","<uml><use-case><requirements><scenarios><use-case-diagram>","2021-12-14 04:04:30","86","1","2","70345542","<p>Whether you associate two distinct lecturers to the use-case or one lecturer with a multiplicity of 2 does not make a difference here.  The UML specifications let the case with multiple actors completely unspecified:</p>
<blockquote>
<p><em><strong>UML 2.5.1, page 640</strong></em> (highlighting is mine): <br><br>When a UseCase has an association to an Actor with a multiplicity that is greater than one at the Actor end, it means that more than one Actor instance is involved in the UseCase. <strong>The manner in which multiple Actors participate in the UseCase depends on the specific situation on hand and is not defined in this specification</strong>. For instance, a particular UseCase might require simultaneous (concurrent) action by two separate Actors (e.g., in launching a nuclear missile) or it might require complementary and successive actions by the Actors (e.g., one Actor starting something and the other one stopping it).</p>
</blockquote>
<p>Here some possible solutions to refine your model:</p>
<ul>
<li>Show an <code>{xor}</code> constraint between the two lecturer associations.</li>
<li>Add a comment box anchored to the use case in which you explain it in plain-text.</li>
<li>Laeve the diagram as is and describe the requirement in the textual use-case description.</li>
</ul>
<p>Additional comments, not related to your issue:</p>
<ul>
<li>If the number of students has no upper bound, use <code>*</code> instead of <code>M</code>.  Use a number if its specified in the text.</li>
<li>Main lecturers and substitute lecturers are both full lecturers, and the choice only depends on the availability, isn't it?</li>
</ul>
"
"70343657","How do I depict this situation in a use-case diagram?","<p>Consider a scenario as such:<br/>
A university ABC allocates 2 lecturers to a course (a main lecturer and a substitute lecturer). The job of the substitute lecturer is to conduct lectures whenever the main lecturer cannot attend. Thus, both lecturers need not be present at the same time to conduct a lecture.
<br/>
<br/>
How do I show that either the main lecturer or the substitute lecturer offers lectures at a time?
<br/><br/>
What I drew :
<br/><a href=""https://i.stack.imgur.com/R5gea.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/R5gea.png"" alt=""Image"" /></a>
<br/><br/>
However, the idea depicted in the scenario isn't consistent here because, at the same time it is possible for both lecturers to offer the lecture.
<br/>
How do I correct this?</p>
","<uml><use-case><requirements><scenarios><use-case-diagram>","2021-12-14 04:04:30","86","1","2","70346637","<p>As commented I would always go down to the actual role. I don't have a good name at hand, but in your case it would be <code>Lecture offerer</code>. That's the one which is linked to the <code>Offer lecture</code> use case.</p>
<p>Now the other 3 actors you showed can simply inherit from that actor above via a generalization.</p>
<p>Any constraints about concurrent access are best kept in requirements, constraints and finally in the flow of events describing the many scenarios that come up. Requirements and constraints should not clutter the simple UC diagram. Instead you create different diagrams that take care of them. The main focus of UC diagrams is to show the added value.</p>
<p>And as always I recommend to read Bittner/Spence about Use Case Modeling.</p>
"
"70334510","Creating requirements.txt in GitLab","<p>Probably a silly question, but I am trying to set up a project in GitLab that is going to be used for deployment of an ML model, for which I will use FastAPI. I'm very new to this and will try to provide as much info as possible.</p>
<p>I created the project in GitLab, which right now only contains a README.md file. The actual Python code is stored in a folder on my computer (&quot;MyProject&quot;), which contains two folders, each of which containing some data, .py scripts and a notebook.</p>
<p>To set up <code>requirements.txt</code>, I tried to create a virtual environment in Windows. Now, when I open the &quot;MyProject&quot; folder, it contains those two folders with code and the virtual enviroment, which also contains <code>Lib, Scripts, pyvenv.cfg</code>. The latter contains:</p>
<pre><code>home = c:\users\me\anaconda3
implementation = CPython
version_info = 3.8.5.final.0
virtualenv = 20.10.0
include-system-site-packages = false
base-prefix = c:\users\me\anaconda3
base-exec-prefix = c:\users\me\anaconda3
base-executable = c:\users\me\anaconda3\python.exe
</code></pre>
<p>I also cloned the GitLab repo, but on my computer it is saved somewhere else (in <code>c:\users\me</code>). I know that I need to do:</p>
<pre><code>pip install -r
requirements.txt
</code></pre>
<p>But I don't understand how to actually add this requirements file. All of the packages and libraries that I needed for my ML model were installed a long time ago with anaconda, before I created this virtual environment. Have I done anything wrong?</p>
","<python><git><gitlab><virtualenv><requirements>","2021-12-13 12:14:39","2032","1","4","70334618","<p>You can create <code>requirements.txt</code> using <code>pip freeze &gt; requirements.txt</code> and add it to your repo. This will generate list of your installed packages and exact versions you have.</p>
<p><a href=""https://pip.pypa.io/en/stable/cli/pip_freeze/"" rel=""nofollow noreferrer"">https://pip.pypa.io/en/stable/cli/pip_freeze/</a></p>
"
"70334510","Creating requirements.txt in GitLab","<p>Probably a silly question, but I am trying to set up a project in GitLab that is going to be used for deployment of an ML model, for which I will use FastAPI. I'm very new to this and will try to provide as much info as possible.</p>
<p>I created the project in GitLab, which right now only contains a README.md file. The actual Python code is stored in a folder on my computer (&quot;MyProject&quot;), which contains two folders, each of which containing some data, .py scripts and a notebook.</p>
<p>To set up <code>requirements.txt</code>, I tried to create a virtual environment in Windows. Now, when I open the &quot;MyProject&quot; folder, it contains those two folders with code and the virtual enviroment, which also contains <code>Lib, Scripts, pyvenv.cfg</code>. The latter contains:</p>
<pre><code>home = c:\users\me\anaconda3
implementation = CPython
version_info = 3.8.5.final.0
virtualenv = 20.10.0
include-system-site-packages = false
base-prefix = c:\users\me\anaconda3
base-exec-prefix = c:\users\me\anaconda3
base-executable = c:\users\me\anaconda3\python.exe
</code></pre>
<p>I also cloned the GitLab repo, but on my computer it is saved somewhere else (in <code>c:\users\me</code>). I know that I need to do:</p>
<pre><code>pip install -r
requirements.txt
</code></pre>
<p>But I don't understand how to actually add this requirements file. All of the packages and libraries that I needed for my ML model were installed a long time ago with anaconda, before I created this virtual environment. Have I done anything wrong?</p>
","<python><git><gitlab><virtualenv><requirements>","2021-12-13 12:14:39","2032","1","4","70334663","<p>Simple solution would be <code>pip freeze &gt; requirements.txt</code> but this command will add all the packages present in your enviroment which may not be used in your project. In my daily job, I use this <a href=""https://pypi.org/project/pipreqs/"" rel=""nofollow noreferrer"">https://pypi.org/project/pipreqs/</a>. you can install it and run <code>pipreqs --force</code> in your project folder. This will add packages to requirements.txt which are used in your project.</p>
"
"70334510","Creating requirements.txt in GitLab","<p>Probably a silly question, but I am trying to set up a project in GitLab that is going to be used for deployment of an ML model, for which I will use FastAPI. I'm very new to this and will try to provide as much info as possible.</p>
<p>I created the project in GitLab, which right now only contains a README.md file. The actual Python code is stored in a folder on my computer (&quot;MyProject&quot;), which contains two folders, each of which containing some data, .py scripts and a notebook.</p>
<p>To set up <code>requirements.txt</code>, I tried to create a virtual environment in Windows. Now, when I open the &quot;MyProject&quot; folder, it contains those two folders with code and the virtual enviroment, which also contains <code>Lib, Scripts, pyvenv.cfg</code>. The latter contains:</p>
<pre><code>home = c:\users\me\anaconda3
implementation = CPython
version_info = 3.8.5.final.0
virtualenv = 20.10.0
include-system-site-packages = false
base-prefix = c:\users\me\anaconda3
base-exec-prefix = c:\users\me\anaconda3
base-executable = c:\users\me\anaconda3\python.exe
</code></pre>
<p>I also cloned the GitLab repo, but on my computer it is saved somewhere else (in <code>c:\users\me</code>). I know that I need to do:</p>
<pre><code>pip install -r
requirements.txt
</code></pre>
<p>But I don't understand how to actually add this requirements file. All of the packages and libraries that I needed for my ML model were installed a long time ago with anaconda, before I created this virtual environment. Have I done anything wrong?</p>
","<python><git><gitlab><virtualenv><requirements>","2021-12-13 12:14:39","2032","1","4","70335088","<blockquote>
<p>how to actually add this requirements file</p>
</blockquote>
<p>You create the file yourself. For every library that you use, add a line in <code>requirements.txt</code> with the name of the library.  Also see documentation <a href=""https://pip.pypa.io/en/stable/reference/requirements-file-format/"" rel=""nofollow noreferrer"">https://pip.pypa.io/en/stable/reference/requirements-file-format/</a></p>
<p>After creating the file, <code>commit</code> and <code>push</code> it to the git repository.</p>
<blockquote>
<p>All of the packages and libraries that I needed for my ML model were installed a long time ago with anaconda</p>
</blockquote>
<p>Gitlab-CI with docker executor starts with a fresh environment. You have to repeat <em>all</em> installation steps that you did on your workstation <em>inside</em> the docker environment. You can run docker instance of the container locally for testing. Consult gitalb-ci and docker documentations.</p>
"
"70334510","Creating requirements.txt in GitLab","<p>Probably a silly question, but I am trying to set up a project in GitLab that is going to be used for deployment of an ML model, for which I will use FastAPI. I'm very new to this and will try to provide as much info as possible.</p>
<p>I created the project in GitLab, which right now only contains a README.md file. The actual Python code is stored in a folder on my computer (&quot;MyProject&quot;), which contains two folders, each of which containing some data, .py scripts and a notebook.</p>
<p>To set up <code>requirements.txt</code>, I tried to create a virtual environment in Windows. Now, when I open the &quot;MyProject&quot; folder, it contains those two folders with code and the virtual enviroment, which also contains <code>Lib, Scripts, pyvenv.cfg</code>. The latter contains:</p>
<pre><code>home = c:\users\me\anaconda3
implementation = CPython
version_info = 3.8.5.final.0
virtualenv = 20.10.0
include-system-site-packages = false
base-prefix = c:\users\me\anaconda3
base-exec-prefix = c:\users\me\anaconda3
base-executable = c:\users\me\anaconda3\python.exe
</code></pre>
<p>I also cloned the GitLab repo, but on my computer it is saved somewhere else (in <code>c:\users\me</code>). I know that I need to do:</p>
<pre><code>pip install -r
requirements.txt
</code></pre>
<p>But I don't understand how to actually add this requirements file. All of the packages and libraries that I needed for my ML model were installed a long time ago with anaconda, before I created this virtual environment. Have I done anything wrong?</p>
","<python><git><gitlab><virtualenv><requirements>","2021-12-13 12:14:39","2032","1","4","70335164","<p>I think you mixed up some things. GitLab uses Git for version control of your files (your code). Therefore your repository should contain the files with your code. You can just put the files of your folder &quot;MyProject&quot; into the folder, where you cloned the repository to. Also add the requirements.txt the readme-file and so on.</p>
<p>The virtual environment is used to keep your system installation of Python clean and only have the necessary packages installed for each project. Among other things to avoid package requirement conflicts. The usage of an requirements.txt file is independet of the virtual environment, even if it is a sensible combination.</p>
<p>In general this means, your requirements.txt is always shared together with your code, because it lays within the same repository. When someone clones the repository, he can use the requirements.txt to install all the dependencies to his venv (or somewherer else) and then run your code without the nedd to install further python packages.</p>
<p>Your requirements.txt file has to contain columns, which look like this: <code>numpy==1.21.4</code>. Then you have to activate the environment with <code>&lt;your path to the venv folder&gt;\venv\Scripts\activate</code> and use <code>python -m pip install -r requirements.txt</code> to install the packages listed in your requirements.txt.</p>
"
"70084248","Exporting C# Applications to clients - Confusion about imports","<p>I never really understood the technical requirements for C# applications.
I know Windows 10 has some .NET-versions installed by default. But whenever i write a console-application in c# and copy the compiled .exe-file to another computer, the .exe-file never runs (doesnt matter if compiled with net-core or net-framework). It is always missing a lot of dependencies. So I always either have to copy a huge amount of dll-files into the same folder as the .exe-file or publish it as a standalone-application, which is ridicilous huge (130 MB .exe-file for 100-line application which does nothing special at all).</p>
<p>On the other hand i can create a windows-service, compile it and use it. The compiled service-exe is very small (around 30 kb) and can be installed via cmd.exe (&quot;sc create  [...]&quot;). I tested this on a windows 10 VM. It runs without problems.</p>
<p>Am I getting everything right? Why can windows-services run without the .dll-files, but console-applications can not? Since Windows 10 has a lot of .net-applications installed, i would assume every c# application should run on windows 10 without having to add the .dll-files.</p>
","<c#><.net><requirements>","2021-11-23 16:16:26","75","-1","1","70084434","<p>If the target computer doesn't have the .Net runtime you are targeting installed, you have two options:</p>
<ol>
<li>Install the runtime, then run the app.</li>
<li>Bundle the runtime with the app, either as separate files or all within the same exe.</li>
</ol>
<p>Option 2 is only available for .Net Core and .Net 5 and higher. For .Net Framework (4 and lower) you must choose option 1.</p>
<p>You can detect what versions of Framework are installed by looking at some registry values: <a href=""https://learn.microsoft.com/en-us/dotnet/framework/migration-guide/how-to-determine-which-versions-are-installed"" rel=""nofollow noreferrer"">https://learn.microsoft.com/en-us/dotnet/framework/migration-guide/how-to-determine-which-versions-are-installed</a></p>
<p>.Net Framework 4.6.1 is included in Windows 10 (I think base but also version 1511). <a href=""https://learn.microsoft.com/en-us/dotnet/framework/migration-guide/versions-and-dependencies#net-framework-461"" rel=""nofollow noreferrer"">Source</a>. This is why your Windows Service ran just fine without you needing to do anything.</p>
<p>You can install the .Net Core/5+ runtime from <a href=""https://dotnet.microsoft.com/"" rel=""nofollow noreferrer"">https://dotnet.microsoft.com/</a> so that you don't need to include the runtime with the binaries, if you wish.</p>
"
"69953033","ERROR: Could not install packages due to an OSError?","<p>I am getting errors please tell me what is wrong with this, I am not able to find a solution anywhere!</p>
<p>I am working on one project but when other members try with install -r rquirements.txt they get this error! please tell what should be the action to handle or remove this error?</p>
<pre><code>ERROR: Could not install packages due to an OSError: [Errno 2] 
No such file or directory: 'c:\\users\\ketan\\anaconda3\\lib\\site-packages\\numpy-1.21.2.dist-info\\ME
TADATA'
</code></pre>
<p>Output :</p>
<pre><code>Collecting Werkzeug==2.0.2
Using cached Werkzeug-2.0.2-py3-none-any.whl (288 kB)
Requirement already satisfied: wheel==0.37.0 in c:\users\ketan\anaconda3\lib\site-packages (from -r requirements.txt (line 93)) (0.37.0)
Collecting win32-setctime==1.0.3
  Using cached win32_setctime-1.0.3-py3-none-any.whl (3.5 kB)
Requirement already satisfied: wincertstore==0.2 in c:\users\ketan\anaconda3\lib\site-packages (from -r requirements.txt (line 95)) (0.2)
ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'c:\\users\\ketan\\anaconda3\\lib\\site-packages\\numpy-1.21.2.dist-info\\ME
TADATA'
</code></pre>
<p>pip install -r requirements.txt --ignore-installed</p>
<p>Output2 :</p>
<pre><code>Collecting tbb==2021.*
  Using cached tbb-2021.4.0-py3-none-win_amd64.whl (268 kB)
Building wheels for collected packages: bottleneck
  Building wheel for bottleneck (PEP 517) ... error
  ERROR: Command errored out with exit status 1:
   command: 'C:\Users\ketan\anaconda3\python.exe' 'C:\Users\ketan\anaconda3\lib\site-packages\pip\_vendor\pep517\in_process\_in_process.py' build_wheel 'C:\Users\keta
n\AppData\Local\Temp\tmp4t2qkb8i'
       cwd: C:\Users\ketan\AppData\Local\Temp\pip-install-sqrcce6s\bottleneck_b15ec4cdd7084e748dc7a963008d04b3
  Complete output (51 lines):
  running bdist_wheel
  running build
  running build_py
  creating build
  creating build\lib.win-amd64-3.8
  creating build\lib.win-amd64-3.8\bottleneck
  copying bottleneck\_pytesttester.py -&gt; build\lib.win-amd64-3.8\bottleneck
  copying bottleneck\_version.py -&gt; build\lib.win-amd64-3.8\bottleneck
  copying bottleneck\__init__.py -&gt; build\lib.win-amd64-3.8\bottleneck
  creating build\lib.win-amd64-3.8\bottleneck\benchmark
  copying bottleneck\benchmark\autotimeit.py -&gt; build\lib.win-amd64-3.8\bottleneck\benchmark
  copying bottleneck\benchmark\bench.py -&gt; build\lib.win-amd64-3.8\bottleneck\benchmark
  copying bottleneck\benchmark\bench_detailed.py -&gt; build\lib.win-amd64-3.8\bottleneck\benchmark
  copying bottleneck\benchmark\__init__.py -&gt; build\lib.win-amd64-3.8\bottleneck\benchmark
  creating build\lib.win-amd64-3.8\bottleneck\slow
  copying bottleneck\slow\move.py -&gt; build\lib.win-amd64-3.8\bottleneck\slow
  copying bottleneck\slow\nonreduce.py -&gt; build\lib.win-amd64-3.8\bottleneck\slow
  copying bottleneck\slow\nonreduce_axis.py -&gt; build\lib.win-amd64-3.8\bottleneck\slow
  copying bottleneck\slow\reduce.py -&gt; build\lib.win-amd64-3.8\bottleneck\slow
  copying bottleneck\slow\__init__.py -&gt; build\lib.win-amd64-3.8\bottleneck\slow
  creating build\lib.win-amd64-3.8\bottleneck\src
  copying bottleneck\src\bn_config.py -&gt; build\lib.win-amd64-3.8\bottleneck\src
  copying bottleneck\src\bn_template.py -&gt; build\lib.win-amd64-3.8\bottleneck\src
  copying bottleneck\src\__init__.py -&gt; build\lib.win-amd64-3.8\bottleneck\src
  creating build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\input_modification_test.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\list_input_test.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\memory_test.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\move_test.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\nonreduce_axis_test.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\nonreduce_test.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\reduce_test.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\scalar_input_test.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\util.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\__init__.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  UPDATING build\lib.win-amd64-3.8\bottleneck/_version.py
  set build\lib.win-amd64-3.8\bottleneck/_version.py to '1.3.2'
  running build_ext
  running config
  compiling '_configtest.c':
  
  
  
  int __attribute__((optimize(&quot;O3&quot;))) have_attribute_optimize_opt_3(void*);
  
  int main(void)
  {
      return 0;
  }
  
  error: Microsoft Visual C++ 14.0 or greater is required. Get it with &quot;Microsoft C++ Build Tools&quot;: https://visualstudio.microsoft.com/visual-cpp-build-tools/
  ----------------------------------------
  ERROR: Failed building wheel for bottleneck
Failed to build bottleneck
ERROR: Could not build wheels for bottleneck which use PEP 517 and cannot be installed directly
</code></pre>
<p>pip install numpy==1.19.3
Output3:</p>
<pre><code>$ pip install numpy==1.19.3
Collecting numpy==1.19.3
  Using cached numpy-1.19.3-cp38-cp38-win_amd64.whl (13.3 MB)
WARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: 'c:\\users\\ketan\\anaconda3\\lib\\site-packages\\numpy-1.21.2.dist-info\\METADATA
'
Installing collected packages: numpy
  Attempting uninstall: numpy
    Found existing installation: numpy 1.21.2
ERROR: Cannot uninstall numpy 1.21.2, RECORD file not found. You might be able to recover from this via: 'pip install --force-reinstall --no-deps numpy==1.21.2'.
</code></pre>
","<python><python-3.x><requirements>","2021-11-13 09:30:01","6573","2","2","69953141","<p>Try using an older version of NumPy, it should work.</p>
<pre><code>pip uninstall numpy

pip install numpy==1.19.3
</code></pre>
"
"69953033","ERROR: Could not install packages due to an OSError?","<p>I am getting errors please tell me what is wrong with this, I am not able to find a solution anywhere!</p>
<p>I am working on one project but when other members try with install -r rquirements.txt they get this error! please tell what should be the action to handle or remove this error?</p>
<pre><code>ERROR: Could not install packages due to an OSError: [Errno 2] 
No such file or directory: 'c:\\users\\ketan\\anaconda3\\lib\\site-packages\\numpy-1.21.2.dist-info\\ME
TADATA'
</code></pre>
<p>Output :</p>
<pre><code>Collecting Werkzeug==2.0.2
Using cached Werkzeug-2.0.2-py3-none-any.whl (288 kB)
Requirement already satisfied: wheel==0.37.0 in c:\users\ketan\anaconda3\lib\site-packages (from -r requirements.txt (line 93)) (0.37.0)
Collecting win32-setctime==1.0.3
  Using cached win32_setctime-1.0.3-py3-none-any.whl (3.5 kB)
Requirement already satisfied: wincertstore==0.2 in c:\users\ketan\anaconda3\lib\site-packages (from -r requirements.txt (line 95)) (0.2)
ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'c:\\users\\ketan\\anaconda3\\lib\\site-packages\\numpy-1.21.2.dist-info\\ME
TADATA'
</code></pre>
<p>pip install -r requirements.txt --ignore-installed</p>
<p>Output2 :</p>
<pre><code>Collecting tbb==2021.*
  Using cached tbb-2021.4.0-py3-none-win_amd64.whl (268 kB)
Building wheels for collected packages: bottleneck
  Building wheel for bottleneck (PEP 517) ... error
  ERROR: Command errored out with exit status 1:
   command: 'C:\Users\ketan\anaconda3\python.exe' 'C:\Users\ketan\anaconda3\lib\site-packages\pip\_vendor\pep517\in_process\_in_process.py' build_wheel 'C:\Users\keta
n\AppData\Local\Temp\tmp4t2qkb8i'
       cwd: C:\Users\ketan\AppData\Local\Temp\pip-install-sqrcce6s\bottleneck_b15ec4cdd7084e748dc7a963008d04b3
  Complete output (51 lines):
  running bdist_wheel
  running build
  running build_py
  creating build
  creating build\lib.win-amd64-3.8
  creating build\lib.win-amd64-3.8\bottleneck
  copying bottleneck\_pytesttester.py -&gt; build\lib.win-amd64-3.8\bottleneck
  copying bottleneck\_version.py -&gt; build\lib.win-amd64-3.8\bottleneck
  copying bottleneck\__init__.py -&gt; build\lib.win-amd64-3.8\bottleneck
  creating build\lib.win-amd64-3.8\bottleneck\benchmark
  copying bottleneck\benchmark\autotimeit.py -&gt; build\lib.win-amd64-3.8\bottleneck\benchmark
  copying bottleneck\benchmark\bench.py -&gt; build\lib.win-amd64-3.8\bottleneck\benchmark
  copying bottleneck\benchmark\bench_detailed.py -&gt; build\lib.win-amd64-3.8\bottleneck\benchmark
  copying bottleneck\benchmark\__init__.py -&gt; build\lib.win-amd64-3.8\bottleneck\benchmark
  creating build\lib.win-amd64-3.8\bottleneck\slow
  copying bottleneck\slow\move.py -&gt; build\lib.win-amd64-3.8\bottleneck\slow
  copying bottleneck\slow\nonreduce.py -&gt; build\lib.win-amd64-3.8\bottleneck\slow
  copying bottleneck\slow\nonreduce_axis.py -&gt; build\lib.win-amd64-3.8\bottleneck\slow
  copying bottleneck\slow\reduce.py -&gt; build\lib.win-amd64-3.8\bottleneck\slow
  copying bottleneck\slow\__init__.py -&gt; build\lib.win-amd64-3.8\bottleneck\slow
  creating build\lib.win-amd64-3.8\bottleneck\src
  copying bottleneck\src\bn_config.py -&gt; build\lib.win-amd64-3.8\bottleneck\src
  copying bottleneck\src\bn_template.py -&gt; build\lib.win-amd64-3.8\bottleneck\src
  copying bottleneck\src\__init__.py -&gt; build\lib.win-amd64-3.8\bottleneck\src
  creating build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\input_modification_test.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\list_input_test.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\memory_test.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\move_test.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\nonreduce_axis_test.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\nonreduce_test.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\reduce_test.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\scalar_input_test.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\util.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  copying bottleneck\tests\__init__.py -&gt; build\lib.win-amd64-3.8\bottleneck\tests
  UPDATING build\lib.win-amd64-3.8\bottleneck/_version.py
  set build\lib.win-amd64-3.8\bottleneck/_version.py to '1.3.2'
  running build_ext
  running config
  compiling '_configtest.c':
  
  
  
  int __attribute__((optimize(&quot;O3&quot;))) have_attribute_optimize_opt_3(void*);
  
  int main(void)
  {
      return 0;
  }
  
  error: Microsoft Visual C++ 14.0 or greater is required. Get it with &quot;Microsoft C++ Build Tools&quot;: https://visualstudio.microsoft.com/visual-cpp-build-tools/
  ----------------------------------------
  ERROR: Failed building wheel for bottleneck
Failed to build bottleneck
ERROR: Could not build wheels for bottleneck which use PEP 517 and cannot be installed directly
</code></pre>
<p>pip install numpy==1.19.3
Output3:</p>
<pre><code>$ pip install numpy==1.19.3
Collecting numpy==1.19.3
  Using cached numpy-1.19.3-cp38-cp38-win_amd64.whl (13.3 MB)
WARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: 'c:\\users\\ketan\\anaconda3\\lib\\site-packages\\numpy-1.21.2.dist-info\\METADATA
'
Installing collected packages: numpy
  Attempting uninstall: numpy
    Found existing installation: numpy 1.21.2
ERROR: Cannot uninstall numpy 1.21.2, RECORD file not found. You might be able to recover from this via: 'pip install --force-reinstall --no-deps numpy==1.21.2'.
</code></pre>
","<python><python-3.x><requirements>","2021-11-13 09:30:01","6573","2","2","69953223","<p>When using Windows OS with python, many python packages and libraries required Microsoft Build Tools for compiling and installing the package. You have to download <a href=""https://visualstudio.microsoft.com/"" rel=""nofollow noreferrer"">Visual Studio</a> for installing Microsoft Build Tools. In addition also install C++ dependencies in Visual Studio.</p>
"
"69889964","Symfony 4 Conditional Routing","<p>im building a website using symfony 4. The website's pages are dynamically created in an admin section.</p>
<p>How can i create an exception or requirements that the rout rendering the custom pages should only be used for custom page and will not affect routs for login and register? here is my rout</p>
<pre><code> /**
 * @Route(&quot;/{page}&quot;, name=&quot;subpages&quot;, requirements={&quot;page&quot;=&quot;\d+&quot;})
 */
public function subpages(Request $request): Response
{

    $page = $request-&gt;get('page');

    $content = $this-&gt;getDoctrine()-&gt;getRepository(Pages::class)-&gt;find($page);
    
    return $this-&gt;render('public_pages/subpage.html.twig', [
        'controller_name' =&gt; 'home',
        'content' =&gt; $content
    ]);
}
</code></pre>
<p>this case, i want to only use that rout if the {page} is not /login or /register</p>
<p>Thank you in advance</p>
","<php><routes><conditional-statements><symfony4><requirements>","2021-11-08 21:08:50","238","0","1","69890600","<p>The order of your controller functions matter, you should put <code>/login</code> and <code>/register</code> before your <code>subpage</code> function.</p>
<p>However, sometimes it might not be possible due to other functions being in different controllers files with different names etc making ordering difficult..</p>
<p>You can use <a href=""https://regex101.com/r/ePR75X/1"" rel=""nofollow noreferrer""><em>Regex</em></a> in the requirements. So in your case you could do this:</p>
<pre><code>@Route(&quot;/{page}&quot;, name=&quot;subpages&quot;, requirements={&quot;page&quot;=&quot;^(?!\blogin\b|\bregister\b).+&quot;})
</code></pre>
<p>This will match any route except <code>login</code> or <code>register</code>. You can add more into the regex with a word boundary, eg <code>\bcontact\b</code>.</p>
<p>This might not be the best approach if you have lots of routes however as it can be hard to keep track. Instead you could also consider having the route like <code>&quot;/pages/{page}&quot;</code></p>
<p><strong>Symfony 5.1</strong> supports <a href=""https://symfony.com/blog/new-in-symfony-5-1-route-annotations-priority"" rel=""nofollow noreferrer"">priority</a> which makes this situation easier to deal with using the <code>priority</code> parameter in the annotation.</p>
"
"69871330","Should functions that depend upon specific values be made unsafe?","<p>I have a function that takes a <code>usize</code> equivalent to a pointer, and aligns it up to the next alignment point.</p>
<p>It doesn't require any unsafe as it's side effect free, but the alignment must be a power of two with this implementation. This means that if you use the function with bad parameters, you might get undefined behaviour later down the line. I can't check for this inside the function itself with <code>assert!</code> as it's supposed to be very fast.</p>
<pre class=""lang-rust prettyprint-override""><code>/// Align the given address `addr` upwards to alignment `align`.
///
/// Unsafe as `align` must be a power of two.
unsafe fn align_next_unsafe(addr: usize, align: usize) -&gt; usize {
    (addr + align - 1) &amp; !(align - 1)
}
</code></pre>
<p>Currently, I've made this unsafe for the above reasons, but I'm not sure if that's best practice. Should I only define a function as unsafe if it has side effects? Or is this a valid time to require an unsafe block?</p>
","<rust><parameters><unsafe><requirements>","2021-11-07 09:47:36","76","1","1","69873276","<p>I'll preface this by saying this is a fairly opinion-heavy answer, and represents a point of view, rather than &quot;the truth&quot;.</p>
<p>Consider this code taken from the <code>Vec</code> docs:</p>
<pre class=""lang-rust prettyprint-override""><code>let x = vec![1, 2, 4];
let x_ptr = x.as_ptr();

unsafe {
    for i in 0..x.len() {
        assert_eq!(*x_ptr.add(i), 1 &lt;&lt; i);
    }
}
</code></pre>
<p>The function you're describing seems to have a similar safety profile to <code>Vec::as_ptr</code>. <code>Vec::as_ptr</code> is not <code>unsafe</code>, and does nothing particularly bad on its own; having an invalid <code>*const T</code> isn't bad until you dereference it. That's why dereferencing the raw pointer requires <code>unsafe</code>.</p>
<p>Similarly, I'd argue that <code>align_next</code> doesn't do anything particularly bad unless that value is then passed into some <code>unsafe</code> context. As with any question of <code>unsafe</code>, it's a tradeoff between safety/risk and ergonomics.</p>
<p>In <code>Vec::as_ptr</code>'s case, the risk is relatively low; the stdlib has lots of eyes on it, and is well &quot;battle-tested&quot;. Moreover, it is a single function with a single implementation.</p>
<p>If your <code>align_next</code> was a function on a trait, I'd be much more tempted to make it unsafe, since someone in the future could implement it badly, and you might have other code whose safety relies on a correct implementation of <code>align_next</code>.</p>
<p>However, in your case, I'd say the pattern is similar to <code>Vec::as_ptr</code>, and you should make sure that any functions that consume this value are marked <code>unsafe</code> if they can cause UB.</p>
<p>I'd also second Martin Gallagher's point about creating a <code>Result</code> returning variant and benchmarking (you could also try an <code>Option&lt;usize&gt;</code>-returning API to make use of null-pointer optimizations).</p>
"
"69763090","Package built by Poetry is missing runtime dependencies","<p>I've been working on a project which so far has just involved building some cloud infrastructure, and now I'm trying to <a href=""https://github.com/linz/geostore/pull/1142"" rel=""nofollow noreferrer"">add a CLI</a> to simplify running some AWS Lambdas. Unfortunately both the sdist and wheel packages built using <code>poetry build</code> don't seem to include the dependencies, so I have to manually <code>pip install</code> all of them to run the command. Basically I</p>
<ol>
<li>run <code>poetry build</code> in the project,</li>
<li><code>cd &quot;$(mktemp --directory)&quot;</code>,</li>
<li><code>python -m venv .venv</code>,</li>
<li><code>. .venv/bin/activate</code>,</li>
<li><code>pip install /path/to/result/of/poetry/build/above</code>, and then</li>
<li>run the new .venv/bin/ executable.</li>
</ol>
<p>At this point the executable fails, because <code>pip</code> did not install any of the package dependencies. <em>If I <code>pip show PACKAGE</code> the <code>Requires</code> line is empty.</em></p>
<p>The Poetry manual doesn't seem to specify how to link dependencies to the built package, so what do I have to do instead?</p>
<p>I am using some optional dependencies, could that be interfering with the build process? To be clear, even non-optional dependencies do not show up in the <a href=""https://github.com/linz/geostore/suites/4248835463/artifacts/110229472"" rel=""nofollow noreferrer"">package</a> dependencies.</p>
<p>pyproject.toml:</p>
<pre><code>[build-system]
requires = [&quot;poetry-core&gt;=1.0.0&quot;]
build-backend = &quot;poetry.core.masonry.api&quot;

[tool.black]
line-length = 100

[tool.coverage.report]
exclude_lines = [
    'if TYPE_CHECKING:',
    'if __name__ == &quot;__main__&quot;:',
    'pragma: no cover',
]
fail_under = 100

[tool.coverage.run]
branch = true
omit = [
    &quot;.venv/*&quot;,
]

[tool.isort]
case_sensitive = true
line_length = 100
profile = &quot;black&quot;

[tool.mypy]
show_error_codes = true
strict = true

[[tool.mypy.overrides]]
module = [
    &quot;jsonschema&quot;,
    &quot;jsonschema._utils&quot;,
    &quot;jsonschema.validators&quot;,
    &quot;multihash&quot;,
    &quot;pystac&quot;,
    &quot;pystac.layout&quot;,
    &quot;pytest_subtests&quot;,
    &quot;smart_open&quot;,
    &quot;linz_logger&quot;
]
ignore_missing_imports = true

[tool.poetry]
name = &quot;geostore&quot;
version = &quot;0.1.0&quot;
description = &quot;Central storage, management and access for important geospatial datasets developed by LINZ&quot;
authors = [
    &quot;Bill M. Nelson &lt;bmnelson@linz.govt.nz&gt;&quot;,
    &quot;Daniel Silk &lt;dsilk@linz.govt.nz&gt;&quot;,
    &quot;Ivan Mincik &lt;ivan.mincik@gmail.com&gt;&quot;,
    &quot;Mitchell Paff &lt;mpaff@linz.govt.nz&gt;&quot;,
    &quot;Sandro Santilli &lt;strk@kbt.io&gt;&quot;,
    &quot;Simon Planzer &lt;splanzer@linz.govt.nz&gt;&quot;,
    &quot;Victor Engmark &lt;vengmark@linz.govt.nz&gt;&quot;,
]
license = &quot;MIT&quot;
readme = &quot;README.md&quot;
homepage = &quot;https://github.com/linz/geostore&quot;
repository = &quot;https://github.com/linz/geostore&quot;
keywords = [
    &quot;SpatioTemporal Asset Catalog (STAC)&quot;,
    &quot;Toitū Te Whenua Land Information New Zealand&quot;,
]
classifiers = [
    &quot;Development Status :: 4 - Beta&quot;,
    &quot;Environment :: Console&quot;,
    &quot;Framework :: AWS CDK&quot;,
    &quot;Framework :: Pytest&quot;,
    &quot;Intended Audience :: End Users/Desktop&quot;,
    &quot;Intended Audience :: Information Technology&quot;,
    &quot;License :: OSI Approved :: MIT License&quot;,
    &quot;Natural Language :: English&quot;,
    &quot;Operating System :: POSIX&quot;,
    &quot;Programming Language :: Python :: 3.8&quot;,
    &quot;Topic :: Communications :: File Sharing&quot;,
    &quot;Topic :: Scientific/Engineering :: GIS&quot;,
    &quot;Topic :: Utilities&quot;,
    &quot;Typing :: Typed&quot;,
]

[tool.poetry.dependencies]
python = &quot;^3.8&quot;
&quot;aws-cdk.aws-dynamodb&quot; = {version = &quot;*&quot;, optional = true}
&quot;aws-cdk.aws-ec2&quot; = {version = &quot;*&quot;, optional = true}
&quot;aws-cdk.aws-ecr&quot; = {version = &quot;*&quot;, optional = true}
&quot;aws-cdk.aws-ecr_assets&quot; = {version = &quot;*&quot;, optional = true}
&quot;aws-cdk.aws-ecs&quot; = {version = &quot;*&quot;, optional = true}
&quot;aws-cdk.aws-events&quot; = {version = &quot;*&quot;, optional = true}
&quot;aws-cdk.aws-events-targets&quot; = {version = &quot;*&quot;, optional = true}
&quot;aws-cdk.aws-iam&quot; = {version = &quot;*&quot;, optional = true}
&quot;aws-cdk.aws-lambda&quot; = {version = &quot;*&quot;, optional = true}
&quot;aws-cdk.aws-lambda-event-sources&quot; = {version = &quot;*&quot;, optional = true}
&quot;aws-cdk.aws-lambda-python&quot; = {version = &quot;*&quot;, optional = true}
&quot;aws-cdk.aws-s3&quot; = {version = &quot;*&quot;, optional = true}
&quot;aws-cdk.aws-sns&quot; = {version = &quot;*&quot;, optional = true}
&quot;aws-cdk.aws-stepfunctions&quot; = {version = &quot;*&quot;, optional = true}
&quot;aws-cdk.aws-stepfunctions_tasks&quot; = {version = &quot;*&quot;, optional = true}
awscli = {version = &quot;*&quot;, optional = true}
boto3 = &quot;*&quot;
cattrs = {version = &quot;*&quot;, optional = true}
jsonschema = {version = &quot;*&quot;, extras = [&quot;format&quot;], optional = true}
multihash = {version = &quot;*&quot;, optional = true}
pynamodb = {version = &quot;*&quot;, optional = true}
pystac = {version = &quot;*&quot;, optional = true}
slack-sdk = {version = &quot;*&quot;, extras = [&quot;models&quot;, &quot;webhook&quot;], optional = true}
smart-open = {version = &quot;*&quot;, extras = [&quot;s3&quot;], optional = true}
strict-rfc3339 = {optional = true, version = &quot;*&quot;}
typer = &quot;*&quot;
ulid-py = {version = &quot;*&quot;, optional = true}
linz-logger = {version = &quot;*&quot;, optional = true}

[tool.poetry.dev-dependencies]
black = &quot;*&quot;
boto3-stubs = {version = &quot;*&quot;, extras = [&quot;batch&quot;, &quot;dynamodb&quot;, &quot;events&quot;, &quot;lambda&quot;, &quot;lambda-python&quot;, &quot;s3&quot;, &quot;s3control&quot;, &quot;sns&quot;, &quot;sqs&quot;, &quot;ssm&quot;, &quot;stepfunctions&quot;, &quot;sts&quot;]}
gitlint = &quot;*&quot;
ipdb = &quot;*&quot;
isort = &quot;*&quot;
language-formatters-pre-commit-hooks = &quot;*&quot;
mutmut = &quot;*&quot;
mypy = &quot;*&quot;
pre-commit = &quot;*&quot;
pylint = &quot;*&quot;
pytest = &quot;*&quot;
pytest-randomly = &quot;*&quot;
pytest-socket = &quot;*&quot;
pytest-subtests = &quot;*&quot;
pytest-timeout = &quot;*&quot;
types-pkg-resources = &quot;*&quot;
types-python-dateutil = &quot;*&quot;
types-requests = &quot;*&quot;
types-six = &quot;*&quot;
types-toml = &quot;*&quot;

[tool.poetry.dev-dependencies.coverage]
version = &quot;*&quot;
extras = [&quot;toml&quot;]

[tool.poetry.extras]
cdk = [
    &quot;aws-cdk.aws-dynamodb&quot;,
    &quot;aws-cdk.aws-ec2&quot;,
    &quot;aws-cdk.aws-ecr&quot;,
    &quot;aws-cdk.aws-ecr_assets&quot;,
    &quot;aws-cdk.aws-ecs&quot;,
    &quot;aws-cdk.aws-events&quot;,
    &quot;aws-cdk.aws-events-targets&quot;,
    &quot;aws-cdk.aws-iam&quot;,
    &quot;aws-cdk.aws-lambda&quot;,
    &quot;aws-cdk.aws-lambda-event-sources&quot;,
    &quot;aws-cdk.aws-lambda-python&quot;,
    &quot;aws-cdk.aws-s3&quot;,
    &quot;aws-cdk.aws-sns&quot;,
    &quot;aws-cdk.aws-stepfunctions&quot;,
    &quot;aws-cdk.aws-stepfunctions_tasks&quot;,
    &quot;awscli&quot;,
    &quot;cattrs&quot;,
]
check_files_checksums = [
    &quot;boto3&quot;,
    &quot;linz-logger&quot;,
    &quot;multihash&quot;,
    &quot;pynamodb&quot;,
]
check_stac_metadata = [
    &quot;boto3&quot;,
    &quot;jsonschema&quot;,
    &quot;linz-logger&quot;,
    &quot;pynamodb&quot;,
    &quot;strict-rfc3339&quot;,
]
cli = [
    &quot;boto3&quot;,
    &quot;typer&quot;,
]
content_iterator = [
    &quot;jsonschema&quot;,
    &quot;linz-logger&quot;,
    &quot;pynamodb&quot;,
]
datasets = [
    &quot;boto3&quot;,
    &quot;jsonschema&quot;,
    &quot;linz-logger&quot;,
    &quot;pynamodb&quot;,
    &quot;pystac&quot;,
    &quot;ulid-py&quot;,
]
dataset_versions = [
    &quot;jsonschema&quot;,
    &quot;linz-logger&quot;,
    &quot;pynamodb&quot;,
    &quot;ulid-py&quot;,
]
import_asset_file = [
    &quot;boto3&quot;,
    &quot;linz-logger&quot;,
    &quot;smart-open&quot;,
]
import_dataset = [
    &quot;boto3&quot;,
    &quot;jsonschema&quot;,
    &quot;linz-logger&quot;,
    &quot;pynamodb&quot;,
    &quot;smart-open&quot;,
    &quot;ulid-py&quot;,
]
import_metadata_file = [
    &quot;boto3&quot;,
    &quot;linz-logger&quot;,
]
import_status = [
    &quot;boto3&quot;,
    &quot;jsonschema&quot;,
    &quot;linz-logger&quot;,
    &quot;pynamodb&quot;,
]
notify_status_update = [
    &quot;boto3&quot;,
    &quot;jsonschema&quot;,
    &quot;linz-logger&quot;,
    &quot;pynamodb&quot;,
    &quot;slack-sdk&quot;
]
populate_catalog = [
    &quot;boto3&quot;,
    &quot;jsonschema&quot;,
    &quot;linz-logger&quot;,
    &quot;pystac&quot;,
]
update_dataset_catalog = [
    &quot;boto3&quot;,
    &quot;jsonschema&quot;,
    &quot;linz-logger&quot;,
    &quot;pynamodb&quot;,
    &quot;ulid-py&quot;
]
upload_status = [
    &quot;boto3&quot;,
    &quot;jsonschema&quot;,
    &quot;linz-logger&quot;,
    &quot;pynamodb&quot;,
]
validation_summary = [
    &quot;jsonschema&quot;,
    &quot;linz-logger&quot;,
    &quot;pynamodb&quot;,
]

[tool.poetry.scripts]
geostore = &quot;geostore.cli:app&quot;

[tool.pylint.MASTER]
disable = [
    &quot;duplicate-code&quot;,
    &quot;missing-class-docstring&quot;,
    &quot;missing-function-docstring&quot;,
    &quot;missing-module-docstring&quot;,
]
load-plugins = [
    &quot;pylint.extensions.mccabe&quot;,
]
max-complexity = 6

[tool.pytest.ini_options]
addopts = &quot;--randomly-dont-reset-seed&quot;
markers = [
    &quot;infrastructure: requires a deployed infrastructure&quot;,
]
python_functions = &quot;should_*&quot;
testpaths = [
    &quot;tests&quot;
]
</code></pre>
<p>As you can see the boto3 and typer runtime dependencies are not optional, so I'd expect to see them in <code>poetry show geostore</code>.</p>
","<python-packaging><requirements><python-poetry>","2021-10-29 02:54:44","2887","4","1","69833825","<p>This appears to be a bug in Poetry. Or at least it's not clear from the documentation what the expected behavior would be in a case such as yours.</p>
<p>In your <code>pyproject.toml</code>, you specify two dependencies as required in this section:</p>
<pre><code>[tool.poetry.dependencies]
…
awscli = {version = &quot;*&quot;, optional = true}
boto3 = &quot;*&quot;
…
typer = &quot;*&quot;
…
</code></pre>
<p>So, as opposed to <code>awscli</code> among many others, <code>boto3</code> and <code>typer</code> should be required because the <code>optional</code> attribute is not set and defaults to <code>false</code>. But you also list the two required dependencies as &quot;extras&quot; in this section:</p>
<pre><code>[tool.poetry.extras]
…
cli = [
    &quot;boto3&quot;,
    &quot;typer&quot;,
]
…
</code></pre>
<p>Poetry takes that to mean that they are in fact optional, not required. Which makes sense, in a way, because extras are effectively optional. If you inspect the <code>.whl</code> wheel file built by Poetry (it's just a zip archive), specifically the <code>METADATA</code> file in it (which is what Pip refers to when installing the package), then it contains this line:</p>
<pre class=""lang-none prettyprint-override""><code>Requires-Dist: typer; extra == &quot;cli&quot;
</code></pre>
<p>So that dependency is in fact optional: It will only get installed if users ask for it explicitly with <code>pip install geostore[cli]</code>.</p>
<p>The solution then is simple: Remove all references to the required dependencies from the <code>extras</code> section. They are not needed there anyway.</p>
<p>The Poetry documentation is in fact not very clear on what <code>optional</code> really signifies. That attribute is (currently) only briefly mentioned in the <a href=""https://python-poetry.org/docs/pyproject/#extras"" rel=""noreferrer"">section on the <code>pyproject.toml</code> file</a>. One could also argue that if <code>optional</code> is <code>false</code>, then the <code>extras</code> section should not override that value.</p>
"
"69627616","Make explicit in UML state diagram that order of activities does not matter","<p>Have a UML state diagram describing behaviour of a system by showing the interaction of the user and the system to carry out a use case. This diagram is used as agreement (requirement) with the developers of the system.</p>
<p>When the user request to carry out a use case, the system request information to the user and show error messages if the information is not valid. The system also authenticate the user and show him an error if he is not authenticated.</p>
<p>But it does not matter which activity is done first. It is, which error, information or authentication error, is shown first. We want to make explicit to the developers that the order of activities does not matter though all activities should be done. How we achieve that? I think the &quot;fork&quot; item in state diagram is for this?</p>
","<uml><requirements><state-diagram>","2021-10-19 08:39:24","189","0","1","69628966","<p>It seems that you are confusing state machine diagram with activity diagram (and possibly also sequence diagram). The latter has fork (and in sequence diagram there is a way of showing that events are happening in parallel).</p>
<p>The state machine diagram does show the changes of the state and its triggers but is not the main diagram to show related actions nor their flow.
Moreover the entire state machine of an entity typically is influenced by more than one user story. In other words, triggers of state changes can be caused by different use cases. So state machine is across multiple user stories rather than describing just one.</p>
<p>If you try to document flow of use case using state machine diagram, you are most probably doing it wrong.</p>
"
"69626224","Which Dependencies File Should I Use for my Dockerfile?","<p>I'm currently learning about <strong>Docker</strong>. I'm trying to use it in my python project (I'm using Django)</p>
<p>In my <code>Dockerfile</code>, I want my image to install the dependencies of my project into each new container.
I just created a requirements.txt file using the command tool 'pipreqs'</p>
<p>After looking at the content of this file, I realize that I have 2 others files related to the dependencies:</p>
<ul>
<li><code>Pipfile</code></li>
<li><code>Pipfile.lock</code></li>
</ul>
<p>I think they have been created and updated when I was using pipenv command.</p>
<p>My question is : Which one of these file should I use in my <code>Dockerfile</code>? <code>Pipfile</code>, <code>Pipfile.lock</code> or <code>requirements.txt</code>?</p>
","<python><docker><dependencies><requirements><pipfile>","2021-10-19 06:50:56","250","0","1","69628031","<p>Default choice is <strong>requirements.txt with pinned versions</strong>.</p>
<p>Versions can be pinned by <code>pip freeze &gt; requirements.txt</code> or <code>pipenv lock -r &gt; requirements.txt</code>.
You need Pipfile and Pipfile.lock if you going to use pipenv inside container. Then <code>pipenv install</code> will use your Pipfile.lock.</p>
"
"69462872","Use case instance and Scenario","<p>In the literature, a scenario has sometimes been defined as an instance of a use case.<br />
Do you see any problem with defining a <strong>scenario</strong> as an “<strong>instance of the use case</strong>”?<br />
Please, help me!</p>
","<uml><terminology><use-case><requirements><scenarios>","2021-10-06 09:11:23","253","0","1","69734356","<p>The scenarios are not use-case instances and you do not need to reinvent terms:</p>
<ul>
<li><p>The UML specification define <strong>use-cases</strong> and <strong>use-case instances</strong>:</p>
<blockquote>
<p>A UseCase is a specification of behavior. An instance of a UseCase refers to an <strong>occurrence</strong> of the emergent behavior that conforms to the corresponding UseCase.</p>
</blockquote>
</li>
<li><p>The UML standard does not define the scenario. But <strong>scenario</strong> is a common term in use-case literature, and refer to a general sequence of events.  Mainstream use-case document templates rely heavily on scenarios (e.g. &quot;Main scenario&quot; and &quot;alternative scenario&quot; for variants, error processing or exceptions).</p>
</li>
</ul>
<p><strong>Usual ATM example</strong>:</p>
<ul>
<li><p><code>Withdraw cash</code> would be a use-case</p>
</li>
<li><p><code>Ms. Smith withdraws cash on October 27 2021 at 9:23AM at the ATM #23782 of Bank Y for an amount of 50€</code> would be an instance of the use-case, i.e. a specific occurence at a given moment in time with a specific user.</p>
</li>
<li><p>Following general scenarios could be envisaged for the use-case: use of a bank card to be inserted in the ATM, use of a contactless card,  or ATM swallows the card because of wrong codes.</p>
</li>
<li><p>The instance may correspond to one of those scenarios.  But a same scenario could happen in many instances.</p>
</li>
</ul>
"
"68789467","What are the TestCafe requirements for the HTML and Javascript used in a WebApp (i.e a Tomcat web app)","<p>The TestCafe docs lack any but the simplest requirements.</p>
<p>The web app i wrote in 2008-9 is XHMTL 1.0 syntax generated by
Freemarker templates under SpringFramework 2.5.x, that have lots
of forms and pages with excel like tables full of buttons,links,form+input, etc
in each row of the tables.</p>
<p>It uses a <code>onclick=&quot;...&quot;</code> javascript for conditional button behaviors
that do input validation on the form inputs, and other such, alert()s, etc.
I used css / class attribute only for formatting, but lots of <code>id=&quot;xxx&quot;</code>
and <code>getElementById(&quot;xxx&quot;)</code> in the javascript and update the DOM from .js
functions.  I did not user any javascript frameworks like Node.js or jquery.
I did use iFrames for printout frames.</p>
<p>I also have a few cases of Select menu B options map is dependent on a
Select Menu A choice, which causes dynamic replacement of the menu B options map.
The app has more than 150 unique pages, 5 user roles. The app works in Firefox,
Safari and IE11/Edge, Chrome.</p>
<p>Q: Can TestCafe test a WebApp implemented in this outdated manner?</p>
<p>Q: Can it handle the dynamic DOM modification made via javascript functions
invoked by <code>onclick=&quot; func()&quot; and onselect=&quot; func()&quot;</code> of button and select tags?</p>
<p>Q Can TestCafe <code>Selector()</code> use element ids to <code>find()</code> elements?
as the web app generates unique ids for link, button, input, etc, tags
in rows of the tables via freemarker template variables.</p>
","<javascript><testing><dynamic><testcafe><requirements>","2021-08-15 07:14:37","55","0","2","68799784","<p>At present, TestCafe may have issues during testing of XHMTL pages (see <a href=""https://github.com/DevExpress/testcafe-hammerhead/issues/350"" rel=""nofollow noreferrer"">this page</a> for more information). I am not familiar with the Tomcat Web application. However, if this web application can be opened in a browser, TestCafe can operate with it.</p>
"
"68789467","What are the TestCafe requirements for the HTML and Javascript used in a WebApp (i.e a Tomcat web app)","<p>The TestCafe docs lack any but the simplest requirements.</p>
<p>The web app i wrote in 2008-9 is XHMTL 1.0 syntax generated by
Freemarker templates under SpringFramework 2.5.x, that have lots
of forms and pages with excel like tables full of buttons,links,form+input, etc
in each row of the tables.</p>
<p>It uses a <code>onclick=&quot;...&quot;</code> javascript for conditional button behaviors
that do input validation on the form inputs, and other such, alert()s, etc.
I used css / class attribute only for formatting, but lots of <code>id=&quot;xxx&quot;</code>
and <code>getElementById(&quot;xxx&quot;)</code> in the javascript and update the DOM from .js
functions.  I did not user any javascript frameworks like Node.js or jquery.
I did use iFrames for printout frames.</p>
<p>I also have a few cases of Select menu B options map is dependent on a
Select Menu A choice, which causes dynamic replacement of the menu B options map.
The app has more than 150 unique pages, 5 user roles. The app works in Firefox,
Safari and IE11/Edge, Chrome.</p>
<p>Q: Can TestCafe test a WebApp implemented in this outdated manner?</p>
<p>Q: Can it handle the dynamic DOM modification made via javascript functions
invoked by <code>onclick=&quot; func()&quot; and onselect=&quot; func()&quot;</code> of button and select tags?</p>
<p>Q Can TestCafe <code>Selector()</code> use element ids to <code>find()</code> elements?
as the web app generates unique ids for link, button, input, etc, tags
in rows of the tables via freemarker template variables.</p>
","<javascript><testing><dynamic><testcafe><requirements>","2021-08-15 07:14:37","55","0","2","69199932","<p>Q1) I don't have any insight on this question.</p>
<p>Q2) Yes. Look into async, await, and promises.</p>
<p>Q3) Yes. Any kind of attribute. You mentioned find() specifically, so look into: <a href=""https://testcafe.io/documentation/402750/reference/test-api/selector/find"" rel=""nofollow noreferrer"">https://testcafe.io/documentation/402750/reference/test-api/selector/find</a></p>
"
"68781332","Microservice design: change on data requirements or schema","<p>Suppose we have 2 services, service A and service B. They are interact with each other with event sourcing. Service A publish event ( entity1 created with fields f1, f2, f3). Service B make own copy of entity1 with fields f1 and f2. Now how we can address this two scenario.</p>
<ol>
<li>New requirement in service 2 and needs for f3. How service2 must update its local data?</li>
<li>Schema change on service 1. how service 2 must update its local data and schema?</li>
</ol>
<p>In scenario 2, services are tightly coupled by schema and can causes errors and this has contradict with event sourcing goal. How can we address this problem?</p>
","<design-patterns><microservices><event-sourcing>","2021-08-14 07:42:34","133","0","1","68783220","<p>For scenario 1, where the view of the entity changes to incorporate fields which were published to the event stream, the easiest thing is likely to be replaying the events (e.g. if the event stream is on Kafka, using a new consumer group with <code>auto.offset.reset=earliest</code>) with an event handler which uses the new field.  This can often be surprisingly quick, allowing you to run this rebuild in a time window where the previous version of the service is running; otherwise, you should be able to run the old instance of service B alongside the new instance (if they're writing to different DBs): when the new instance catches up, you shift whatever traffic is hitting service B to use the new instance and tear down the old (basically a blue-green deploy).</p>
<p>For the second scenario, there are some choices to make:</p>
<ul>
<li>You can define an <code>Entity1CreatedV2</code> event which fits the new schema (this is likely to require updating consumers to know about the new event first)</li>
<li>If the fields in the old schema are unchanged (i.e. the schema change is strictly additive), you can keep the old <code>Entity1Created</code> message and then have an event for the new fields.  Note that accomodating the schema change for existing entities in service A may drive you to this solution anyway, especially if there's no command-sourcing for service A going on (command-sourcing might allow you to pretend that the new schema was around forever).</li>
</ul>
"
"65947614","How can I find the requirements for older TensorFlow versions?","<p>Because right now, I am using the <a href=""https://web.archive.org/web/20201030140623if_/https://www.tensorflow.org/install/gpu"" rel=""nofollow noreferrer"">Wayback Machine</a>, which is absurd.
There <em>must</em> be a better way.</p>
<p><strong>For a given TensorFlow version, e.g. 2.1, how / where can I find the related software requirements?</strong></p>
<p>More specifically, which NVIDIA GPU Drivers, Cuda Toolkit and cuDNN are required.</p>
","<python><tensorflow><requirements>","2021-01-29 01:33:36","419","1","1","65947789","<p>One way is, you can setup a virtual environment and install tensorflow 2.1</p>
<pre><code>$ pip install tensorflow==2.1.3
</code></pre>
<p>Then just calling the library in command line will show its dependencies</p>
<pre><code>$ tensorflow
</code></pre>
<p>Check <a href=""https://stackoverflow.com/questions/29751572/how-to-find-a-python-packages-dependencies"">this answer</a> for details.</p>
<hr />
<p>If you don't want to install the library,</p>
<ol>
<li>You can go to the <a href=""https://github.com/tensorflow/tensorflow/releases"" rel=""nofollow noreferrer"">TensorFlow releases</a>.</li>
<li>Select the specific package</li>
<li>And in the source code for the older version (will have to download its zip) in setup.py under REQUIRED_PACKAGES you can find the list.</li>
</ol>
<p>Example here (check the path shown below to find the file)- <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py</a></p>
<pre><code>REQUIRED_PACKAGES = [
    'absl-py ~= 0.10',
    'astunparse ~= 1.6.3',
    'flatbuffers ~= 1.12.0',
    'google_pasta ~= 0.2',
    'h5py ~= 3.1.0',
    'keras_preprocessing ~= 1.1.2',
    'numpy ~= 1.19.2',
    'opt_einsum ~= 3.3.0',
    'protobuf &gt;= 3.9.2',
    'six ~= 1.15.0',
    'termcolor ~= 1.1.0',
    'typing_extensions ~= 3.7.4',
    'wheel ~= 0.35',
    'wrapt ~= 1.12.1',
    # These packages need to be pinned exactly as newer versions are
    # incompatible with the rest of the ecosystem
    'gast == 0.4.0',
    # TensorFlow ecosystem packages that TF exposes API for
    # These need to be in sync with the existing TF version
    # They are updated during the release process
    # When updating these, please also update the nightly versions below
    'tensorboard ~= 2.4',
    'tensorflow_estimator ~= 2.3.0',
]
</code></pre>
"
"65833151","Adding version requirements in OSGI capability","<p>Does OSGI capabilities support versioning and how does it work? Say I have a module with the following declared:</p>
<pre><code>Bundle-SymbolicName: my-module
Implementation-Version: 1.8.1-qualifier
Provide-Capability: org.foo.dependency;nameId=&quot;my-module&quot;,version=&quot;1.8.1-qualifier&quot;
</code></pre>
<p>Would I then be able to add this require to get the module above?</p>
<pre><code>Require-Capability: org.foo.dependency;filter:=&quot;&amp;(nameId=my-module)(version&gt;=1.8)&quot;
</code></pre>
<p>Is there also a way to leverage <code>Implementation-Version</code> on the manifest if it's already specified in the provider module? I see references to <code>osgi.wiring.bundle</code> <a href=""https://docs.osgi.org/specification/osgi.core/7.0.0/framework.namespaces.html#i1773242"" rel=""nofollow noreferrer"">here</a>. Would I be able to do this instead on the require:</p>
<pre><code>Require-Capability: org.foo.dependency;filter:=&quot;(nameId=my.module)&quot;,osgi.wiring.bundle;filter:=&quot;(bundle-version&gt;=1.8)&quot;
</code></pre>
<p>Appreciate any pointers on the subject matter.</p>
","<java><osgi><requirements><capability>","2021-01-21 17:57:17","129","0","1","65837281","<p><code>1.8.1-qualifier</code> is not a valid <a href=""https://docs.osgi.org/specification/osgi.core/8.0.0/framework.module.html#i2655136"" rel=""nofollow noreferrer"">OSGi version</a>. <code>1.8.1.qualifier</code> is a valid OSGi version.</p>
<p><code>&amp;(nameId=my-module)(version&gt;=1.8)</code> is not a valid <a href=""https://docs.osgi.org/specification/osgi.core/8.0.0/framework.module.html#framework.module.filtersyntax"" rel=""nofollow noreferrer"">OSGi filter expression</a>. You need to surround with parenthesis. <code>(&amp;(nameId=my-module)(version&gt;=1.8))</code></p>
<p>You cannot use <code>Implementation-Version</code>, but you can use <code>Bundle-Version</code>.</p>
<pre><code>Bundle-SymbolicName: my-module
Bundle-Version: 1.8.1.qualifier

Require-Capability: osgi.wiring.bundle;filter:=&quot;(&amp;(osgi.wiring.bundle=my-module)(bundle-version&gt;=1.8))&quot;
</code></pre>
<p>See <a href=""https://docs.osgi.org/specification/osgi.core/8.0.0/framework.namespaces.html#framework.namespaces.osgi.wiring.bundle"" rel=""nofollow noreferrer"">https://docs.osgi.org/specification/osgi.core/8.0.0/framework.namespaces.html#framework.namespaces.osgi.wiring.bundle</a>.</p>
"
"65744941","Is providing the ability to violate ""shall"" requirement w/o generation of a diagnostic message a compiler bug / defect or feature?","<p>Context: The C standard does not classify diagnostic messages as &quot;warnings&quot; or &quot;errors&quot;.</p>
<p>Question: By treating certain &quot;diagnostic messages&quot; as &quot;warnings&quot; and by giving the ability to disable generation of warnings, certain compiler implementations allow to the end user to violate &quot;shall&quot; requirements of the C standard w/o generation of a diagnostic messages. Is this allowance a compiler bug / defect? If not, then how to correctly interpret this case? As a &quot;compiler feature that allows to violate &quot;shall&quot; requirement w/o generation of a diagnostic message&quot;?</p>
<p>Example:</p>
<pre><code>#pragma warning( disable : 34 )
typedef int T[];
int main()
{
    return sizeof(T);
}
</code></pre>
<pre><code>$ cl t28.c /Za
&lt;no diagnostic messages, the &quot;shall&quot; requirement [1] is silently violated&gt;
</code></pre>
<p>[1] ISO/IEC 9899:1990:</p>
<blockquote>
<p>The sizeof operator shall not be applied to an expression that has function type or an incomplete type.</p>
</blockquote>
<p>UPD.</p>
<ol>
<li>If <code>/Za</code> (Disable Language Extensions) is specified, then <code>__STDC__</code> is defined with definition 1.</li>
<li>According to <code>ANSI Conformance</code> page (<a href=""https://learn.microsoft.com/en-us/cpp/c-language/ansi-conformance?view=msvc-160"" rel=""nofollow noreferrer"">https://learn.microsoft.com/en-us/cpp/c-language/ansi-conformance?view=msvc-160</a>):</li>
</ol>
<blockquote>
<p>Microsoft C conforms to the standard for the C language as set forth in the 9899:1990 edition of the ANSI C standard.</p>
</blockquote>
<ol start=""3"">
<li>However, <code>cl</code> gives to the end user the ability to disable &quot;shall requirement originated&quot; warnings. Is it a compiler bug / defect or feature? Need to to correctly interpret this case.</li>
</ol>
","<c><constraints><compiler-warnings><requirements>","2021-01-15 23:41:25","53","0","2","65745241","<p>C 2018 6.10.6 discusses the <code>#pragma</code> directive. Paragraph 1 says:</p>
<blockquote>
<p>… causes the implementation to behave in an implementation-defined manner. The behavior might cause translation to fail or cause the translator or the resulting program to behave in a non-conforming manner…</p>
</blockquote>
<p>That largely licenses the implementation to do anything it wants, as long as it documents it. If <code>#pragma warning( disable : 34 )</code> is documented to disable the warning, and that is what it does, then that is conforming.</p>
<p>Note in particular that the <code>#pragma</code> “might … cause the translator … to behave in a non-conforming manner.” So, doing something that is otherwise non-conforming because a pragma told you to is conforming.</p>
<p>(I think the original text should say that the <code>#pragma</code> may cause the translator or program to behave in an <strong>otherwise</strong> non-conforming manner. Because, as currently written, behaving in this documented non-conforming manner is conforming, not non-conforming.)</p>
"
"65744941","Is providing the ability to violate ""shall"" requirement w/o generation of a diagnostic message a compiler bug / defect or feature?","<p>Context: The C standard does not classify diagnostic messages as &quot;warnings&quot; or &quot;errors&quot;.</p>
<p>Question: By treating certain &quot;diagnostic messages&quot; as &quot;warnings&quot; and by giving the ability to disable generation of warnings, certain compiler implementations allow to the end user to violate &quot;shall&quot; requirements of the C standard w/o generation of a diagnostic messages. Is this allowance a compiler bug / defect? If not, then how to correctly interpret this case? As a &quot;compiler feature that allows to violate &quot;shall&quot; requirement w/o generation of a diagnostic message&quot;?</p>
<p>Example:</p>
<pre><code>#pragma warning( disable : 34 )
typedef int T[];
int main()
{
    return sizeof(T);
}
</code></pre>
<pre><code>$ cl t28.c /Za
&lt;no diagnostic messages, the &quot;shall&quot; requirement [1] is silently violated&gt;
</code></pre>
<p>[1] ISO/IEC 9899:1990:</p>
<blockquote>
<p>The sizeof operator shall not be applied to an expression that has function type or an incomplete type.</p>
</blockquote>
<p>UPD.</p>
<ol>
<li>If <code>/Za</code> (Disable Language Extensions) is specified, then <code>__STDC__</code> is defined with definition 1.</li>
<li>According to <code>ANSI Conformance</code> page (<a href=""https://learn.microsoft.com/en-us/cpp/c-language/ansi-conformance?view=msvc-160"" rel=""nofollow noreferrer"">https://learn.microsoft.com/en-us/cpp/c-language/ansi-conformance?view=msvc-160</a>):</li>
</ol>
<blockquote>
<p>Microsoft C conforms to the standard for the C language as set forth in the 9899:1990 edition of the ANSI C standard.</p>
</blockquote>
<ol start=""3"">
<li>However, <code>cl</code> gives to the end user the ability to disable &quot;shall requirement originated&quot; warnings. Is it a compiler bug / defect or feature? Need to to correctly interpret this case.</li>
</ol>
","<c><constraints><compiler-warnings><requirements>","2021-01-15 23:41:25","53","0","2","65745707","<p>&quot;shall&quot; (and &quot;shall not&quot;) requirements in the standard come in two distinct kinds: restrictions on the <em>program</em> and restrictions on the <em>implementation</em>.</p>
<p>Restrictions on the <em>implemention</em> are things the implementation must (or must not) do -- these may have mandatory diagnostics associated with them.</p>
<p>Restrictions on the <em>program</em> are in fact <em>freedoms</em> for the implementation -- they are things that -- if the program does them -- cause undefined behavior, so the implementation can do anything with them and still be conforming.</p>
<p>The example you have above &quot;The sizeof operator shall not be applied to an expression that &quot;... is a restriction on the <em>program</em>.  So a program that does that is not conforming and an implementation can do anything it wants (including treating it as an extension without any requirement for a flag or pragma) and still be conforming.</p>
"
"65736410","pipenv deleted libraries from my virtual environment?","<p>I am using Homebrew-installed <code>pipenv</code> to manage my virtual environments for Python projects. I navigate to my Python project's folder and use the <code>pipenv shell</code> command to activate the venv.</p>
<p>It has worked fine, until today when I noticed that I can't run my app.py from within the shell using the <code>python3 app.py</code> command. I get the <code>ModuleNotFoundError: No module named 'flask'</code> right from line 1.</p>
<p>When I run <code>which python3</code> and <code>which pip3</code>, I see the expected response that specifies that I'm within my venv. When I run <code>pip3 list</code>, I only see <code>pip</code>, <code>setuptools</code> and <code>wheel</code>.</p>
<p>This is odd, because just very recently everything has worked fine (1-2 weeks ago?), and I'm positive that I personally didn't do anything that would mess with the libraries/requirements.</p>
<p>The Pipfile still lists all the requirements as expected. So how come they got deleted from my virtual environment?</p>
<p>I understand that I can just redownload all of the requirements; I'm just curious about why this happened in the first place.</p>
<p>UPDATE: I just realised that I did change the name of the folder which contains the project; I assume this is the cause. Since I've redownloaded the requirements already, does that mean I now have duplicates existing somewhere? If so, where?</p>
","<python><pipenv><requirements><pipfile>","2021-01-15 12:47:42","270","0","1","65793232","<p>If you moved/renamed the folder where you created your virtual env, then the next time you try to activate the virtual env there, Pipenv will create a brand new virtual env. This is because Pipenv creates the actual virtual env folders <strong>based on the full path to the project directory</strong>. This is noted in the docs:</p>
<p><a href=""https://pipenv-fork.readthedocs.io/en/latest/install.html#virtualenv-mapping-caveat"" rel=""nofollow noreferrer"">https://pipenv-fork.readthedocs.io/en/latest/install.html#virtualenv-mapping-caveat</a></p>
<blockquote>
<ul>
<li>Pipenv automatically maps projects to their specific virtualenvs.</li>
<li>The virtualenv is stored globally with the name of the project’s root directory plus the hash of the full path to the project’s root (e.g., <code>my_project-a3de50</code>).</li>
<li><strong>If you change your project’s path, you break such a default mapping and pipenv will no longer be able to find and to use the project’s virtualenv.</strong></li>
</ul>
</blockquote>
<p>Emphasis on the 3rd bullet. So it didn't delete your packages, it basically created a new one. You should have also seen a notice that it was creating a new one:</p>
<pre class=""lang-none prettyprint-override""><code>demo$ pipenv shell
Launching subshell in virtual environment...
...

(demo) demo$ 
exit
demo$ cd ..
~$ mv demo demo2
~$ cd demo2

demo2$ pipenv shell
Creating a virtualenv for this project...
...

(demo2) demo2$ 
</code></pre>
<p>That &quot;Creating a virtualenv...&quot; means it's creating a new one.</p>
<p>Now, on to:</p>
<blockquote>
<p>does that mean I now have duplicates existing somewhere? If so, where?</p>
</blockquote>
<p>It means you still have your previous virtual env folder somewhere, where you previously installed your packages. You can try using the <a href=""https://pipenv.pypa.io/en/latest/cli/#cmdoption-pipenv-venv"" rel=""nofollow noreferrer""><code>--venv</code></a> option to get the top-level directory where Pipenv creates all virtual env folders. In your new env:</p>
<pre class=""lang-none prettyprint-override""><code>(demo2) demo2$ pipenv --venv
/Users/gino.mempin/.venvs/demo2-4Y1NLH_X
</code></pre>
<p>As mentioned, the virtual env folder here is <code>demo2-4Y1NLH_X</code>, and the top-level folder is (for my case) <code>.venvs</code>. The default is something like <em>/.local/share/</em> or whatever you set <code>WORKON_HOME</code> to (see <a href=""https://pipenv.pypa.io/en/latest/advanced/#custom-virtual-environment-location"" rel=""nofollow noreferrer"">Custom Virtual Environment Location</a>). Just run the <code>--venv</code> for yourself.</p>
<p>You can try going there, and it will list all the virtual envs you have created:</p>
<pre class=""lang-none prettyprint-override""><code>(demo2) demo2$ ls /Users/gino.mempin/.venvs
demo-tSf-ZA7f
demo2-4Y1NLH_X
some-other-project-ABJaje5
another-project-8WUmE08m
...
</code></pre>
<p>Here, if you are lucky, you can find the name of your old folder, and then simply delete it if you want to cleanup. If you are unlucky, there'll be multiple folders with the same name, and you won't be able to tell which one was your old folder.</p>
<pre class=""lang-none prettyprint-override""><code>(demo2) demo2$ ls /Users/gino.mempin/.venvs
demo-tSf-ZA7f
demo-7I2ki6rH
demo-8WUmE08m
demo2-4Y1NLH_X
</code></pre>
<p>There is currently no way to get the full path to the original directly from the virtual env folder-hash itself. (See related: <a href=""https://stackoverflow.com/q/65126606/2745495"">How to remove all pipenv virtualenvs when the directory was deleted?</a>). There is also no way to reuse your old virtual env and copy it to your new one. But you don't need to anyway, creating virtual envs is inexpensive, just recreate it and reinstall all previous packages.</p>
"
"65332828","Functional Requirement vs Non-Functional Requirement for Uber Application","<p>What is the difference between the functional requirement and non-functional requirement for Uber application?</p>
","<uber-api><requirements><system-requirements>","2020-12-16 23:55:53","2578","2","1","65333161","<p><strong>Regardless UberApi (or any product or technology)</strong></p>
<p>The terms are <strong>general terms</strong>.</p>
<p>If you have a client that asks you to develop an <strong>e-commerce web site</strong> that will be reached by customers thousands of times every minute, then based on this example:</p>
<p><strong>Functional</strong> Requirements are:</p>
<ol>
<li>Customer should be able to list products</li>
<li>Customer should be able to place order</li>
<li>Customer should be able to pay by card</li>
</ol>
<p>and so on</p>
<p><strong>Non-functional</strong> Requirements (Technical Requirement)</p>
<ol>
<li>The Site should be able to serve a huge number of customers at the
same time without problems.</li>
<li>The site should be secure enough because there will be sensitive data.</li>
</ol>
<p>and so on</p>
<p>So you can consider <strong>functional</strong> as the Domain(Business) requirements while the <strong>non-functional</strong> as the supportive requirements.</p>
"
"65127894","How far IEEE 754 can be violated for the goal of performance increase?","<p>As we know, the practice &quot;not fully IEEE 754 conformant, but faster&quot; exists. This is what compilers optionally do (options related to <code>floating-point model</code> or <code>floating-point behavior</code>).
However, which exactly IEEE 754 requirements can never be violated? Is there any addendum describing these aspects (i.e. &quot;how far optimizing IEEE 754 implementations can go?&quot;).</p>
","<c><optimization><floating-point><ieee-754><requirements>","2020-12-03 14:27:53","75","0","2","65128063","<p><a href=""https://en.wikipedia.org/wiki/IEEE_754"" rel=""nofollow noreferrer"">Wikipedia</a> gives a few directions/clues:</p>
<ul>
<li><p>The <a href=""https://en.wikipedia.org/wiki/IEEE_754#Extended_and_extendable_precision_formats"" rel=""nofollow noreferrer"">extended precision formats</a> are optional.</p>
</li>
<li><p>There are <a href=""https://en.wikipedia.org/wiki/IEEE_754#Recommendations"" rel=""nofollow noreferrer"">recommendations</a> which are not required.</p>
</li>
</ul>
<p>Other parts of this Wikipedia entry describes required functionality.</p>
"
"65127894","How far IEEE 754 can be violated for the goal of performance increase?","<p>As we know, the practice &quot;not fully IEEE 754 conformant, but faster&quot; exists. This is what compilers optionally do (options related to <code>floating-point model</code> or <code>floating-point behavior</code>).
However, which exactly IEEE 754 requirements can never be violated? Is there any addendum describing these aspects (i.e. &quot;how far optimizing IEEE 754 implementations can go?&quot;).</p>
","<c><optimization><floating-point><ieee-754><requirements>","2020-12-03 14:27:53","75","0","2","65128555","<blockquote>
<p>As we know, the practice &quot;not fully IEEE 754 conformant, but faster&quot; exists. This is what compilers optionally do (options related to floating-point model or floating-point behavior). However, which exactly IEEE 754 requirements can never be violated?</p>
</blockquote>
<p>This mostly devolves into a discussion about how much you can get away with before the words &quot;not fully&quot; aren't appropriate anymore. If you want to take things very literally, you could just have a sign bit (that conforms to IEEE 754) and nothing else (no exponent, no significant) and still say &quot;not fully compliant&quot; and be technically correct; but in this case most people would complain that the amount of &quot;not fully compliant&quot; is so close to &quot;not compliant&quot; that it's misleading.</p>
<p>To avoid being misleading; &quot;not fully compliant&quot; is closer to &quot;compliant enough for most things in practice&quot;, but this really depends on the implementation and should be interpreted as such (e.g. probably should be taken to mean &quot;read the compiler's manual&quot;).</p>
<p>Note that often &quot;not fully compliant&quot; actually means it pretends that subnormals are zero, and/or that signaling NaNs aren't supported, and/or that precision is higher than it should be (e.g. 80-bit floating point used for intermediate results causing more accurate final results than you would get if it was fully compliant).</p>
<p>Also; often compilers will offer a third &quot;fast math&quot; option that is even faster (and even less compliant), and don't use the words &quot;not fully compliant&quot; for this case. When that happens it makes sense for &quot;not fully compliant&quot; to be more of a middle ground between &quot;fast math&quot; and &quot;fully compliant&quot;.</p>
"
"65110424","obtain requirements from HP ALM executing a query of a concrete target version","<p>I need to obtain all the requirements in a corporate HPE ALM of a concrete target version (field user-template-18). To obtain these requirements, I'm using the next url in my code within the C# project that I'm developing:
http://&lt;hp_alm&gt;/qcbin/rest/domains/&lt;name_domain&gt;/projects/&lt;name_project&gt;/requirements/?fields=id,name,description,user-03,user-template-18</p>
<p>With the previous url, I obtain via url navigator all these fields of a concrete id available in corporate HPE ALM. My final goal is to achieve how to implement/execute the next sql in my code project.</p>
<p>If I execute directly the next sql in HP ALM console, returns correctly the desired requirements of a concrete target version:
select id,name,description,user-03,user-template-18
from req
where type_id = '108'
and user-template-18 = '&lt;version_target&gt;'</p>
<p>Could anyone specify how to implement the code to obtain all the requirements executing the previous sql of a concrete target version in a c# project?</p>
<p>Thanks in advance
Regards</p>
","<c#><api><rest><alm><requirements>","2020-12-02 14:50:15","123","0","1","65208961","<p>I've developed the next method to obtain all requirements for a concrete target version of HP ALM (&lt;target_version&gt;) and I've an error in the line XmlSerializer.</p>
<p>Could you confirm which error exists in attached code?</p>
<p>public Entity LoginAlm (string url, string username, string password, string domain, string project, string targetVersion)
{</p>
<pre><code>        var client = new RestClient(url + &quot;/qcbin/&quot;);
        client.Authenticator = new HttpBasicAuthenticator(username, password);
        client.CookieContainer = new System.Net.CookieContainer();
        var Domain = domain;
        var Project = project;

        var getItems1 = new RestRequest(&quot;authentication-point/authenticate&quot;);
        IRestResponse response1 = client.Execute(getItems1);

        var getItems2 = new RestRequest(&quot;rest/site-session&quot;, Method.GET);
        IRestResponse response2 = client.Execute(getItems2);

        string sql = &quot;select id,name,description,user-03,user-31,user-template-03,father-name &quot; +
            &quot;from req where type_id = '108' and user-template-18 = '&lt;target_version&gt;'&quot;;

        var getReqs = new RestRequest(&quot;rest/domains/&quot; + Domain + &quot;/projects/&quot; + Project + &quot;/requirements?query=[{&quot; + sql + '}' + ']');

        getReqs.AddHeader(&quot;Content-Type&quot;, &quot;application/xml&quot;);
        getReqs.AddHeader(&quot;Accept&quot;, &quot;application/xml&quot;);

        getReqs.AddParameter(&quot;domain&quot;, Domain, ParameterType.UrlSegment);
        getReqs.AddParameter(&quot;project&quot;, Project, ParameterType.UrlSegment);

        IRestResponse response = client.Execute(getReqs);

        var reader = new StringReader(response.Content);
        var serializer = new XmlSerializer(typeof(Entity));
        var instance = (Entity)serializer.Deserialize(reader);

        return instance;//JsonConvert.SerializeObject(instance, Newtonsoft.Json.Formatting.Indented);
        
    }
</code></pre>
"
"64993251","Spyder IDE Version Operating System Requirements","<p>What are the Operating System Requirements for different versions of the Spyder IDE Windows Installer found at <a href=""https://docs.spyder-ide.org/current/installation.html"" rel=""nofollow noreferrer"">https://docs.spyder-ide.org/current/installation.html</a> ?</p>
","<operating-system><version><spyder><requirements>","2020-11-24 19:08:07","2096","0","1","65012822","<p>(<em>Spyder maintainer here</em>) Our Windows installer works on Windows 10 (it probably works on Windows 8.1 too).</p>
<p>You can find the list of our system requirements in the section <em>Running Spyder</em> of our <a href=""https://docs.spyder-ide.org/current/faq.html#running-spyder"" rel=""nofollow noreferrer"">FAQ</a></p>
"
"64991457","Getting subsets of signatures in Alloy","<p>I was wondering if there is a way to extract a subset of a set in a given signature in Alloy.
The extracted set will then be used in the definition of some facts of the model.</p>
<p>Assume the following model:</p>
<pre><code>abstract sig Status{}
one sig Status1 extends Status{}
one sig Status2 extends Status{}

sig A {
     status: one Status
}

sig B {
     setA: set A
}

fun SubsetOfSetAinB [b: B] : set A {
    //have some kind of operation here 
    //that returns a subset of b.setA where b.setA.status in Status1
}

</code></pre>
<p>Thank you for your time.</p>
","<subset><modeling><alloy><requirements>","2020-11-24 17:10:27","98","1","2","64993990","<p>You should be able to get this with a set intersection, like <code>b.setA &amp; Status1.~status</code>.</p>
"
"64991457","Getting subsets of signatures in Alloy","<p>I was wondering if there is a way to extract a subset of a set in a given signature in Alloy.
The extracted set will then be used in the definition of some facts of the model.</p>
<p>Assume the following model:</p>
<pre><code>abstract sig Status{}
one sig Status1 extends Status{}
one sig Status2 extends Status{}

sig A {
     status: one Status
}

sig B {
     setA: set A
}

fun SubsetOfSetAinB [b: B] : set A {
    //have some kind of operation here 
    //that returns a subset of b.setA where b.setA.status in Status1
}

</code></pre>
<p>Thank you for your time.</p>
","<subset><modeling><alloy><requirements>","2020-11-24 17:10:27","98","1","2","65001744","<p>You already gave the answer yourself :-). You only lacked 5 characters:</p>
<pre><code>fun SubsetOfSetAinB [b: B] : set A {
    { x : b.setA | b.setA.status in Status1 }
}
</code></pre>
<p>The enumeration with <code>{ vars | test(vars) }</code>  is incredibly useful for lots of problems.</p>
"
"64890268","Waterfall model","<p>Im thinking about using the waterfall model as my main development methodology for my CS exam. I have experience working with Unified Process, and agile methodolgies such as SCRUM and XP. All of these have clear and structured way to collect either tasks, use cases or user stories. But i cant seem to find the equvilent for the waterfall model.</p>
<p>So my question is, does the waterfall model have any specific way to collect your 'use cases/user stories (or whatever you may call them) - or should i borrow some from ex. UP, and work with use cases?</p>
","<task><project-management><use-case><requirements><waterfall>","2020-11-18 09:25:59","213","1","1","65100314","<p>Waterfall, Unified Process and agile approaches differ in the way the activities are organised:</p>
<ul>
<li>all of them need somehow to cover the full spectrum of software development activities such as to gather requirements,  design the system,  implement its features and test the result and deliver it.</li>
<li>each of them package and combine these activities differently: agile for example favors small iterations that combine all these activities to deliver a software increment, until everything's done.  At the other extreme, waterfall separates these activities one after the other, with a delivery in the end and iteration (back to implementation or back to requirements) only if there's a significant problem.</li>
</ul>
<p>When carrying out these activities, you may use a set of practices that help you to achieve more effectively the result.  Practice sometimes emerge in the context of a method,  but can often be generalized to be used in other contexts.  For example:</p>
<p>In a <a href=""https://en.wikipedia.org/wiki/Waterfall_model"" rel=""nofollow noreferrer"">Waterfall</a> context, requirements are written up-front. This works well only if the requirements are very well known and do not change very often.  In the case of a study project, you may well be in such a situation.</p>
<p>Nowadays, this kind of requirements are documented using the IEEE standard of <a href=""https://en.wikipedia.org/wiki/Software_requirements_specification"" rel=""nofollow noreferrer"">Software Requirement Statements (SRS)</a>. Frequently, the functional part of this document is structured according to <a href=""https://en.wikipedia.org/wiki/Use_case"" rel=""nofollow noreferrer"">use-cases</a> (not necessarily use-case diagrams).  Moreover modern use-cases, the so-called <a href=""https://www.ivarjacobson.com/publications/white-papers/use-case-ebook"" rel=""nofollow noreferrer"">Use-case 2.0</a>, evolved into a more agile practice which allow to gather &quot;user-stories&quot; (user narratives) to make use-case slices that gradually enrich a use-case.  This approach is in fact very similar to user-story mapping (which defines a high level narrative line) that decomposes a narrative line into detailed user-stories.</p>
<p>So yes,  you can borrow any of those techniques, except that waterfall requires everything to be ready upfront.  Since use-cases can be used both in waterfall (traditional use-cases) or agile (use-case 2.0), it's certainly a good base in your context.  For a school work,  an SRS structured according to use-cases would certainly make good impression.  However, if you want a task oriented approach, and if all the requirements are not yet clear, I'd really advise to go for use-case 2.0 or user-story mapping, and avoid waterfall.</p>
"
"64888110","Asp.net core mvc update after approval","<p>I have two tables
one has all the employee information
the second one like log or history for the changes</p>
<p>what I want to do is</p>
<p>the employee can update his information but it will not update the main table unless the manger approve the changes when the manger approve the changes it will update the main table which has all the employee information</p>
<p>how I can do this and please
note that I am beginner
in asp.net core MVC &amp; Entity framework core</p>
<p>Thanks.</p>
","<.net><entity-framework-core><requirements>","2020-11-18 06:25:47","309","3","2","64888227","<p>The easiest is to:</p>
<ol>
<li>Make a 2nd classes in your code, you can inherit from the employee, let's call it EmployeeAproval</li>
<li>When changes are needed to be made then find the latest change request that is not approved and load it, or, copy the employee data in a new EmployeeAproval instance, show that instance in your screen.</li>
<li>Save the changes made to the EmployeeAproval class, EF will save it in the table for you.
4, Notify the manager that he has changes pending (do not bombard managers they do not like to work) if he has no pending approvals.</li>
<li>Manager approves the change then cast the  EmployeeAproval to an Employee instance and save it or find the approved version, copy the changes and save it.</li>
<li>Notify the Employee instance that the changes where approved.</li>
</ol>
<p>That's the easy way.</p>
<p>The hard way is to set am approved DateTime and duplicate the records make sure you join on latest approved entries etc... becomes a maintenance mess as soon as you hand over the code in 3 years ;-)</p>
"
"64888110","Asp.net core mvc update after approval","<p>I have two tables
one has all the employee information
the second one like log or history for the changes</p>
<p>what I want to do is</p>
<p>the employee can update his information but it will not update the main table unless the manger approve the changes when the manger approve the changes it will update the main table which has all the employee information</p>
<p>how I can do this and please
note that I am beginner
in asp.net core MVC &amp; Entity framework core</p>
<p>Thanks.</p>
","<.net><entity-framework-core><requirements>","2020-11-18 06:25:47","309","3","2","64888249","<p>Maybe you can share more details about what you keep in history, might help with information about the status of employees (if they have unsaved data that needs approval and so on)</p>
<p>You can use some intermediate table where to keep unsaved employee data. Then maybe add a flag on the employee, that has unsaved changes (that way also the manager knows which rows are looking for approvals) and once is approved update entry with data from intermediate table.</p>
<p>Would be other options as well, but you need to think what happens if the manager denies the changes. (in the case above, data will not be affected)</p>
"
"64783448","How to check if all packages meet version requirements?","<p>When running a script in Python interpreter, I want to check if I use the following versions:</p>
<pre><code>absl-py==0.1.10
agate==1.6.0
agate-dbf==0.2.0
agate-excel==0.2.1
agate-sql==0.5.2
appnope==0.1.0
</code></pre>
<p>I can for example do this:</p>
<pre><code>if absl-py.__version__ != &quot;0.1.10&quot;:
    logging.error(&quot;update to version == 0.1.10&quot;)
    sys.exit() #
</code></pre>
<p>And repeat for all other packages. Is there a way to iterate through all the specified packages and raise and error when one if the conditions is not met?</p>
","<python><requirements>","2020-11-11 09:09:30","259","0","3","64783676","<p>You can use the following code to check if the packages exist (make sure to create <code>requirements.txt</code> first):</p>
<pre class=""lang-py prettyprint-override""><code>with open(&quot;requirements.txt&quot;) as f:
    packages = f.read().split(&quot;\n&quot;)
    for package in packages:
        package_name, package_version = package.split(&quot;==&quot;)
        package_name = &quot;_&quot;.join(package_name.split(&quot;-&quot;))
        exec(f&quot;&quot;&quot;\
try:
    import {package_name}
except ImportError:
    print(&quot;{package_name} doesn't exist&quot;) 
else:
    if not {package_name}.__version__== '{package_version}': 
        print(f&quot;{package_name} is not up to date&quot;)&quot;&quot;&quot;)
        

</code></pre>
"
"64783448","How to check if all packages meet version requirements?","<p>When running a script in Python interpreter, I want to check if I use the following versions:</p>
<pre><code>absl-py==0.1.10
agate==1.6.0
agate-dbf==0.2.0
agate-excel==0.2.1
agate-sql==0.5.2
appnope==0.1.0
</code></pre>
<p>I can for example do this:</p>
<pre><code>if absl-py.__version__ != &quot;0.1.10&quot;:
    logging.error(&quot;update to version == 0.1.10&quot;)
    sys.exit() #
</code></pre>
<p>And repeat for all other packages. Is there a way to iterate through all the specified packages and raise and error when one if the conditions is not met?</p>
","<python><requirements>","2020-11-11 09:09:30","259","0","3","64783877","<p>You can do something like this and define the modules and versions in a dictionary:</p>
<pre><code>import pkg_resources

module_versions = {&quot;absl-py&quot;:&quot;0.1.10&quot;, &quot;agate&quot;:&quot;1.6.0&quot;}

for module, v_req in module_versions.items():
    try:
        if pkg_resources.get_distribution(module).version != v_req:
            print(f&quot;{module}, Required Version: {v_req}, Your Version: {v_inst}&quot;)
    except:
        print(f&quot;{module} not installed&quot;)
</code></pre>
"
"64783448","How to check if all packages meet version requirements?","<p>When running a script in Python interpreter, I want to check if I use the following versions:</p>
<pre><code>absl-py==0.1.10
agate==1.6.0
agate-dbf==0.2.0
agate-excel==0.2.1
agate-sql==0.5.2
appnope==0.1.0
</code></pre>
<p>I can for example do this:</p>
<pre><code>if absl-py.__version__ != &quot;0.1.10&quot;:
    logging.error(&quot;update to version == 0.1.10&quot;)
    sys.exit() #
</code></pre>
<p>And repeat for all other packages. Is there a way to iterate through all the specified packages and raise and error when one if the conditions is not met?</p>
","<python><requirements>","2020-11-11 09:09:30","259","0","3","64784094","<p>You can receive the list of the installed packages using setuptools' <a href=""https://setuptools.readthedocs.io/en/latest/pkg_resources.html"" rel=""nofollow noreferrer""><code>pkg_resources</code></a>:</p>
<pre><code>import pkg_resources
package_versions = {
    p.project_name: p.version for p in pkg_resources.working_set
}
</code></pre>
<p>Now you can iterate through your file and compare the versions in it with those in the <code>package_versions</code> dict.</p>
"
"64712007","Update objects from two modules with same attribute in DOORS","<p>I have one module with objects that have the attribute <em>customer ID</em>.
I have new module, with updated data, which was an import from PDF to DOORS using ReqMan.</p>
<p>Now I want to update the first module with data from the new module. The <em>customer ID</em> attribute is equal in both modules, but I cannot find a way in DOORS to do a sort of VLOOKUP to look for the <em>customer ID</em> and update the <em>Object Text</em> on the base module.</p>
<p>Preferably I would like to do it without DXL.</p>
","<requirements><ibm-doors><ibm-rational><requirements-management>","2020-11-06 09:30:01","577","0","2","64712561","<p>(modify the following instructions as needed - I describe my favorite settings here)</p>
<p>Use spreadsheet import and export, preferably Tab separated.
For export, create a view which does NOT contain Absolute Number nor the main column, but all the data you want to modify plus customer ID. Ensure that the labels of the columns are identical to the attribute names.</p>
<p>In the generated text file, you can change the attributes for existing rows and you can add new rows with customer IDs that do not yet exist in the module. Make sure that the first line contains the attribute names.</p>
<p>After you updated your text file, open the module and choose File -&gt; Import -&gt; Spreadsheet with the following settings :</p>
<ul>
<li>Import to attributes: by column labes</li>
<li>Import options: Update existing objects</li>
<li>Update: All Objects</li>
<li>Data separator: Tab</li>
<li>Input file: the full path to your .tsv file</li>
<li>Advanced: check that the columns in the first row correspond to your attribute names</li>
<li>set the correct encoding</li>
<li>press Import</li>
<li>there should be no question  &quot;create new attribute?&quot;</li>
<li>In the dialog &quot;Select key&quot;, select &quot;customer ID&quot; as the &quot;column/attribute that uniquely identifies the objects&quot;.</li>
<li>press &quot;Select&quot;</li>
<li>check the result, save the module only if everything looks correct.</li>
</ul>
"
"64712007","Update objects from two modules with same attribute in DOORS","<p>I have one module with objects that have the attribute <em>customer ID</em>.
I have new module, with updated data, which was an import from PDF to DOORS using ReqMan.</p>
<p>Now I want to update the first module with data from the new module. The <em>customer ID</em> attribute is equal in both modules, but I cannot find a way in DOORS to do a sort of VLOOKUP to look for the <em>customer ID</em> and update the <em>Object Text</em> on the base module.</p>
<p>Preferably I would like to do it without DXL.</p>
","<requirements><ibm-doors><ibm-rational><requirements-management>","2020-11-06 09:30:01","577","0","2","64712710","<pre><code>Object ob, ob1
Module m = current // First module

string s=&quot;/Training Car Project/Stakeholder Requirements&quot; //Give full path of your second module

Module mod=read(s,false)

for ob in m do
{
for ob1 in mod do
{
if((ob.&quot;customer ID&quot;&quot;&quot; = ob1.&quot;customer ID&quot;&quot;&quot;) &amp;&amp; (ob.&quot;Object Text&quot;&quot;&quot; != ob1.&quot;Object Text&quot;&quot;&quot;))
{
ob.&quot;Object Text&quot;&quot;&quot; = ob1.&quot;Object Text&quot;&quot;&quot;
}
}
}
</code></pre>
"
"63651256","PIP install version problems on Mac OS","<p>I am trying to install several dependencies for a python project from a requirements.txt file.</p>
<p>When it encounters the &quot;torch&quot; dependency, it claims to be unable to find version 1.3.1 -- but only on my Mac and not on Ubuntu, which is puzzling. (using a different version like 1.4 is not an option for this project, unfortunately)</p>
<p>On my Mac:</p>
<pre><code>➜  code mkdir test_proj
➜  code cd test_proj
➜  test_proj mkvirtualenv $(basename $(pwd))
created virtual environment CPython3.8.5.final.0-64 in 304ms
  creator CPython3Posix(dest=/Users/aeb/.virtualenvs/test_proj, clear=False, global=False)
  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/Users/aeb/Library/Application Support/virtualenv)
    added seed packages: pip==20.2.2, setuptools==49.6.0, wheel==0.35.1
  activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator
virtualenvwrapper.user_scripts creating /Users/aeb/.virtualenvs/test_proj/bin/predeactivate
virtualenvwrapper.user_scripts creating /Users/aeb/.virtualenvs/test_proj/bin/postdeactivate
virtualenvwrapper.user_scripts creating /Users/aeb/.virtualenvs/test_proj/bin/preactivate
virtualenvwrapper.user_scripts creating /Users/aeb/.virtualenvs/test_proj/bin/postactivate
virtualenvwrapper.user_scripts creating /Users/aeb/.virtualenvs/test_proj/bin/get_env_details
(test_proj) ➜  test_proj which python
/Users/aeb/.virtualenvs/test_proj/bin/python
(test_proj) ➜  test_proj which pip
/Users/aeb/.virtualenvs/test_proj/bin/pip
(test_proj) ➜  test_proj pip install torch==1.3.1
ERROR: Could not find a version that satisfies the requirement torch==1.3.1 (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2, 1.4.0, 1.5.0, 1.5.1, 1.6.0)
ERROR: No matching distribution found for torch==1.3.1
(test_proj) ➜  test_proj
</code></pre>
<p>Interestingly, within an Ubuntu VM, there is no issue with the same pip install command:</p>
<pre><code>user@devbox-vm2:~$ pip3 install torch==1.3.1
Collecting torch==1.3.1
  Using cached https://files.pythonhosted.org/packages/88/95/90e8c4c31cfc67248bf944ba42029295b77159982f532c5689bcfe4e9108/torch-1.3.1-cp36-cp36m-manylinux1_x86_64.whl
</code></pre>
<p>Does anyone <strong>know why the mac version of pip is having trouble finding this specific version of PyTorch, but Ubuntu is not having the same problem</strong> and completes successfully?</p>
<p>Perhaps more to the point, <strong>is there a way to &quot;point&quot; the Mac version of pip to the same package file that the Ubuntu VM</strong> is using, since that seems to be working (or an analogous <strong>modification I can make to the requirements.txt file so that it works on Mac</strong>, and not just on Ubuntu)?</p>
<p>Many thanks!</p>
","<python><macos><pip><virtualenv><requirements>","2020-08-29 20:00:04","939","2","2","63651345","<p><a href=""https://pypi.org/project/torch/1.3.1/#files"" rel=""nofollow noreferrer""><code>torch</code> 1.3.1</a> doesn't provide wheels for Python 3.8 so your Python on Mac cannot install it. On Ubuntu you use Python 3.6 so <code>pip</code> on Ubuntu can install this version.</p>
<p>Use Python 3.6 or 3.7 on Mac.</p>
"
"63651256","PIP install version problems on Mac OS","<p>I am trying to install several dependencies for a python project from a requirements.txt file.</p>
<p>When it encounters the &quot;torch&quot; dependency, it claims to be unable to find version 1.3.1 -- but only on my Mac and not on Ubuntu, which is puzzling. (using a different version like 1.4 is not an option for this project, unfortunately)</p>
<p>On my Mac:</p>
<pre><code>➜  code mkdir test_proj
➜  code cd test_proj
➜  test_proj mkvirtualenv $(basename $(pwd))
created virtual environment CPython3.8.5.final.0-64 in 304ms
  creator CPython3Posix(dest=/Users/aeb/.virtualenvs/test_proj, clear=False, global=False)
  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/Users/aeb/Library/Application Support/virtualenv)
    added seed packages: pip==20.2.2, setuptools==49.6.0, wheel==0.35.1
  activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator
virtualenvwrapper.user_scripts creating /Users/aeb/.virtualenvs/test_proj/bin/predeactivate
virtualenvwrapper.user_scripts creating /Users/aeb/.virtualenvs/test_proj/bin/postdeactivate
virtualenvwrapper.user_scripts creating /Users/aeb/.virtualenvs/test_proj/bin/preactivate
virtualenvwrapper.user_scripts creating /Users/aeb/.virtualenvs/test_proj/bin/postactivate
virtualenvwrapper.user_scripts creating /Users/aeb/.virtualenvs/test_proj/bin/get_env_details
(test_proj) ➜  test_proj which python
/Users/aeb/.virtualenvs/test_proj/bin/python
(test_proj) ➜  test_proj which pip
/Users/aeb/.virtualenvs/test_proj/bin/pip
(test_proj) ➜  test_proj pip install torch==1.3.1
ERROR: Could not find a version that satisfies the requirement torch==1.3.1 (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2, 1.4.0, 1.5.0, 1.5.1, 1.6.0)
ERROR: No matching distribution found for torch==1.3.1
(test_proj) ➜  test_proj
</code></pre>
<p>Interestingly, within an Ubuntu VM, there is no issue with the same pip install command:</p>
<pre><code>user@devbox-vm2:~$ pip3 install torch==1.3.1
Collecting torch==1.3.1
  Using cached https://files.pythonhosted.org/packages/88/95/90e8c4c31cfc67248bf944ba42029295b77159982f532c5689bcfe4e9108/torch-1.3.1-cp36-cp36m-manylinux1_x86_64.whl
</code></pre>
<p>Does anyone <strong>know why the mac version of pip is having trouble finding this specific version of PyTorch, but Ubuntu is not having the same problem</strong> and completes successfully?</p>
<p>Perhaps more to the point, <strong>is there a way to &quot;point&quot; the Mac version of pip to the same package file that the Ubuntu VM</strong> is using, since that seems to be working (or an analogous <strong>modification I can make to the requirements.txt file so that it works on Mac</strong>, and not just on Ubuntu)?</p>
<p>Many thanks!</p>
","<python><macos><pip><virtualenv><requirements>","2020-08-29 20:00:04","939","2","2","63651386","<p>When you look at the <a href=""https://pypi.org/project/torch/1.3.1/#files"" rel=""nofollow noreferrer"">list of files available</a> for that version of Torch, you can see that:</p>
<ul>
<li>There is no source distribution (which would generally be a <code>.tar.gz</code>) version that you would be able to recompile;</li>
<li>All available binary distributions target either:
<ul>
<li><code>manylinux1</code> is a tag that works on many linux versions, that can be pretty old - it is not surprising that it would work on Ubuntu, with Python 2.7, 3.5, 3.6 or 3.7;</li>
<li>Mac OS 10.6 with Python 3.5, or Mac OS 10.7 with Python 2.7, 3.6, or 3.7 - these builds would probably work on later versions of Mac OS, provided the version of Python matches;</li>
</ul>
</li>
</ul>
<p>In particular, none of these distributions can run on Python 3.8, which is the version of Python shown by your console output.</p>
"
"63432212","Change data requirements of an input field based on the value of a select field in a web form","<p>I am working on a web form that includes a select drop down with two options: &quot;Cedula&quot; (in English, &quot;Identification&quot;) and &quot;Pasaporte&quot; (in English, &quot;Passport&quot;).</p>
<p><a href=""https://i.stack.imgur.com/3Nm6W.png"" rel=""nofollow noreferrer"">Here</a> is an image of my web form so far.</p>
<p>Please help me achieve the following goal: when the user selects &quot;Cedula&quot;, they are limited to 10 digits, but when they select &quot;Pasaporte, they are not limited to 10 digits.</p>
<p>Here is my code so far:</p>
<pre><code>&lt;?php
if ($_GET['id']) {
    $cliente = $clienteNegocio-&gt;recuperar($_GET['id']);
    $txtAction = 'Editar';          
}else{
    $cliente = new cliente();
    $txtAction = 'Agregar';
}

?&gt;
&lt;div class=&quot;container&quot;&gt;
  &lt;div class=&quot;page-header&quot;&gt;
    &lt;h1&gt;&lt;?php echo $txtAction; ?&gt; Cliente&lt;/h1&gt;
  &lt;/div&gt;
    &lt;form role=&quot;form&quot; method=&quot;post&quot; id=&quot;principal&quot;&gt;
        &lt;input type=&quot;hidden&quot; name=&quot;id&quot; value=&quot;&lt;?php echo $cliente-&gt;getId();?&gt;&quot; &gt;
        
        &lt;div class=&quot;form-group&quot;&gt;
            &lt;label for=&quot;nombre&quot;&gt;Nombre&lt;/label&gt;
            &lt;input type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;nombre&quot; name=&quot;nombre&quot; placeholder=&quot;Nombre&quot; value=&quot;&lt;?php echo $cliente-&gt;getNombre();?&gt;&quot; required&gt;
            &lt;div class=&quot;help-block with-errors&quot;&gt;&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class=&quot;form-group&quot;&gt;
            &lt;label for=&quot;apellido&quot;&gt;Apellidos&lt;/label&gt;
            &lt;input type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;apellido&quot; name=&quot;apellido&quot; placeholder=&quot;Apellido&quot; value=&quot;&lt;?php echo $cliente-&gt;getApellido();?&gt;&quot; required&gt;
            &lt;div class=&quot;help-block with-errors&quot;&gt;&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class=&quot;form-group&quot;&gt;
            &lt;label for=&quot;tipoDoc&quot;&gt;Tipo de Documento&lt;/label&gt;
            &lt;select class=&quot;form-control&quot; id=&quot;tipoDoc&quot; name=&quot;tipoDoc&quot;&gt;
                &lt;option value=&quot;Cedula&quot;  &lt;?php if($cliente-&gt;getTipoDoc() == 'Cedula') {echo &quot;selected&quot;;} ?&gt;  &gt;Cedula&lt;/option&gt;
                &lt;option value=&quot;Pasaporte&quot; &lt;?php if($cliente-&gt;getTipoDoc() == 'Pasaporte') {echo &quot;selected&quot;;} ?&gt; &gt;Pasaporte&lt;/option&gt;
            &lt;/select&gt;
        &lt;/div&gt;
        &lt;div class=&quot;form-group&quot;&gt;
            &lt;label for=&quot;nroDoc&quot;&gt;Numero de Documento&lt;/label&gt;
            &lt;input type=&quot;number&quot; class=&quot;form-control&quot; id=&quot;nroDoc&quot; maxlength=10 oninput=&quot;if(this.value.length &gt; this.maxLength) this.value = this.value.slice(0, this.maxLength);&quot;
             name=&quot;nroDoc&quot; placeholder=&quot;Numero de Documento&quot; value=&quot;&lt;?php echo $cliente -&gt;getNroDoc();?&gt;&quot; required&gt;
            &lt;div class=&quot;help-block with-errors&quot;&gt;&lt;/div&gt;
        &lt;/div&gt;
</code></pre>
","<php>","2020-08-16 01:08:15","90","0","1","63432384","<p>There you go.</p>
<p>I have written a javascript function to check the length with you select Pasaporte/Cedula.</p>
<p>Secondly, in <code>&lt;input type = &quot;number&quot;/&gt;</code> you cannot set maxLength. Hence you have to set <code>&lt;input type = &quot;text&quot; /&gt;</code>. Also, an <code>onKeyPress</code> event to verify the input as number</p>
<pre><code>&lt;?php
if ($_GET['id']) {
    $cliente = $clienteNegocio-&gt;recuperar($_GET['id']);
    $txtAction = 'Editar';          
}else{
    $cliente = new cliente();
    $txtAction = 'Agregar';
}

?&gt;

&lt;script&gt;
function setMaxLength(){
    var inputVal = document.getElementById(&quot;tipoDoc&quot;)
    var selIndex = inputVal.options[inputVal.selectedIndex].value
    var inputNum = document.getElementById(&quot;nroDoc&quot;);


    if( selIndex === &quot;Cedula&quot;){

        inputNum.maxLength = 10
        selIndex.substr(0, 9);
        inputNum.value = inputNum.value.substr(0, 9);

    } else{

        // Set your own limit here
        // if selIndex === &quot;Pasaporte&quot;
        inputNum.maxLength = 20
    }
}
&lt;/script&gt;


&lt;div class=&quot;container&quot;&gt;
  &lt;div class=&quot;page-header&quot;&gt;
    &lt;h1&gt;&lt;?php echo $txtAction; ?&gt; Cliente&lt;/h1&gt;
  &lt;/div&gt;
    &lt;form role=&quot;form&quot; method=&quot;post&quot; id=&quot;principal&quot;&gt;
        &lt;input type=&quot;hidden&quot; name=&quot;id&quot; value=&quot;&lt;?php echo $cliente-&gt;getId();?&gt;&quot; &gt;
        
        &lt;div class=&quot;form-group&quot;&gt;
            &lt;label for=&quot;nombre&quot;&gt;Nombre&lt;/label&gt;
            &lt;input type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;nombre&quot; name=&quot;nombre&quot; placeholder=&quot;Nombre&quot; value=&quot;&lt;?php echo $cliente-&gt;getNombre();?&gt;&quot; required&gt;
            &lt;div class=&quot;help-block with-errors&quot;&gt;&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class=&quot;form-group&quot;&gt;
            &lt;label for=&quot;apellido&quot;&gt;Apellidos&lt;/label&gt;
            &lt;input type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;apellido&quot; name=&quot;apellido&quot; placeholder=&quot;Apellido&quot; value=&quot;&lt;?php echo $cliente-&gt;getApellido();?&gt;&quot; required&gt;
            &lt;div class=&quot;help-block with-errors&quot;&gt;&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class=&quot;form-group&quot;&gt;
            &lt;label for=&quot;tipoDoc&quot;&gt;Tipo de Documento&lt;/label&gt;
            &lt;select class=&quot;form-control&quot; id=&quot;tipoDoc&quot; name=&quot;tipoDoc&quot; onChange=&quot;setMaxLength()&quot;&gt;
                &lt;option value=&quot;Cedula&quot;  &lt;?php if($cliente-&gt;getTipoDoc() == 'Cedula') {echo &quot;selected&quot;;} ?&gt;  &gt;Cedula&lt;/option&gt;
                &lt;option value=&quot;Pasaporte&quot; &lt;?php if($cliente-&gt;getTipoDoc() == 'Pasaporte') {echo &quot;selected&quot;;} ?&gt; &gt;Pasaporte&lt;/option&gt;
            &lt;/select&gt;
        &lt;/div&gt;
        &lt;div class=&quot;form-group&quot;&gt;
            &lt;label for=&quot;nroDoc&quot;&gt;Numero de Documento&lt;/label&gt;
            &lt;!-- 
                Here onKeyPress method is used to check if the input is a number
                in &lt;input type = &quot;number&quot;/&gt; you cannot set maxLength
                hence you have to set &lt;input type = &quot;text&quot; /&gt;
            --&gt;
            &lt;input type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;nroDoc&quot; maxlength=10 onkeypress=&quot;if ( isNaN(this.value + String.fromCharCode(event.keyCode) )) return false;&quot;
             name=&quot;nroDoc&quot; placeholder=&quot;Numero de Documento&quot; value=&quot;&lt;?php echo $cliente -&gt;getNroDoc();?&gt;&quot; required&gt;
            &lt;div class=&quot;help-block with-errors&quot;&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/form&gt;
&lt;/div&gt;
</code></pre>
"
"63228853","UML: How to reduce use cases for user accounts system to avoid redundancy and unnecessary use cases?","<p>I need help to reduce the use cases on my subsystem.</p>
<p>This subsystem is about manage multiple accounts for users, administrators and a superuser with the following requirements:</p>
<blockquote>
<p>The system shall manage users accounts, where there are:</p>
<ul>
<li><p>Users: can create, read, update, delete and block their own accounts, also login.</p>
<p>Create needs email authentication. Login should ask for 2-step auth (optional)</p>
</li>
<li><p>Admins: can manage all users accounts (CRUD, block and login) as a user. Also read only and login their own account.</p>
<p>Login needs 2 step authentication.</p>
</li>
<li><p>Superuser: can manage both users and admin accounts (CRUD, block, logins) and their own superuser account.</p>
<p>Create admin needs email &amp; phone auth.<br>
Login is same as admins, needs 2 step auth.<br>
Can delegate the superuser access to another admin.</p>
</li>
</ul>
</blockquote>
<p>The system's flow need to be clear just with use case diagram and use case descriptions (without other type of diagram)</p>
<p><strong>What is the right way to design these use cases to avoid redundacy on use case descriptions and make unnecessary use cases on diagram?</strong></p>
<p>For example, on this system, the user, admin, and superuser have a Login Use Case each one. User Login ask for 2 step auth (optional) while on admin and superuser the 2 step auth must be always required.</p>
<p>SuperUser inherits from Admin who inherits from User.</p>
<p><em>The final goal I am looking for is to make (for instance) these 3 login uses cases into one that connects to the User Actor only so Admin and SuperUser inherit the use case but, due to the behavior is different for every Actor, I want to put one Login Use Case Description which changes the behavior according to the Actor type who triggers the Login. So instead of have 3 Login Use Cases (one for each actor), I have just 1 use case and 1 description that works for all.</em></p>
","<uml><software-design><use-case><requirements><use-case-diagram>","2020-08-03 11:47:08","406","0","1","63237966","<p>What you seem to look for is the parametrised use-cases, which is a concept promoted by Alistair Cockburn for textual use-cases.</p>
<p>The typical example is CRUD when the same use-case description is used over and over again with a slight variant for each operation. The approach is the to have a parametrised use case where the parameter is the operation (create, read, update, delete).</p>
<p>The same concept doesn’t exist in UML notation as far as I know. So you would typically have either a use case <code>Manage XYZ</code> and describe the details in the narratives, or the four use-cases <code>Create XYZ</code>, <code>Update XYZ</code>, <code>Delete XYZ</code>, <code>Read XYZ</code>. Personally I prefer the first, so that the use-case convey the big picture.</p>
<p>Instead of multiplying the same use-cases for the different actors, you could also use less use-cases and use <a href=""https://www.uml-diagrams.org/constraint.html"" rel=""nofollow noreferrer"">contraints</a> to explain in plain text the special rules that apply to the  different categories of actors for the different use-cases.</p>
<p>Finally, I’d like to add that use-cases are not meant to model flows and sequence of events. Use cases are meant to identify different goals  that would translate to different kind of interactions. In this regard I  wonder if it could  make sense to distinguish <code>Manage own account</code> and <code>Manage other user account</code> since this correspond to very different goals.</p>
"
"63163058","Collecting numpy causes docker build to crash","<p>I'm trying to deploy a little python script using Selenium on my GCP Virtual Machine following <a href=""https://towardsdatascience.com/build-a-scalable-web-crawler-with-selenium-and-pyhton-9c0c23e3ebe5"" rel=""nofollow noreferrer"">this tutorial</a>. Unfortunately, I can't pass the <code>requirements.txt</code> when building the container image. Indeed as one can read:</p>
<pre><code>mikempc3@instance-1:~$ sudo docker build --tag my-python-app .
Sending build context to Docker daemon  387.1MB
Step 1/6 : FROM python:alpine3.7
alpine3.7: Pulling from library/python
48ecbb6b270e: Pull complete 
692f29ee68fa: Pull complete 
6439819450d1: Pull complete 
3c7be240f7bf: Pull complete 
ca4b349df8ed: Pull complete 
Digest: sha256:35f6f83ab08f98c727dbefd53738e3b3174a48b4571ccb1910bae480dcdba847
Status: Downloaded newer image for python:alpine3.7
 ---&gt; 00be2573e9f7
Step 2/6 : COPY . /app
 ---&gt; d8ae78db92f8
Step 3/6 : WORKDIR /app
 ---&gt; Running in 3f6269c90e90
Removing intermediate container 3f6269c90e90
 ---&gt; 717897752d1d
Step 4/6 : RUN pip install -r requirements.txt
 ---&gt; Running in 061da28ee5cb
Collecting selenium (from -r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)
Collecting pandas (from -r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/6f/29/32ff85413724ffa7cc8d52373f93c2ef1cb197ffd0c7b1b10d36452dd0ca/pandas-1.1.0.tar.gz (5.2MB)
  Installing build dependencies: started
  Installing build dependencies: finished with status 'error'
  Complete output from command /usr/local/bin/python /usr/local/lib/python3.7/site-packages/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-ou2zb3ns/overlay --no-warn-script-l
ocation --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools wheel Cython&gt;=0.29.16,&lt;3 &quot;numpy==1.15.4; python_version=='3.6' and platform_system!='AIX'&quot; &quot;numpy==1.15.4; 
python_version=='3.7' and platform_system!='AIX'&quot; &quot;numpy==1.17.3; python_version&gt;='3.8' and platform_system!='AIX'&quot; &quot;numpy==1.16.0; python_version=='3.6' and platform_system=='AIX'&quot; &quot;numpy==1.16.0
; python_version=='3.7' and platform_system=='AIX'&quot; &quot;numpy==1.17.3; python_version&gt;='3.8' and platform_system=='AIX'&quot;:
  Ignoring numpy: markers 'python_version == &quot;3.6&quot; and platform_system != &quot;AIX&quot;' don't match your environment
  Ignoring numpy: markers 'python_version &gt;= &quot;3.8&quot; and platform_system != &quot;AIX&quot;' don't match your environment
  Ignoring numpy: markers 'python_version == &quot;3.6&quot; and platform_system == &quot;AIX&quot;' don't match your environment
  Ignoring numpy: markers 'python_version == &quot;3.7&quot; and platform_system == &quot;AIX&quot;' don't match your environment
  Ignoring numpy: markers 'python_version &gt;= &quot;3.8&quot; and platform_system == &quot;AIX&quot;' don't match your environment
  Collecting setuptools
    Downloading https://files.pythonhosted.org/packages/8e/11/9e10f1cad4518cb307b484c255cae61e97f05b82f6d536932b1714e01b47/setuptools-49.2.0-py3-none-any.whl (789kB)
  Collecting wheel
    Downloading https://files.pythonhosted.org/packages/8c/23/848298cccf8e40f5bbb59009b32848a4c38f4e7f3364297ab3c3e2e2cd14/wheel-0.34.2-py2.py3-none-any.whl
  Collecting Cython&lt;3,&gt;=0.29.16
    Downloading https://files.pythonhosted.org/packages/ad/4b/9e53bcce3c959fd0db143626e573210bba07be810fe8d7296373948c4183/Cython-0.29.21-py2.py3-none-any.whl (974kB)
  Collecting numpy==1.15.4
    Downloading https://files.pythonhosted.org/packages/2d/80/1809de155bad674b494248bcfca0e49eb4c5d8bee58f26fe7a0dd45029e2/numpy-1.15.4.zip (4.5MB)
  Building wheels for collected packages: numpy
    Building wheel for numpy (setup.py): started
    Building wheel for numpy (setup.py): finished with status 'error'
    Complete output from command /usr/local/bin/python -u -c &quot;import setuptools, tokenize;__file__='/tmp/pip-install-800mjafl/numpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.rea
d().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))&quot; bdist_wheel -d /tmp/pip-wheel-q_b64mdo --python-tag cp37:
    Running from numpy source directory.
    blas_opt_info:
    blas_mkl_info:
    customize UnixCCompiler
      libraries mkl_rt not found in ['/usr/local/lib', '/usr/lib']
      NOT AVAILABLE
  
    blis_info:
    customize UnixCCompiler
      libraries blis not found in ['/usr/local/lib', '/usr/lib']
      NOT AVAILABLE
  
    openblas_info:
    customize UnixCCompiler
    customize UnixCCompiler
      libraries openblas not found in ['/usr/local/lib', '/usr/lib']
      NOT AVAILABLE
  
    atlas_3_10_blas_threads_info:
    Setting PTATLAS=ATLAS
    customize UnixCCompiler
      libraries tatlas not found in ['/usr/local/lib', '/usr/lib']
      NOT AVAILABLE
  
    atlas_3_10_blas_info:
    customize UnixCCompiler
      libraries satlas not found in ['/usr/local/lib', '/usr/lib']
      NOT AVAILABLE
  
    atlas_blas_threads_info:
    Setting PTATLAS=ATLAS
    customize UnixCCompiler
      libraries ptf77blas,ptcblas,atlas not found in ['/usr/local/lib', '/usr/lib']
      NOT AVAILABLE
  
    atlas_blas_info:
    customize UnixCCompiler
      libraries f77blas,cblas,atlas not found in ['/usr/local/lib', '/usr/lib']
      NOT AVAILABLE
  
    accelerate_info:
      NOT AVAILABLE
  
    /tmp/pip-install-800mjafl/numpy/numpy/distutils/system_info.py:625: UserWarning:
        Atlas (http://math-atlas.sourceforge.net/) libraries not found.
        Directories to search for the libraries can be specified in the
        numpy/distutils/site.cfg file (section [atlas]) or by setting
        the ATLAS environment variable.
      self.calc_info()
    blas_info:
    customize UnixCCompiler
      libraries blas not found in ['/usr/local/lib', '/usr/lib']
      NOT AVAILABLE
    ...
        File &quot;/usr/local/lib/python3.7/distutils/core.py&quot;, line 148, in setup
          dist.run_commands()
        File &quot;/usr/local/lib/python3.7/distutils/dist.py&quot;, line 966, in run_commands
          self.run_command(cmd)
        File &quot;/usr/local/lib/python3.7/distutils/dist.py&quot;, line 985, in run_command
          cmd_obj.run()
        File &quot;/tmp/pip-install-800mjafl/numpy/numpy/distutils/command/install.py&quot;, line 62, in run
          r = self.setuptools_run()
        File &quot;/tmp/pip-install-800mjafl/numpy/numpy/distutils/command/install.py&quot;, line 36, in setuptools_run
          return distutils_install.run(self)
        File &quot;/usr/local/lib/python3.7/distutils/command/install.py&quot;, line 545, in run
          self.run_command('build')
        File &quot;/usr/local/lib/python3.7/distutils/cmd.py&quot;, line 313, in run_command
          self.distribution.run_command(command)
        File &quot;/usr/local/lib/python3.7/distutils/dist.py&quot;, line 985, in run_command
          cmd_obj.run()
        File &quot;/tmp/pip-install-800mjafl/numpy/numpy/distutils/command/build.py&quot;, line 47, in run
          old_build.run(self)
        File &quot;/usr/local/lib/python3.7/distutils/command/build.py&quot;, line 135, in run
          self.run_command(cmd_name)
        File &quot;/usr/local/lib/python3.7/distutils/cmd.py&quot;, line 313, in run_command
          self.distribution.run_command(command)
        File &quot;/usr/local/lib/python3.7/distutils/dist.py&quot;, line 985, in run_command
          cmd_obj.run()
        File &quot;/tmp/pip-install-800mjafl/numpy/numpy/distutils/command/build_src.py&quot;, line 148, in run
          self.build_sources()
        File &quot;/tmp/pip-install-800mjafl/numpy/numpy/distutils/command/build_src.py&quot;, line 159, in build_sources
          self.build_library_sources(*libname_info)
        File &quot;/tmp/pip-install-800mjafl/numpy/numpy/distutils/command/build_src.py&quot;, line 294, in build_library_sources
          sources = self.generate_sources(sources, (lib_name, build_info))
        File &quot;/tmp/pip-install-800mjafl/numpy/numpy/distutils/command/build_src.py&quot;, line 377, in generate_sources
          source = func(extension, build_dir)
        File &quot;numpy/core/setup.py&quot;, line 666, in get_mathlib_info
          raise RuntimeError(&quot;Broken toolchain: cannot link a simple C program&quot;)
      RuntimeError: Broken toolchain: cannot link a simple C program
  
      ----------------------------------------
  Command &quot;/usr/local/bin/python -u -c &quot;import setuptools, tokenize;__file__='/tmp/pip-install-800mjafl/numpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\
n');f.close();exec(compile(code, __file__, 'exec'))&quot; install --record /tmp/pip-record-sgbls4z_/install-record.txt --single-version-externally-managed --prefix /tmp/pip-build-env-ou2zb3ns/overlay -
-compile&quot; failed with error code 1 in /tmp/pip-install-800mjafl/numpy/
  You are using pip version 19.0.1, however version 20.2 is available.
  You should consider upgrading via the 'pip install --upgrade pip' command.
  
  ----------------------------------------
Command &quot;/usr/local/bin/python /usr/local/lib/python3.7/site-packages/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-ou2zb3ns/overlay --no-warn-script-location --no-binary :n
one: --only-binary :none: -i https://pypi.org/simple -- setuptools wheel Cython&gt;=0.29.16,&lt;3 &quot;numpy==1.15.4; python_version=='3.6' and platform_system!='AIX'&quot; &quot;numpy==1.15.4; python_version=='3.7' 
and platform_system!='AIX'&quot; &quot;numpy==1.17.3; python_version&gt;='3.8' and platform_system!='AIX'&quot; &quot;numpy==1.16.0; python_version=='3.6' and platform_system=='AIX'&quot; &quot;numpy==1.16.0; python_version=='3.7
' and platform_system=='AIX'&quot; &quot;numpy==1.17.3; python_version&gt;='3.8' and platform_system=='AIX'&quot;&quot; failed with error code 1 in None
You are using pip version 19.0.1, however version 20.2 is available.
You should consider upgrading via the 'pip install --upgrade pip' command.
The command '/bin/sh -c pip install -r requirements.txt' returned a non-zero code: 1
</code></pre>
<p>Here is my requirements.txt file:</p>
<pre><code>selenium
pandas
numpy
collections
json
time
requests
</code></pre>
<p>And here is the file I'm trying to contenerize:</p>
<pre><code>from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import ElementClickInterceptedException
from selenium.common.exceptions import NoSuchElementException
from selenium.webdriver.chrome.options import Options



import pandas as pd
import numpy as np

from collections import defaultdict
import json

import time

import requests
from requests.exceptions import ConnectionError

# Define Browser Options
chrome_options = Options()
chrome_options.add_argument(&quot;--headless&quot;) # Hides the browser window

# Reference the local Chromedriver instance
chrome_path = r&quot;C:\Programs\chromedriver.exe&quot;
driver = webdriver.Chrome(executable_path=chrome_path, options=chrome_options)

df = pd.read_csv('path/to/file')    

tradable = []
print(len(df['Ticker']))
for ticker in df['Ticker']:
    print(&quot;ticker: &quot;, ticker)
    location = &quot;https://www.etoro.com/markets/&quot; + ticker.lower()
    try:
        request = requests.get(location)
        driver.get(location)
        time.sleep(2)
        current_url = driver.current_url
        if current_url == location:
            tradable.append(ticker)
        else:
            print(&quot;no page but request= &quot;, request)
    except ConnectionError:
        print('Ticker isn\'t tradable')
    else:
        tradable.append(ticker)
</code></pre>
<p>Here is my  Dockerfile:</p>
<pre><code>FROM python:alpine3.7
COPY . /app
WORKDIR /app
RUN pip install -r requirements.txt
EXPOSE 5000
CMD python ./find_tradable.py
</code></pre>
<p>Here are my os name and version:</p>
<pre><code>mikempc3@instance-1:~$ cat /etc/os-release
PRETTY_NAME=&quot;Debian GNU/Linux 9 (stretch)&quot;
NAME=&quot;Debian GNU/Linux&quot;
VERSION_ID=&quot;9&quot;
VERSION=&quot;9 (stretch)&quot;
VERSION_CODENAME=stretch
ID=debian
HOME_URL=&quot;https://www.debian.org/&quot;
SUPPORT_URL=&quot;https://www.debian.org/support&quot;
BUG_REPORT_URL=&quot;https://bugs.debian.org/&quot;
</code></pre>
<p>Here is my Linux kernel version:</p>
<pre><code>mikempc3@instance-1:~$ uname -r
4.9.0-12-amd64
</code></pre>
<h1>Update</h1>
<p>I'm trying Serhii Rohoza's answer.</p>
<p>I have updated my requirements.txt file, I don't have the same issue but now I have an error when trying the command to build the image from the Dockerfile:</p>
<pre><code>mikempc3@instance-1:~$ sudo docker build --tag my-python-app:1 .
Sending build context to Docker daemon  387.1MB
Step 1/6 : FROM python:python3.7-slim
manifest for python:python3.7-slim not found: manifest unknown: manifest unknown
</code></pre>
<p>So I tried:</p>
<pre><code>mikempc3@instance-1:~$ sudo docker pull python:3.7-slim
3.7-slim: Pulling from library/python
6ec8c9369e08: Already exists 
401b5acb42e6: Already exists 
2e487de6656a: Pull complete 
519de614852e: Pull complete 
a3d1a61e090c: Pull complete 
Digest: sha256:47081c7bca01b314e26c64d777970d46b2ad7049601a6f702d424881af9f2738
Status: Downloaded newer image for python:3.7-slim
docker.io/library/python:3.7-slim
mikempc3@instance-1:~$ sudo docker build --tag my-python-app:1 .
Sending build context to Docker daemon  387.1MB
Step 1/6 : FROM python:python3.7-slim
manifest for python:python3.7-slim not found: manifest unknown: manifest unknown
</code></pre>
","<python-3.x><docker><google-cloud-platform><requirements>","2020-07-29 21:58:15","822","0","1","63175982","<p><strong>To solve your issue</strong> you should use Debian based image:</p>
<p>To build Docker image I removed <code>collections</code> (which is <a href=""https://docs.python.org/3.7/library/collections.html"" rel=""nofollow noreferrer"">deprecated</a>), <code>json</code> (it's built in) and <code>time</code> (it's built in) from <code>requirements.txt</code> and changed  <code>Dockerfile</code>:</p>
<pre><code>$ cat Dockerfile 
FROM python:3.7-slim
COPY . /app
WORKDIR /app
RUN pip install -r requirements.txt
EXPOSE 5000
CMD python ./find_tradable.py

$ cat requirements.txt
selenium
pandas
numpy
requests

$ sudo docker build --tag my-python-app:1 .
Sending build context to Docker daemon   5.12kB
Step 1/6 : FROM python:3.7-slim
 ---&gt; c042d3af0838
Step 2/6 : COPY . /app
 ---&gt; ddb4662cd16f
Step 3/6 : WORKDIR /app
 ---&gt; Running in 24e1a60ce53c
Removing intermediate container 24e1a60ce53c
 ---&gt; 5db1f089513b
Step 4/6 : RUN pip install -r requirements.txt
 ---&gt; Running in 5cdde4c11b10
Collecting selenium
  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)
Collecting pandas
  Downloading pandas-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (10.5 MB)
Collecting numpy
  Downloading numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)
Collecting requests
  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)
Collecting urllib3
  Downloading urllib3-1.25.10-py2.py3-none-any.whl (127 kB)
Collecting python-dateutil&gt;=2.7.3
  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)
Collecting pytz&gt;=2017.2
  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)
Collecting idna&lt;3,&gt;=2.5
  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)
Collecting chardet&lt;4,&gt;=3.0.2
  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)
Collecting certifi&gt;=2017.4.17
  Downloading certifi-2020.6.20-py2.py3-none-any.whl (156 kB)
Collecting six&gt;=1.5
  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)
Installing collected packages: urllib3, selenium, six, python-dateutil, numpy, pytz, pandas, idna, chardet, certifi, requests
Successfully installed certifi-2020.6.20 chardet-3.0.4 idna-2.10 numpy-1.19.1 pandas-1.1.0 python-dateutil-2.8.1 pytz-2020.1 requests-2.24.0 selenium-3.141.0 six-1.15.0 urllib3-1.25.10
WARNING: You are using pip version 20.1.1; however, version 20.2 is available.
You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.
Removing intermediate container 5cdde4c11b10
 ---&gt; 94dd7203a37c
Step 5/6 : EXPOSE 5000
 ---&gt; Running in 3f24bb8b62f5
Removing intermediate container 3f24bb8b62f5
 ---&gt; 3bed65d447d6
Step 6/6 : CMD python ./find_tradable.py
 ---&gt; Running in 35c0601f2c70
Removing intermediate container 35c0601f2c70
 ---&gt; af17d0675fee
Successfully built af17d0675fee
Successfully tagged my-python-app:1
</code></pre>
<p>As a possible <a href=""https://stackoverflow.com/a/57485724/12428794"">workaround</a>, you can try to install <code>pandas</code> and <code>numpy</code> from packages available in the <a href=""https://pkgs.alpinelinux.org/contents?file=&amp;path=&amp;name=&amp;branch=edge&amp;repo=community&amp;arch=x86"" rel=""nofollow noreferrer"">Alpine repository</a>:</p>
<pre><code>$ cat Dockerfile 
FROM python:alpine3.7
COPY . /app
WORKDIR /app
RUN echo &quot;http://dl-8.alpinelinux.org/alpine/edge/community&quot; &gt;&gt; /etc/apk/repositories
RUN apk add --update --no-cache libgfortran py3-pandas py3-numpy
ENV PYTHONPATH=/usr/lib/python3.7/site-packages
RUN pip install -r requirements.txt
EXPOSE 5000
CMD python ./find_tradable.py

$ cat requirements.txt
selenium
requests

$ sudo docker build --tag my-python-app:2 .
Sending build context to Docker daemon   5.12kB
Step 1/9 : FROM python:alpine3.7
 ---&gt; 00be2573e9f7
Step 2/9 : COPY . /app
 ---&gt; 2d9fe2cb3266
Step 3/9 : WORKDIR /app
 ---&gt; Running in c106bf69643a
Removing intermediate container c106bf69643a
 ---&gt; 807d1d546864
Step 4/9 : RUN echo &quot;http://dl-8.alpinelinux.org/alpine/edge/community&quot; &gt;&gt; /etc/apk/repositories
 ---&gt; Running in 77a65a19f776
Removing intermediate container 77a65a19f776
 ---&gt; 940ce2de1711
Step 5/9 : RUN apk add --update --no-cache libgfortran py3-numpy py3-pandas
 ---&gt; Running in 5084ac4055a2
fetch http://dl-cdn.alpinelinux.org/alpine/v3.7/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.7/community/x86_64/APKINDEX.tar.gz
fetch http://dl-8.alpinelinux.org/alpine/edge/community/x86_64/APKINDEX.tar.gz
(1/11) Installing libgcc (6.4.0-r5)
(2/11) Installing libquadmath (6.4.0-r5)
(3/11) Installing libgfortran (6.4.0-r5)
(4/11) Installing openblas (0.2.19-r3)
(5/11) Installing py3-numpy (1.19.1-r0)
(6/11) Installing python3 (3.6.9-r1)
(7/11) Installing py3-six (1.11.0-r0)
(8/11) Installing py3-dateutil (2.8.1-r0)
(9/11) Installing py3-tz (2017.3-r0)
(10/11) Installing libstdc++ (6.4.0-r5)
(11/11) Installing py3-pandas (1.0.5-r0)
Executing busybox-1.27.2-r11.trigger
OK: 172 MiB in 47 packages
Removing intermediate container 5084ac4055a2
 ---&gt; 3af579bb35da
Step 6/9 : ENV PYTHONPATH=/usr/lib/python3.7/site-packages
 ---&gt; Running in 89513c5c2f02
Removing intermediate container 89513c5c2f02
 ---&gt; 3edc5aa5ef96
Step 7/9 : RUN pip install -r requirements.txt
 ---&gt; Running in a694e49a4fbf
Collecting selenium (from -r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)
Collecting requests (from -r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)
Collecting urllib3 (from selenium-&gt;-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/9f/f0/a391d1463ebb1b233795cabfc0ef38d3db4442339de68f847026199e69d7/urllib3-1.25.10-py2.py3-none-any.whl (127kB)
Collecting chardet&lt;4,&gt;=3.0.2 (from requests-&gt;-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)
Collecting idna&lt;3,&gt;=2.5 (from requests-&gt;-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/a2/38/928ddce2273eaa564f6f50de919327bf3a00f091b5baba8dfa9460f3a8a8/idna-2.10-py2.py3-none-any.whl (58kB)
Collecting certifi&gt;=2017.4.17 (from requests-&gt;-r requirements.txt (line 2))
  Downloading https://files.pythonhosted.org/packages/5e/c4/6c4fe722df5343c33226f0b4e0bb042e4dc13483228b4718baf286f86d87/certifi-2020.6.20-py2.py3-none-any.whl (156kB)
Installing collected packages: urllib3, selenium, chardet, idna, certifi, requests
Successfully installed certifi-2020.6.20 chardet-3.0.4 idna-2.10 requests-2.24.0 selenium-3.141.0 urllib3-1.25.10
You are using pip version 19.0.1, however version 20.2 is available.
You should consider upgrading via the 'pip install --upgrade pip' command.
Removing intermediate container a694e49a4fbf
 ---&gt; c6cee0e65a83
Step 8/9 : EXPOSE 5000
 ---&gt; Running in 0a8738c81f82
Removing intermediate container 0a8738c81f82
 ---&gt; 66b223aa513c
Step 9/9 : CMD python ./find_tradable.py
 ---&gt; Running in 3ca56154d699
Removing intermediate container 3ca56154d699
 ---&gt; 3b5e507c7b4b
Successfully built 3b5e507c7b4b
Successfully tagged my-python-app:2
</code></pre>
"
"63083042","discord.py how to make requirements.txt","<p>finally I made my discord bot now I need to upload it to Heroku so it can be online 24/7. I watched some videos about that. youtube guys were using a simple bot code. and their requirements.txt file be like</p>
<pre><code>discord
</code></pre>
<p>yea literally this because their code is so simple. how do I add my other things into that.</p>
<p>top of my code is like</p>
<pre><code>import discord
from discord.ext import commands
import youtube_dl
from discord import FFmpegPCMAudio
import os
</code></pre>
<p>i dont wanna do smth wrong that I cant fix it later because it happens to me a lot :v</p>
","<python><heroku><bots><discord.py><requirements>","2020-07-25 00:29:16","3734","0","1","63083100","<p>os is a default python package so it doesn't need to be included. Aside from that you only have discord and youtube_dl so place those in your requirements.txt</p>
<pre><code>discord
youtube_dl
</code></pre>
"
"62988451","What would be the better unit to draw state machine diagrams in SRS?","<p>Recently I am working on a SRS documentation for my university project. When I draw the state machine diagrams I'm confused for what parts should I draw it. Is that for the components? or for the classes?</p>
<p>Clearly the inherent state of the object shows in the state diagrams. But, my question is how do we find for what we should draw states. Is that get from the components or classes?</p>
","<uml><state-machine><requirements><state-diagram><system-analysis>","2020-07-20 03:59:00","158","2","1","62992886","<p>An SRS is a <a href=""https://en.wikipedia.org/wiki/Software_requirements_specification"" rel=""nofollow noreferrer"">System Requirement Specification</a>: you document the requirements and not the solution. So the state diagram in the SRS should be <strong>related to the requirements</strong>, whatever they are.</p>
<p>In UML, state-machines are defined for classifiers. They can define event driven behaviors (<a href=""https://www.uml-diagrams.org/state-machine-diagrams.html#behavioral-state-machine"" rel=""nofollow noreferrer"">behavioral state-machine</a>) or the valid set of interactions with the classifier (<a href=""https://www.uml-diagrams.org/protocol-state-machine-diagrams.html#protocol-state-machine"" rel=""nofollow noreferrer"">protocol state-machine</a>).  A <a href=""https://www.uml-diagrams.org/classifier.html"" rel=""nofollow noreferrer"">classifier</a> is typically a class or a component: both are possible.</p>
<p>But in your SRS you don't care:  you don't need to provide an SM for every class or every component; you need to provide an SM only if there are state-related requirements.</p>
<p>Dummy examples:</p>
<blockquote>
<ol>
<li>The user may create a <code>shopping basket</code>, and add <code>items</code> from the <code>catalog</code> to the cart.  Items may also be removed.  The user may view the shopping cart and continue  the purchases.  The user can check-out the shopping cart, and once the <code>payment</code> is completed, <em><strong>no changes shall be possible anymore</strong></em> to the cart.</li>
<li>The <code>controller</code> ignites the rocket booster.  Once the booster fuel level is detected to be empty, the controller activate the decoupling of the booster, and ignites the main engine. Once the booster is succesfully decoupled, the controller shall monitor any variation in altitude.</li>
</ol>
</blockquote>
<p>You'd certainly model 1 with classes, and the constraints about the validity of operations on <code>shopping cart</code> are easily expressed in a state-machine.  This is, by the way, typical for any object that has a life-cycle that is to be tracked.  The other classes seem not to have any interesting state to model.</p>
<p>You'd certainly model 2 with a <code>controller</code> component, and the event-driven set of behaviors are easily and clearly expressed with a state-machine.</p>
<p>So ultimately, you do not care if it is a class or a component.  The only thing that should drive your modelling in the SRS, is if there are behavior or constraints that <em><strong>CAN be expressed more precisely/easily/clearly</strong></em> with a state machine.  Many SRS don't even show any state-machine, because the states emerge only in the design of the solution.</p>
"
"62726398","Sha256 Mismatch for pip install on fresh docker image","<p>I am trying to create a docker image with a bunch of python libraries.</p>
<p>On doing a <code>pip install --no-cache-dir -r requirements.txt</code>, it keeps failing with mismatched hashes for libraries, especially pyspark.</p>
<p>The failure message looks like -</p>
<pre><code>ERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.
    pyspark==2.4.6 from https://files.pythonhosted.org/packages/e9/e4/5c15ab8d354c4e3528510821865e6748209a9b0ff6a1788f4cd36cc2a5dc/pyspark-2.4.6.tar.gz#sha256=b4b319a3ffd187a3019f654ae1c8ac38048bcec2940f8cecdef829302d166feb (from -r requirements.txt (line 4)):
        Expected sha256 b4b319a3ffd187a3019f654ae1c8ac38048bcec2940f8cecdef829302d166feb
             Got        e15b72fe55a366df7329932882c56328874152cf618950c7ce45e11f1c9dc5d1
</code></pre>
<p>Some stuff that I have already tried, consulting other stack overflow threads -</p>
<ol>
<li>Remove <code>__pycache__</code> and <code>~/.cache/</code> directories.</li>
<li>Downgrade pip to 20.0.2, since there were threads saying that this was caused by pip20.1.0</li>
<li>Also tried using <code>--no-cache-dir</code> as you can see.</li>
<li>Build the docker image without caching using - <code>docker build --no-cache . -t labydock-image</code></li>
</ol>
<p>The Dockerfile looks something like this -</p>
<pre><code>FROM python:3.7.7-stretch

USER root
RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends openjdk-8-jdk

WORKDIR /labyrinth
COPY ./dodo.py .
COPY ./requirements.txt .

RUN pip install pip==20.0.2

RUN rm -rf ~/.cache
RUN rm -rf __pycache__

RUN pip install --no-cache-dir -r requirements.txt
</code></pre>
<p>And the corresponding requirements.txt file looks like this -</p>
<pre><code>mockito==1.2.1
py4j==0.10.7
pypandoc==1.5
pyspark==2.4.6
pytest
pandas
doit
koalas
requests
presto-client
mysql-connector-python
</code></pre>
<p>Any help would be highly appreciated. Please let me know if you need more details</p>
","<python><docker><caching><pip><requirements>","2020-07-04 07:14:54","1334","5","1","62737561","<p>After much deliberation, I could figure this out with the help of a colleague.</p>
<p>Our Root cause analysis is as follows - When we download a library, the server itself sends a SHA to be verified post download, to prevent tampering with the library. Now, due to <strong>poor internet</strong> connection, the library was getting corrupted while downloading and hence the sha mismatch happened. It sounds incredibly weird to me since I assumed pip would have detected this failure and prompted that the library download failed.</p>
<p>Anyway, we ran the same docker image on a VM and it worked like a charm.</p>
"
"62657477","Requirements to access IP Camera using OpenCV","<p>I'm new to IP cameras and I know there are quite a lot of topics about this in the forum already, but I can't find a concrete answer for my needs.</p>
<p>I want to access an IP camera using OpenCV in Python from a Windows PC. As I don't have a camera yet, I need to buy one and I can't figure out, what requirements this camera needs to have.</p>
<p>For example, there are quite cheap IP cameras (e.g. Xi****) which say they come with an Android or iOS app and are only accessible via those.</p>
<p>I thought you can access any IP cam via OpenCV, but now I'm not sure anymore... can anyone give me an overview, what specs an IP cam needs, to be accessed via OpenCV on Windows? I don't want to buy a camera and later realize, that I can't access the video stream.</p>
<p>I'm really sorry, if this has already been asked, but I can't find a satisfying answer to this question and Google doesn't seem to be very helpful...</p>
<p>Thanks in advance.</p>
","<opencv><camera><ip><requirements>","2020-06-30 12:28:16","238","0","1","62657778","<p>check for IP cam that can transmit RTSP opencv know how to work with this type of stream.</p>
"
"62546088","Non functional requirements and functional requirement example","<p>I am analyzing Milk teas management website,  that is a web online to help user buys via online and seller can manage their products, orders</p>
<p>I have to do Non-functional requirements and functional requirements for this website like this</p>
<p>FUNCTIONAL REQUIREMENTS</p>
<p>Register</p>
<p>Login</p>
<p>Add products to card</p>
<p>Submit order</p>
<p>Cancel order</p>
<p>NON - FUNCTIONAL REQUIREMENTS</p>
<p>Number of milk tea can be added to the cart</p>
<p>I am right for that? Can you give me some idea for this to let me improve better, I am new for this section, thank you so much</p>
","<requirements>","2020-06-24 01:14:18","1891","4","1","62546520","<h2>Functional Requirements</h2>
<p>Good functional requirements should clearly describe the behavior of the system. Here are some examples:</p>
<ul>
<li>&quot;If the user enters the wrong password 3 times when signing in, the account shall be locked for 24h.&quot;</li>
<li>&quot;When an electronics product is added to the cart, the user shall be presented with an option to purchase a warranty.&quot;</li>
<li>&quot;If a user attempts to cancel an order after it has been processed, the user must specify the reason for the cancellation, which must be approved before a refund is issued&quot;</li>
</ul>
<p>If you want to add more functionality, create more requirements, don't pile them all into one. For example, the last requirement in the above list can be split into 2: (1) require cancellation reason, (2) approval before refund. It also helps to organize requirements by feature in spreadsheets (one row per requirement) or JIRA Stories, for example.</p>
<p>Make sure you read many examples of well-written requirements, and practice. Follow a checklist, and have a co-worker review your work. <strong>Always</strong> ask yourselves how you would test each requirement. If you can't figure out how to write a test for the requirement, how can you ever prove the product works as intended?</p>
<h2>Non-Functional Requirements</h2>
<p>Non-functional requirements are also known as &quot;quality attributes&quot; or &quot;constraints&quot; of the system. The range of possible items that can be added to a cart (0..max) seems like a constraint on that field, so I can see how some would consider this a NFR. But how would you test it?</p>
<p>Instead, you can express this like a functional requirement: &quot;When the user enters a value that is greater than the maximum, display an error message&quot;. A NFR might describe the color, size and location of the error message. NFRs can also specify which UI kit to use and style guidelines to follow. For example, &quot;Must follow Google Material Design&quot; (<a href=""https://material.io"" rel=""nofollow noreferrer"">https://material.io</a>).</p>
<p>You should also be familiar with NFR categories (also known as the &quot;ilities&quot;):</p>
<ul>
<li>Performance</li>
<li>Stability</li>
<li>Reliability</li>
<li>Scalability</li>
<li>Flexibility</li>
<li>Usability</li>
<li>Testability</li>
<li>Traceability/Auditability</li>
<li>Security</li>
<li>Compliance/Certification</li>
<li>Much More: <a href=""https://en.wikipedia.org/wiki/Non-functional_requirement#Examples"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Non-functional_requirement#Examples</a></li>
</ul>
<p>Here are some examples of NFRs for a website:</p>
<ul>
<li>Performance: &quot;A new user account shall be created in less than 2000 ms&quot;</li>
<li>Reliability: &quot;The system shall have at least 99.9% availability&quot;</li>
<li>Capacity: &quot;The system shall service up to 1000 simultaneous users&quot;</li>
<li>Scalability: &quot;The system shall be horizontally scalable to increase the number of simultaneous users&quot;</li>
<li>Usability: &quot;Users should be able to navigate to any page in the site within 3 clicks&quot;</li>
</ul>
<h2>References</h2>
<p>Read these guidelines by the System Engineering Body of Knowledge (SEBoK). Follow them closely, share with your team:</p>
<ul>
<li><a href=""https://www.sebokwiki.org/wiki/System_Requirements#Presentation_and_Quality_of_Requirements"" rel=""nofollow noreferrer"">https://www.sebokwiki.org/wiki/System_Requirements#Presentation_and_Quality_of_Requirements</a></li>
</ul>
<p>This is an excellent book on large-scale agile requirements if you want to go deeper:</p>
<ul>
<li><a href=""https://www.oreilly.com/library/view/agile-software-requirements/9780321685438/"" rel=""nofollow noreferrer"">https://www.oreilly.com/library/view/agile-software-requirements/9780321685438/</a></li>
</ul>
"
"62329755","is there a way to list all dependancies that being used for the specific project in Python","<p>I just have finished the project with Python. I need to add <code>requirements.txt</code>. Is there a way in a command line to list all the dependencies I have been using along with their versions? </p>

<p>I have researched but it looks like I need to go manually through every single one of them, I was wondering if there is a better way to accomplish this?</p>

<p>Thank you. </p>
","<python><import><dependencies><requirements>","2020-06-11 17:07:16","35","1","1","62330296","<p>to do that you need to type the following command <code>pip/pip3 freeze</code></p>

<p>after that you can copy the dependencies into the <code>requirements.txt</code> file</p>
"
"62032382","Dataflow fails when I add requirements.txt [Python]","<p>So when I try to run dataflow with the DataflowRunner and include the requirements.txt which looks like this </p>

<pre><code>google-cloud-storage==1.28.1
pandas==1.0.3
smart-open==2.0.0
</code></pre>

<p>Every time it fails on this line </p>

<pre><code>INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://..../beamapp-.../numpy-1.18.2.zip...
Traceback (most recent call last):
File ""Database.py"", line 107, in &lt;module&gt;
run()
File ""Database.py"", line 101, in run
| 'Write CSV' &gt;&gt; beam.ParDo(WriteCSVFIle(options.output_bucket, 
pandora_options.output_folder))
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/pipeline.py"", line 503, in __exit__
    self.run().wait_until_finish()
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/pipeline.py"", line 483, in run
    self._options).run(False)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/pipeline.py"", line 496, in run
    return self.runner.run_pipeline(self, self._options)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/dataflow_runner.py"", line 548, in run_pipeline
    self.dataflow_client.create_job(self.job), self)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/utils/retry.py"", line 234, in wrapper
    return fun(*args, **kwargs)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 624, in create_job
    self.create_job_description(job)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 680, in create_job_description
    resources = self._stage_resources(job.options)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 577, in _stage_resources
    staging_location=google_cloud_options.staging_location)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/portability/stager.py"", line 182, in stage_job_resources
    pkg, FileSystems.join(staging_location, os.path.basename(pkg)))
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 942, in stage_artifact
    local_path_to_artifact, artifact_name)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/utils/retry.py"", line 234, in wrapper
    return fun(*args, **kwargs)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 564, in _gcs_file_copy
    self.stage_file(to_folder, to_name, f, total_size=total_size)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 602, in stage_file
    response = self._storage_client.objects.Insert(request, upload=upload)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/io/gcp/internal/clients/storage/storage_v1_client.py"", line 1156, in Insert
    upload=upload, upload_config=upload_config)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/base_api.py"", line 715, in _RunMethod
    http_request, client=self.client)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 908, in InitializeUpload
    return self.StreamInChunks()
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 1020, in StreamInChunks
    additional_headers=additional_headers)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 957, in __StreamMedia
    response = send_func(self.stream.tell())
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 943, in CallSendChunk
    start, additional_headers=additional_headers)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 1120, in __SendChunk
    return self.__SendMediaRequest(request, end)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 1033, in __SendMediaRequest
    retries=self.num_retries, check_response_func=CheckResponse)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/http_wrapper.py"", line 356, in MakeRequest
    max_retry_wait, total_wait_sec))
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/http_wrapper.py"", line 304, in HandleExceptionsAndRebuildHttpConnections
    raise retry_args.exc
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/http_wrapper.py"", line 346, in MakeRequest
    check_response_func=check_response_func)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/http_wrapper.py"", line 396, in _MakeRequestNoRetry
    redirections=redirections, connection_type=connection_type)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/oauth2client/transport.py"", line 169, in new_request
    redirections, connection_type)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/oauth2client/transport.py"", line 169, in new_request
    redirections, connection_type)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/httplib2/__init__.py"", line 1991, in request
    cachekey,
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/httplib2/__init__.py"", line 1690, in _request
    content,
httplib2.RedirectMissingLocation: Redirected but the response is missing a Location: header.
</code></pre>

<p>This is the command I'm running</p>

<pre><code>python Database.py     
--runner DataflowRunner     
--project XXX     
--staging_location gs://.../staging     
--temp_location gs://.../temp     
--template_location gs://.../Template     
--requirements_file requirements.txt
</code></pre>

<p>if I remove the --requirements_file requirements.txt it finishes but when I try to run the job it fails because it can't find the packages.</p>

<ul>
<li>I'm using cloud-storage to list all the files from a bucket so if you have another solution which doesn't involve cloud-storage it would be much appreciated</li>
</ul>

<p>This is my dataflow-requirements-cache folder. Before cleaning it up I had multiple files with different versions e.g. </p>

<pre><code>botocore-1.16.16.tar.gz
botocore-1.16.17.tar.gz
botocore-1.16.18.tar.gz
</code></pre>

<p>After I cleaned it up it looks like this, (it still failed while trying to upload numpy)</p>

<pre><code>numpy-1.18.4.zip
urllib3-1.25.9.tar.gz
smart_open-2.0.0.tar.gz
six-1.15.0.tar.gz
setuptools-47.1.0.zip
s3transfer-0.3.3.tar.gz
rsa-4.0.tar.gz
requests-2.23.0.tar.gz
pytz-2020.1.tar.gz
python-dateutil-2.8.1.tar.gz
pyasn1-modules-0.2.8.tar.gz
pyasn1-0.4.8.tar.gz
protobuf-3.12.2.tar.gz
pandas-1.0.3.tar.gz
jmespath-0.10.0.tar.gz
idna-2.9.tar.gz
googleapis-common-protos-1.51.0.tar.gz
google-resumable-media-0.5.0.tar.gz
google-cloud-storage-1.28.1.tar.gz
google-cloud-core-1.3.0.tar.gz
google-auth-1.15.0.tar.gz
google-api-core-1.17.0.tar.gz
docutils-0.15.2.tar.gz
chardet-3.0.4.tar.gz
certifi-2020.4.5.1.tar.gz
cachetools-4.1.0.tar.gz
botocore-1.16.18.tar.gz
boto3-1.13.18.tar.gz
boto-2.49.0.tar.gz
</code></pre>

<p>---- EDIT ----
The full output</p>

<pre><code>(airflow) afragotsis-mac:pandora_database afragotsis$ python PandoraDatabase.py \
&gt;     --runner DataflowRunner \
&gt;     --project XXX \
&gt;     --staging_location gs://.../dataflow-template/PandoraDatabase/staging \
&gt;     --temp_location gs://.../dataflow-template/PandoraDatabase/temp \
&gt;     --template_location gs://.../dataflow-template/PandoraDatabase/pandoraTemplate \
&gt;     --requirements_file requirements.txt \
&gt;     --save_main_session True
WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones
INFO:apache_beam.internal.gcp.auth:Setting socket default timeout to 60 seconds.
INFO:apache_beam.internal.gcp.auth:socket default timeout is 60.0 seconds.
INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/pipeline.pb...
INFO:oauth2client.transport:Attempting refresh to obtain initial access_token
INFO:oauth2client.client:Refreshing access_token
INFO:oauth2client.transport:Attempting refresh to obtain initial access_token
INFO:oauth2client.client:Refreshing access_token
INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/pipeline.pb in 0 seconds.
INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/requirements.txt...
INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/requirements.txt in 0 seconds.
INFO:apache_beam.runners.portability.stager:Executing command: ['/Users/afragotsis/opt/anaconda3/envs/airflow/bin/python', '-m', 'pip', 'download', '--dest', '/var/folders/zj/dqg766ks0cx663lg7brll7b80000gn/T/dataflow-requirements-cache', '-r', 'requirements.txt', '--exists-action', 'i', '--no-binary', ':all:']
INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/rsa-4.0.tar.gz...
INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/rsa-4.0.tar.gz in 0 seconds.
INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/urllib3-1.25.9.tar.gz...
INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/urllib3-1.25.9.tar.gz in 0 seconds.
INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/boto3-1.13.19.tar.gz...
INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/boto3-1.13.19.tar.gz in 0 seconds.
INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/pyasn1-modules-0.2.8.tar.gz...
INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/pyasn1-modules-0.2.8.tar.gz in 0 seconds.
INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/numpy-1.18.4.zip...
Traceback (most recent call last):
  File ""PandoraDatabase.py"", line 125, in &lt;module&gt;
    run()
  File ""PandoraDatabase.py"", line 119, in run
    | 'Write CSV' &gt;&gt; beam.ParDo(WriteCSVFIle(pandora_options.output_bucket, pandora_options.output_folder))
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/pipeline.py"", line 503, in __exit__
    self.run().wait_until_finish()
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/pipeline.py"", line 483, in run
    self._options).run(False)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/pipeline.py"", line 496, in run
    return self.runner.run_pipeline(self, self._options)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/dataflow_runner.py"", line 548, in run_pipeline
    self.dataflow_client.create_job(self.job), self)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/utils/retry.py"", line 234, in wrapper
    return fun(*args, **kwargs)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 624, in create_job
    self.create_job_description(job)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 680, in create_job_description
    resources = self._stage_resources(job.options)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 577, in _stage_resources
    staging_location=google_cloud_options.staging_location)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/portability/stager.py"", line 182, in stage_job_resources
    pkg, FileSystems.join(staging_location, os.path.basename(pkg)))
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 942, in stage_artifact
    local_path_to_artifact, artifact_name)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/utils/retry.py"", line 234, in wrapper
    return fun(*args, **kwargs)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 564, in _gcs_file_copy
    self.stage_file(to_folder, to_name, f, total_size=total_size)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 602, in stage_file
    response = self._storage_client.objects.Insert(request, upload=upload)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/io/gcp/internal/clients/storage/storage_v1_client.py"", line 1156, in Insert
    upload=upload, upload_config=upload_config)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/base_api.py"", line 715, in _RunMethod
    http_request, client=self.client)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 908, in InitializeUpload
    return self.StreamInChunks()
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 1020, in StreamInChunks
    additional_headers=additional_headers)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 957, in __StreamMedia
    response = send_func(self.stream.tell())
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 943, in CallSendChunk
    start, additional_headers=additional_headers)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 1120, in __SendChunk
    return self.__SendMediaRequest(request, end)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 1033, in __SendMediaRequest
    retries=self.num_retries, check_response_func=CheckResponse)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/http_wrapper.py"", line 356, in MakeRequest
    max_retry_wait, total_wait_sec))
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/http_wrapper.py"", line 304, in HandleExceptionsAndRebuildHttpConnections
    raise retry_args.exc
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/http_wrapper.py"", line 346, in MakeRequest
    check_response_func=check_response_func)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/http_wrapper.py"", line 396, in _MakeRequestNoRetry
    redirections=redirections, connection_type=connection_type)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/oauth2client/transport.py"", line 169, in new_request
    redirections, connection_type)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/oauth2client/transport.py"", line 169, in new_request
    redirections, connection_type)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/httplib2/__init__.py"", line 1991, in request
    cachekey,
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/httplib2/__init__.py"", line 1690, in _request
    content,
httplib2.RedirectMissingLocation: Redirected but the response is missing a Location: header.
</code></pre>

<p>the full path of the dataflow-requirements-cache</p>

<pre><code>/private/var/folders/zj/dqg766ks0cx663lg7brll7b80000gn/T/dataflow-requirements-cache
</code></pre>

<p>it always fails when it tries to upload numpy</p>
","<python><google-cloud-dataflow><dataflow><requirements>","2020-05-26 22:23:49","1366","4","2","62046774","<p>ok so no matter what I tried I couldn't make it work with the requirements file. So I tried the setup file. So now the command looks like this</p>

<pre><code>python Database.py     
--runner DataflowRunner     
--project XXX     
--staging_location gs://.../staging     
--temp_location gs://.../temp
--template_location gs://.../Template       
--setup_file /Users/.../setup.py \
--save_main_session True 
</code></pre>

<p>and the setup file is this </p>

<pre><code>import setuptools

REQUIRED_PACKAGES = [
          'google-cloud-storage==1.28.1',
          'pandas==1.0.3',
          'smart-open==2.0.0'
      ]

PACKAGE_NAME = 'my_package'
PACKAGE_VERSION = '0.0.1'

setuptools.setup(
    name=PACKAGE_NAME,
    version=PACKAGE_VERSION,
    description='Example project',
    install_requires=REQUIRED_PACKAGES,
    packages=setuptools.find_packages(),
)
</code></pre>
"
"62032382","Dataflow fails when I add requirements.txt [Python]","<p>So when I try to run dataflow with the DataflowRunner and include the requirements.txt which looks like this </p>

<pre><code>google-cloud-storage==1.28.1
pandas==1.0.3
smart-open==2.0.0
</code></pre>

<p>Every time it fails on this line </p>

<pre><code>INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://..../beamapp-.../numpy-1.18.2.zip...
Traceback (most recent call last):
File ""Database.py"", line 107, in &lt;module&gt;
run()
File ""Database.py"", line 101, in run
| 'Write CSV' &gt;&gt; beam.ParDo(WriteCSVFIle(options.output_bucket, 
pandora_options.output_folder))
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/pipeline.py"", line 503, in __exit__
    self.run().wait_until_finish()
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/pipeline.py"", line 483, in run
    self._options).run(False)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/pipeline.py"", line 496, in run
    return self.runner.run_pipeline(self, self._options)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/dataflow_runner.py"", line 548, in run_pipeline
    self.dataflow_client.create_job(self.job), self)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/utils/retry.py"", line 234, in wrapper
    return fun(*args, **kwargs)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 624, in create_job
    self.create_job_description(job)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 680, in create_job_description
    resources = self._stage_resources(job.options)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 577, in _stage_resources
    staging_location=google_cloud_options.staging_location)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/portability/stager.py"", line 182, in stage_job_resources
    pkg, FileSystems.join(staging_location, os.path.basename(pkg)))
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 942, in stage_artifact
    local_path_to_artifact, artifact_name)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/utils/retry.py"", line 234, in wrapper
    return fun(*args, **kwargs)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 564, in _gcs_file_copy
    self.stage_file(to_folder, to_name, f, total_size=total_size)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 602, in stage_file
    response = self._storage_client.objects.Insert(request, upload=upload)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/io/gcp/internal/clients/storage/storage_v1_client.py"", line 1156, in Insert
    upload=upload, upload_config=upload_config)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/base_api.py"", line 715, in _RunMethod
    http_request, client=self.client)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 908, in InitializeUpload
    return self.StreamInChunks()
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 1020, in StreamInChunks
    additional_headers=additional_headers)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 957, in __StreamMedia
    response = send_func(self.stream.tell())
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 943, in CallSendChunk
    start, additional_headers=additional_headers)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 1120, in __SendChunk
    return self.__SendMediaRequest(request, end)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 1033, in __SendMediaRequest
    retries=self.num_retries, check_response_func=CheckResponse)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/http_wrapper.py"", line 356, in MakeRequest
    max_retry_wait, total_wait_sec))
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/http_wrapper.py"", line 304, in HandleExceptionsAndRebuildHttpConnections
    raise retry_args.exc
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/http_wrapper.py"", line 346, in MakeRequest
    check_response_func=check_response_func)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/http_wrapper.py"", line 396, in _MakeRequestNoRetry
    redirections=redirections, connection_type=connection_type)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/oauth2client/transport.py"", line 169, in new_request
    redirections, connection_type)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/oauth2client/transport.py"", line 169, in new_request
    redirections, connection_type)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/httplib2/__init__.py"", line 1991, in request
    cachekey,
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/httplib2/__init__.py"", line 1690, in _request
    content,
httplib2.RedirectMissingLocation: Redirected but the response is missing a Location: header.
</code></pre>

<p>This is the command I'm running</p>

<pre><code>python Database.py     
--runner DataflowRunner     
--project XXX     
--staging_location gs://.../staging     
--temp_location gs://.../temp     
--template_location gs://.../Template     
--requirements_file requirements.txt
</code></pre>

<p>if I remove the --requirements_file requirements.txt it finishes but when I try to run the job it fails because it can't find the packages.</p>

<ul>
<li>I'm using cloud-storage to list all the files from a bucket so if you have another solution which doesn't involve cloud-storage it would be much appreciated</li>
</ul>

<p>This is my dataflow-requirements-cache folder. Before cleaning it up I had multiple files with different versions e.g. </p>

<pre><code>botocore-1.16.16.tar.gz
botocore-1.16.17.tar.gz
botocore-1.16.18.tar.gz
</code></pre>

<p>After I cleaned it up it looks like this, (it still failed while trying to upload numpy)</p>

<pre><code>numpy-1.18.4.zip
urllib3-1.25.9.tar.gz
smart_open-2.0.0.tar.gz
six-1.15.0.tar.gz
setuptools-47.1.0.zip
s3transfer-0.3.3.tar.gz
rsa-4.0.tar.gz
requests-2.23.0.tar.gz
pytz-2020.1.tar.gz
python-dateutil-2.8.1.tar.gz
pyasn1-modules-0.2.8.tar.gz
pyasn1-0.4.8.tar.gz
protobuf-3.12.2.tar.gz
pandas-1.0.3.tar.gz
jmespath-0.10.0.tar.gz
idna-2.9.tar.gz
googleapis-common-protos-1.51.0.tar.gz
google-resumable-media-0.5.0.tar.gz
google-cloud-storage-1.28.1.tar.gz
google-cloud-core-1.3.0.tar.gz
google-auth-1.15.0.tar.gz
google-api-core-1.17.0.tar.gz
docutils-0.15.2.tar.gz
chardet-3.0.4.tar.gz
certifi-2020.4.5.1.tar.gz
cachetools-4.1.0.tar.gz
botocore-1.16.18.tar.gz
boto3-1.13.18.tar.gz
boto-2.49.0.tar.gz
</code></pre>

<p>---- EDIT ----
The full output</p>

<pre><code>(airflow) afragotsis-mac:pandora_database afragotsis$ python PandoraDatabase.py \
&gt;     --runner DataflowRunner \
&gt;     --project XXX \
&gt;     --staging_location gs://.../dataflow-template/PandoraDatabase/staging \
&gt;     --temp_location gs://.../dataflow-template/PandoraDatabase/temp \
&gt;     --template_location gs://.../dataflow-template/PandoraDatabase/pandoraTemplate \
&gt;     --requirements_file requirements.txt \
&gt;     --save_main_session True
WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones
INFO:apache_beam.internal.gcp.auth:Setting socket default timeout to 60 seconds.
INFO:apache_beam.internal.gcp.auth:socket default timeout is 60.0 seconds.
INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/pipeline.pb...
INFO:oauth2client.transport:Attempting refresh to obtain initial access_token
INFO:oauth2client.client:Refreshing access_token
INFO:oauth2client.transport:Attempting refresh to obtain initial access_token
INFO:oauth2client.client:Refreshing access_token
INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/pipeline.pb in 0 seconds.
INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/requirements.txt...
INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/requirements.txt in 0 seconds.
INFO:apache_beam.runners.portability.stager:Executing command: ['/Users/afragotsis/opt/anaconda3/envs/airflow/bin/python', '-m', 'pip', 'download', '--dest', '/var/folders/zj/dqg766ks0cx663lg7brll7b80000gn/T/dataflow-requirements-cache', '-r', 'requirements.txt', '--exists-action', 'i', '--no-binary', ':all:']
INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/rsa-4.0.tar.gz...
INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/rsa-4.0.tar.gz in 0 seconds.
INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/urllib3-1.25.9.tar.gz...
INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/urllib3-1.25.9.tar.gz in 0 seconds.
INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/boto3-1.13.19.tar.gz...
INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/boto3-1.13.19.tar.gz in 0 seconds.
INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/pyasn1-modules-0.2.8.tar.gz...
INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/pyasn1-modules-0.2.8.tar.gz in 0 seconds.
INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://.../dataflow-template/PandoraDatabase/staging/beamapp-afragotsis-0529200636-871276.1590782796.871390/numpy-1.18.4.zip...
Traceback (most recent call last):
  File ""PandoraDatabase.py"", line 125, in &lt;module&gt;
    run()
  File ""PandoraDatabase.py"", line 119, in run
    | 'Write CSV' &gt;&gt; beam.ParDo(WriteCSVFIle(pandora_options.output_bucket, pandora_options.output_folder))
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/pipeline.py"", line 503, in __exit__
    self.run().wait_until_finish()
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/pipeline.py"", line 483, in run
    self._options).run(False)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/pipeline.py"", line 496, in run
    return self.runner.run_pipeline(self, self._options)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/dataflow_runner.py"", line 548, in run_pipeline
    self.dataflow_client.create_job(self.job), self)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/utils/retry.py"", line 234, in wrapper
    return fun(*args, **kwargs)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 624, in create_job
    self.create_job_description(job)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 680, in create_job_description
    resources = self._stage_resources(job.options)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 577, in _stage_resources
    staging_location=google_cloud_options.staging_location)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/portability/stager.py"", line 182, in stage_job_resources
    pkg, FileSystems.join(staging_location, os.path.basename(pkg)))
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 942, in stage_artifact
    local_path_to_artifact, artifact_name)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/utils/retry.py"", line 234, in wrapper
    return fun(*args, **kwargs)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 564, in _gcs_file_copy
    self.stage_file(to_folder, to_name, f, total_size=total_size)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/runners/dataflow/internal/apiclient.py"", line 602, in stage_file
    response = self._storage_client.objects.Insert(request, upload=upload)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apache_beam/io/gcp/internal/clients/storage/storage_v1_client.py"", line 1156, in Insert
    upload=upload, upload_config=upload_config)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/base_api.py"", line 715, in _RunMethod
    http_request, client=self.client)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 908, in InitializeUpload
    return self.StreamInChunks()
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 1020, in StreamInChunks
    additional_headers=additional_headers)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 957, in __StreamMedia
    response = send_func(self.stream.tell())
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 943, in CallSendChunk
    start, additional_headers=additional_headers)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 1120, in __SendChunk
    return self.__SendMediaRequest(request, end)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/transfer.py"", line 1033, in __SendMediaRequest
    retries=self.num_retries, check_response_func=CheckResponse)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/http_wrapper.py"", line 356, in MakeRequest
    max_retry_wait, total_wait_sec))
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/http_wrapper.py"", line 304, in HandleExceptionsAndRebuildHttpConnections
    raise retry_args.exc
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/http_wrapper.py"", line 346, in MakeRequest
    check_response_func=check_response_func)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/apitools/base/py/http_wrapper.py"", line 396, in _MakeRequestNoRetry
    redirections=redirections, connection_type=connection_type)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/oauth2client/transport.py"", line 169, in new_request
    redirections, connection_type)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/oauth2client/transport.py"", line 169, in new_request
    redirections, connection_type)
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/httplib2/__init__.py"", line 1991, in request
    cachekey,
  File ""/Users/afragotsis/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/httplib2/__init__.py"", line 1690, in _request
    content,
httplib2.RedirectMissingLocation: Redirected but the response is missing a Location: header.
</code></pre>

<p>the full path of the dataflow-requirements-cache</p>

<pre><code>/private/var/folders/zj/dqg766ks0cx663lg7brll7b80000gn/T/dataflow-requirements-cache
</code></pre>

<p>it always fails when it tries to upload numpy</p>
","<python><google-cloud-dataflow><dataflow><requirements>","2020-05-26 22:23:49","1366","4","2","62142282","<p>A quick search turns up this related question: <a href=""https://stackoverflow.com/questions/59815620/gcloud-upload-httplib2-redirectmissinglocation-redirected-but-the-response-is-m"">GCloud Upload httplib2.RedirectMissingLocation: Redirected but the response is missing a Location: header</a></p>

<p>You may be affected by <a href=""https://github.com/googleapis/google-api-python-client/issues/803"" rel=""nofollow noreferrer"">https://github.com/googleapis/google-api-python-client/issues/803</a>. A workaround appears to be to adjust the httplib2 version.</p>
"
"61542567","Non-interactive functional requirements software engineering","<p>I'm having a problem with listing some non-interactive functional requirements for building a project about ""Smart food court system for a university"" with self-service. In that system, customer can order through mobile app or machine, pay by e-wallet, and when ordering by machine, the machine will automatic print a bill after payment. I can't understand clearly what a concept non-interactive functional requirements in software engineering. And with the example that machine print a bill automatically after payment is a non-interactive functional requirements or not? Can anyone give more examples about non-interactive functional requirements to help me understand clearly? Thank you!</p>
","<software-design><use-case><requirements><use-case-diagram>","2020-05-01 12:31:56","193","0","1","63115953","<p>The concept of <em><strong>non-interactive requirement</strong></em> is not a  common nor well-defined terminology in software engineering.</p>
<p>Interactive requirements are about what the system shall do in response to a user action, or to enable a user action.</p>
<p>Automatically printing a bill is therefore an interactive requirement: even if the printing is by itself not interactive, the sheer fact of enabling the user to pick the bill makes it interactive.</p>
<p>Interactive requirements are captured in the use-cases or in UI requirements. Non-interactive requirements are all the rest, for example:</p>
<ul>
<li>general business rules</li>
<li>requirements about the data objects to be managed, about their consistency, and how they relate to each-other;</li>
<li>non-functional requirements, such as operating constraints, or performance, security or maintainability related requirements.</li>
</ul>
"
"61518704","Pip Install python package: cannot find requirements.txt","<p>I am trying to install the package gamry-parser (<a href=""https://pypi.org/project/gamry-parser/"" rel=""nofollow noreferrer"">https://pypi.org/project/gamry-parser/</a>).</p>

<p>However, the command window is unable to find the requirements.txt in the location it is looking for. I have tried to search the path it is searching in my computer, but it does not seem to exist(<em>c:\users\name\appdata\local\temp\pip-install-rfy1sh\gamry-parser\setup.py</em>). In addition, the requirements.txt does in fact exist, but not in this nonexistant path. I get the following error:</p>

<pre><code>IOError: [Errno 2] No such file or directory: 'requirements.txt'
ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.
</code></pre>

<p>Thanks.</p>
","<python><path><pip><command><requirements>","2020-04-30 08:06:18","19541","0","1","61530333","<p><code>gamry-parser</code> 0.4.1 <a href=""https://pypi.org/project/gamry-parser/0.4.1/#files"" rel=""nofollow noreferrer"">provides</a> a wheel for Python 3 and a source dist that will be used for Python 2.7. I tested them — the wheel installed with Python 3.7, no problem.</p>

<p>The problem is with Python 2.7 and the source distribution — the sdist lacks <code>requirements.txt</code>. To fix it they need to add file <a href=""https://docs.python.org/3/distutils/sourcedist.html#specifying-the-files-to-distribute"" rel=""nofollow noreferrer""><code>MANIFEST.in</code></a>:</p>

<pre><code>echo include requirements.txt &gt; MANIFEST.in
git add MANIFEST.in
git commit -m ""Add MANIFEST.in for sdist""
</code></pre>

<p>Please <a href=""https://github.com/bcliang/gamry-parser/issues"" rel=""nofollow noreferrer"">report the issue</a> or send a pull request.</p>
"
"61480082","python kivy requests import error,ı have buılozer.spec","<p>I have added the request in the buildozer.spec requirements list but it cannot import at Kivy Launcher ı don't have any issue in terminal
ı am using python 3.7.2 on linux</p>

<pre><code>from kivy.app import App

from kivy.uix.label import Label

import os
import sys

import requests


class FirstKivy(App):

    def build(self):
        return Label(text=""hello"")

FirstKivy().run()

my logs:
[INFO              ] Logger: Record log in/storage/emulated/0/kivy/Project/.kivy/logs/kivy_20-04-28_21.txt
[WARNING           ] [Config      ] Upgrading configuration in progress.
[WARNING           ] [Config      ] Older configuration version detected (21 instead of 14)
[INFO              ] Kivy: v1.9.1
[INFO              ] Python: v2.7.2 (default, Mar 20 2016, 23:30:13) 
[GCC 4.8]
[INFO              ] Factory: 179 symbols loaded
[WARNING           ] stderr: /data/user/0/org.kivy.pygame/files/lib/python2.7/site-packages/kivy/core/image/img_pygame.py:13: RuntimeWarning: import cdrom: No module named cdrom
[WARNING           ] stderr: (ImportError: No module named cdrom)
[INFO              ] Image: Providers: img_tex, img_dds, img_gif, img_pygame, img_pil (img_ffpyplayer ignored)
[INFO              ] Text: Provider: pygame
[WARNING           ] stderr: Traceback (most recent call last):
[WARNING           ] stderr:   File ""main.py"", line 8, in &lt;module&gt;
[WARNING           ] stderr:     import requests
[WARNING           ] stderr: ImportError: No module named requests
</code></pre>
","<python><python-requests><kivy><buildozer><requirements>","2020-04-28 12:22:28","581","0","1","61486188","<p>Kivy launcher doesn't include requests. Build your own apk using buildozer/python-for-android.</p>
"
"61405379","Requirements diagram possibilities with use cases and test cases","<p>I am wondering what is allowed (or at least what is the best practice) in a SysML Requirements diagram regarding the use of satisfy/verify links between use-cases, test-cases and requirements.</p>

<p>As I understand it, generally, a use-case &lt;&lt; satisfy >> a requirement, and a test-case &lt;&lt; verify >> it.</p>

<p>Is-it possible though for a use-case to &lt;&lt; verify >> a requirement?</p>

<p>I found different sources with contradictory statements on the matter.</p>

<p>For the classical Alarm-Clock example, with :</p>

<p>Req1 : To be waken at chosen time. </p>

<p>UseCase1 : Set an alarm time &amp; a radio frequency.</p>

<p>Test1 : Given there is a station at 101.5FM and the time is correctly set, when i set an alarm future time and set the freq to 101.5FM, then I will listen to the station at the given time.</p>

<p>What is then the correct and/or best diagram ?</p>

<p>(UseCase1) -- satisfy --> [Req1] ,  [TestCase1] -- verify --> [Req1]</p>

<p>or</p>

<p>(UseCase1) -- satisfy --> [Req1] ,  [TestCase1] -- verify --> (UseCase1)</p>

<p>or</p>

<p>(UseCase1) -- verify --> [Req1] ,  [TestCase1] -- verify --> [Req1]</p>

<p>Thanks for any clarifications!</p>
","<requirements><sysml>","2020-04-24 09:39:19","159","0","1","62182144","<p>There is no formal constraint in the specification, that would disallow this. However, the semantics of the elements makes this meaningless.</p>

<p><strong>How would a use case verify a requirement?</strong> </p>

<blockquote>
  <p><strong>SysML:</strong> A Verify relationship is a dependency between a requirement and a test
  case or other model element that can determine whether a system
  fulfills the requirement.</p>
</blockquote>

<p>A use case describes all the ways a system can be used to achieve a certain goal. It describes user actions as well as functions the system must have to be helpful for achieving this goal. It doesn't describe how to test the system functions. You can however derive test cases from a use case description.</p>

<p><strong>How would a use case satisfy a requirement?</strong> </p>

<blockquote>
  <p><strong>SysML:</strong> A Satisfy relationship is a dependency between a requirement and a
  model element that fulfills the requirement.</p>
</blockquote>

<p>A use case is an analysis tool to find the functions, that the system shall support - in other words, the functional requirements. How can an analysis tool that finds requirements satisfy a requirement?</p>

<p><strong>About your example</strong> </p>

<p>What is the goal of the use case ""set an alarm time and radio frequency""? The alarm time and the radio frequency are set? Well, forgive me, but this is not really helpful. </p>

<p>The use case refines the stakeholder requirement ""Be waken at chosen time"" and has the same name. And this use case has a lot of alternative flows, that most clock makers in their blissfull ignorance forget: I awake early and want to prematurly cancel the alarm (without clearing it for the next day). I pressed the snooze button, but now, that I'm awake, decide to get up anyway (and while I'm under the shower, the alarm goes off). I stayed up late, and now need to strike a balance between a minimum sleep requirement and a full to do list (and would like to know, without calculating late at night, how much time would be left). All these alternative flows lead to additional functional requirements.</p>

<p>So the complete list of functional requirements found in this use case would be: </p>

<ul>
<li>set Alarm time</li>
<li>select Radio or Alarm</li>
<li>set Radio Frequency</li>
<li>control clock for alarming (main function)

<ul>
<li>play Radio at predefined time</li>
<li>sound alarm at predefined time</li>
<li>snooze alarm</li>
<li>cancel Alarm for today </li>
<li>clear Alarm time</li>
<li>show time until alarm </li>
</ul></li>
</ul>

<p>It is amazing how many alarm clocks fail to have all these functions, given that a use case analysis would find them quickly.</p>

<p>So the diagram could be:</p>

<p>«stakeholder requirement» <code>be waken at chosen time</code><br>
&lt;-«refine»- «use case» <code>be waken at chosen time</code><br>
&lt;-«trace»- «functional requirement» <code>cancel Alarm for today</code><br>
&lt;-«satisfy»- «operation» <code>cancel Alarm</code> </p>

<p>«functional requirement» <code>cancel Alarm for today</code><br>
&lt;-«verify»- «testcase» <code>cancel Alarm after snooze</code> </p>

<p>You could argue, that the stakeholder requirement, and, thus indirectly the use case could get verified by a test case. However, I think that a stakeholder requirement would get validated, not verified.</p>
"
"61356355","Requirement is installed but when I try to run the program it says it doesn't","<p>Like the title says, I install crispy forms and it's installed, but when I try to migrate, it says crispy forms it's not installed</p>

<pre><code>(env) C:\Users\Dias\Desktop\Soccer_site\aposta_segura&gt;pip3 install django-crispy-forms
Requirement already satisfied: django-crispy-forms in c:\users\dias\desktop\soccer_site\aposta_segura\env\lib\site-packages (1.9.0)

(env) C:\Users\Dias\Desktop\Soccer_site\aposta_segura&gt;python3 manage.py migrate
Traceback (most recent call last):
  File ""manage.py"", line 21, in &lt;module&gt;
    main()
  File ""manage.py"", line 17, in main
    execute_from_command_line(sys.argv)
  File ""C:\Users\Dias\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\django\core\management\__init__.py"", lin
e 401, in execute_from_command_line
    utility.execute()
  File ""C:\Users\Dias\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\django\core\management\__init__.py"", lin
e 377, in execute
    django.setup()
  File ""C:\Users\Dias\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\django\__init__.py"", line 24, in setup
    apps.populate(settings.INSTALLED_APPS)
  File ""C:\Users\Dias\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\django\apps\registry.py"", line 91, in po
pulate
    app_config = AppConfig.create(entry)
  File ""C:\Users\Dias\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\LocalCache\local-packages\Python38\site-packages\django\apps\config.py"", line 90, in crea
te
    module = import_module(entry)
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.8_3.8.752.0_x64__qbz5n2kfra8p0\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""&lt;frozen importlib._bootstrap&gt;"", line 1014, in _gcd_import
  File ""&lt;frozen importlib._bootstrap&gt;"", line 991, in _find_and_load
  File ""&lt;frozen importlib._bootstrap&gt;"", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'crispy_forms'

(env) C:\Users\Dias\Desktop\Soccer_site\aposta_segura&gt;
</code></pre>

<p>If I install using the requirements.txt, the same thing happens, it says all the requirements are installed but crispy forms is not, i tried using ""--user"" but it doesn't work, don't know if it's a windows thing</p>
","<python><django><migrate><requirements>","2020-04-22 02:36:35","194","0","1","61358761","<p>As @lain mentioned, it seems that the <code>Requirement is already satisfied</code> in your venv. This could only mean that the interpreter cannot be resolved to the correct venv.</p>

<p>check this in cmd prompt</p>

<pre><code>where python 
</code></pre>

<p>And </p>

<pre><code>where python3
</code></pre>

<p>The output of the first will match to the same directory as your <code>venv</code>.</p>

<p>Most likely its <code>python</code> so just use <code>python manage.py migrate</code> and it should work.</p>
"
"60966929","What can I safely remove in a python lib folder?","<p>I am using:</p>

<pre><code>mkdir -p build/python/lib/python3.6/site-packages
pipenv run pip install -r requirements.txt --target build/python/lib/python3.6/site-packages
</code></pre>

<p>to create a directory <code>build</code> with everything I need for my python project but I also need to save as much space as possible.</p>

<p>What can I safely remove in order to save space?</p>

<p>Maybe can I do <code>find build -type d -iname ""*.dist-info"" -exec rm -R {} \;</code> ?</p>

<p>Can I remove <code>*.py</code> if I leave <code>*.pyc</code>?</p>

<p>Thanks</p>
","<python><pip><requirements><pyc>","2020-04-01 08:47:43","435","1","1","63119633","<p>Perhaps platform specific *.exe files, if your project doesn't need to run on Windows:</p>
<p><a href=""https://stackoverflow.com/q/47066676/5156207"">How to prevent *.exe ...</a></p>
<p>Delete *.pyc (byte-compiled files), with an impact to load-time: 100% supported, unlike your trick of the reverse: retain just *.pyc (and delete most *.py sources) in some python versions; not safe IMHO but never tried it.</p>
"
"60955493","Building wheel for scipy (setup.py): finished with status 'error'","<p>I am trying to build a Docker Image and install these requirements with a requirements.txt-file:</p>

<pre><code>numpy==1.18.1
scipy==1.2.1
joblib==0.13.2
Cython==0.29.13
pandas==0.25.3
scikit-learn==0.21.3
h5py==2.8.0
Keras==2.3.1
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.0
</code></pre>

<p>This is my dockerfile:</p>

<pre><code>FROM python:3

MAINTAINER author@sample.com

RUN mkdir /test
COPY ./ /test
WORKDIR /test

## Install your dependencies here using apt-get etc.


RUN pip install -r requirements.txt
</code></pre>

<p>When I try to build theThis is the error message I get</p>

<pre><code>ERROR: Command errored out with exit status 1:
   command: /usr/local/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-d0v5nn_0/scipy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-d0v5nn_0/scipy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-u8mo7l4r
       cwd: /tmp/pip-install-d0v5nn_0/scipy/
  Complete output (9 lines):
  /tmp/pip-install-d0v5nn_0/scipy/setup.py:114: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
    import imp
  Traceback (most recent call last):
    File ""&lt;string&gt;"", line 1, in &lt;module&gt;
    File ""/tmp/pip-install-d0v5nn_0/scipy/setup.py"", line 492, in &lt;module&gt;
      setup_package()
    File ""/tmp/pip-install-d0v5nn_0/scipy/setup.py"", line 468, in setup_package
      from numpy.distutils.core import setup
  ModuleNotFoundError: No module named 'numpy'
  ----------------------------------------
  ERROR: Failed building wheel for scipy
</code></pre>

<p>After this it also tries to run a   </p>

<pre><code>Running setup.py clean for scipy
</code></pre>

<p>but without success</p>
","<python><docker><numpy><scipy><requirements>","2020-03-31 16:36:54","6833","2","1","60957064","<p>Not sure if it's the reason for the error but considering the <a href=""https://github.com/numpy/numpy/releases/tag/v1.18.1"" rel=""nofollow noreferrer"">release notes of Numpy 1.18.1</a>, you should have Cython ≥ 0.29.14 whereas the <code>requirements.txt</code> specifies <code>Cython==0.29.13</code>.</p>

<p><code>FROM python:3</code> results in getting Python 3.8.</p>

<blockquote>
  <p>The Python versions supported in this release are 3.5-3.8. Downstream
  developers should use Cython >= 0.29.14 for Python 3.8 support and
  OpenBLAS >= 3.7 to avoid errors on the Skylake architecture.</p>
</blockquote>
"
"60714415","How do i design a UML use case diagram","<p>I am trying to design a use case diagram for the following scenario.</p>

<p>I have a society that is distributing goods to clients based on their orders. These clients can be administrations, companies, or private individuals.
Depending on what the client is I want to know more or less of their info (name, number etc)</p>

<p>The use cases are different depending on whether the client is:</p>

<ol>
<li>English</li>
<li>English and have used this service for more than 3 years</li>
<li>Foreign</li>
</ol>

<p>For example:</p>

<ul>
<li><p>The 1) English clients' orders are accepted only if they pay a small fee in advance.</p></li>
<li><p>The 2) English clients that have used the service for 3 years don't have to pay this fee but need to get approbation from a different actor (an Agent in this case)</p></li>
<li><p>The 3) Foreign clients' orders are always accepted no matter what.</p></li>
</ul>

<p>This right here is where I run into trouble and need help with. </p>

<p>The orders from nglish clients that have a criminal record are always denied UNLESS they are an administration.</p>

<p>What are the most optimal actor choices here? I thought of going with <code>English client</code>, and <code>Foreign clients</code> but I don't know how to include the ""Unless the client is an administration"" in the use case.</p>
","<uml><actor><use-case><requirements>","2020-03-16 23:18:50","201","-1","2","60790466","<p>Actors in UML use-cases are classifiers.  To decide about which actors to create requires to understand the actors their goals and behaviours and how they differ in the interaction with the system.      </p>

<p>First of all, you need to clarify the super-ambiguous requirements:  </p>

<ul>
<li>""<em>English client</em>"":  is this a client with English nationality?  Is it a client that lives permanently in the UK?  Is this a client with an address in the UK? Is it a client with a +44 phone number?  </li>
<li>""<em>Foreign client</em>"": same kind of questions + can you define for sure the difference between Ensglish and Foreign?  For example: what with bi-nationals? what with people having two addresses one being abroad?  </li>
<li>""<em>Using this service more than three years</em>"":  what with a foreign customer who uses the service for 3 years and then settles in the UK?  </li>
<li>Since you deliver goods, you might also need to consider a delivery address.  What with an English client ordering on a foreign address or vis-versa ? </li>
<li>""<em>criminal record</em>"":  the criminal record might change over time:  is it provided at each purchase? or is it part of the customer registration process ?  In the latter case,  is there a need to periodically renew this information ?  </li>
</ul>

<p>Use-cases should in principle be goal oriented.  So a use-case represents a goal for a user who is going to interact with the system to achieve the goal.  Use-cases are not meant to describe the detailed sequence of your process (if client is this, do that, etc...) and neither are actors meant for that purpose.  </p>

<p>You should therefore consider reformulating the use-cases to represent how the actors would perceive them. If needed you may consider the status of the actor that could explain that an actor behaves very differently. Typically in your case, I could imagine :  </p>

<ul>
<li>New client: a new client may want to provide details (address, identification) or evidence that they are entitled to buy (criminal record - I suppose your activity is regulated if you request such details)</li>
<li>Public administration:  behavior of administration in purchase is anyway different because of public procurement and legal constraints. </li>
<li>Privately owned company:  behavior is different since it can involve several persons,  </li>
<li>Private individual </li>
</ul>

<p>The need to pay an advance fee seem to depend on the address, nationality, history.  It's more related to the process (it's a part of it) than an independent goal for an actor. So I would neither show this as a use-case nor make different actors for this purpose.   </p>

<p>The reason to deny an order is not something that is not relevant for the customer (no customer has a goal go get  a purchase denied!).  It's relevant to you and your system and is a consequence of the registration process.  So no need to have a dedicated actor for that.    </p>
"
"60714415","How do i design a UML use case diagram","<p>I am trying to design a use case diagram for the following scenario.</p>

<p>I have a society that is distributing goods to clients based on their orders. These clients can be administrations, companies, or private individuals.
Depending on what the client is I want to know more or less of their info (name, number etc)</p>

<p>The use cases are different depending on whether the client is:</p>

<ol>
<li>English</li>
<li>English and have used this service for more than 3 years</li>
<li>Foreign</li>
</ol>

<p>For example:</p>

<ul>
<li><p>The 1) English clients' orders are accepted only if they pay a small fee in advance.</p></li>
<li><p>The 2) English clients that have used the service for 3 years don't have to pay this fee but need to get approbation from a different actor (an Agent in this case)</p></li>
<li><p>The 3) Foreign clients' orders are always accepted no matter what.</p></li>
</ul>

<p>This right here is where I run into trouble and need help with. </p>

<p>The orders from nglish clients that have a criminal record are always denied UNLESS they are an administration.</p>

<p>What are the most optimal actor choices here? I thought of going with <code>English client</code>, and <code>Foreign clients</code> but I don't know how to include the ""Unless the client is an administration"" in the use case.</p>
","<uml><actor><use-case><requirements>","2020-03-16 23:18:50","201","-1","2","60826461","<p>The use case <em>diagram</em> is not the right place to put this information. As correctly pointed out by @Christophe, <em>a use-case represents a goal for a user who is going to interact with the system to achieve the goal</em>.</p>

<p>This means that <strong>there is only one single use case in your scenario: ""Order Goods""</strong>. However, it has a set of <em>preconditions</em>. You could list them as structured plain text. Since there is quite some complexity behind each of them, I recommend to put them into a separate decision chart. Then you have a nice clean separation of the diagram scopes, and they remain easily readable.</p>

<p>Sidenote: There could be a second one ""distribute ordered goods"" executed by a 2nd actor who is an employee who does fulfillment / routing / dispatching.</p>
"
"60160359","Error code when installing psycopg2 in requirements.txt in django","<p>I've tried to manually install only the psycopg2 module. As well as with a pip3 install -r requirements.txt. If anybody has encountered this error before, please provide appreciated guidance! </p>

<pre><code>ERROR: Failed building wheel for psycopg2
  Running setup.py clean for psycopg2
Failed to build psycopg2
Installing collected packages: psycopg2
    Running setup.py install for psycopg2 ... error
    ERROR: Command errored out with exit status 1:
     command: /Users/DavidKronish/dev/citram/MyCampus-Backend/citramenv/bin/python3.8 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/8x/lls1w4m94l90p8qszpnrvzgw0000gp/T/pip-install-c2yxmbq8/psycopg2/setup.py'""'""'; __file__='""'""'/private/var/folders/8x/lls1w4m94l90p8qszpnrvzgw0000gp/T/pip-install-c2yxmbq8/psycopg2/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/8x/lls1w4m94l90p8qszpnrvzgw0000gp/T/pip-record-3aciztvp/install-record.txt --single-version-externally-managed --compile --install-headers /Users/DavidKronish/dev/citram/MyCampus-Backend/citramenv/bin/../include/site/python3.8/psycopg2
         cwd: /private/var/folders/8x/lls1w4m94l90p8qszpnrvzgw0000gp/T/pip-install-c2yxmbq8/psycopg2/
    Complete output (144 lines):
    running install
    running build
    running build_py
    creating build
    creating build/lib.macosx-10.9-x86_64-3.8
    creating build/lib.macosx-10.9-x86_64-3.8/psycopg2
    copying lib/_json.py -&gt; build/lib.macosx-10.9-x86_64-3.8/psycopg2
    copying lib/extras.py -&gt; build/lib.macosx-10.9-x86_64-3.8/psycopg2
    copying lib/compat.py -&gt; build/lib.macosx-10.9-x86_64-3.8/psycopg2
    copying lib/errorcodes.py -&gt; build/lib.macosx-10.9-x86_64-3.8/psycopg2
    copying lib/tz.py -&gt; build/lib.macosx-10.9-x86_64-3.8/psycopg2
    copying lib/_range.py -&gt; build/lib.macosx-10.9-x86_64-3.8/psycopg2
    copying lib/_ipaddress.py -&gt; build/lib.macosx-10.9-x86_64-3.8/psycopg2
    copying lib/_lru_cache.py -&gt; build/lib.macosx-10.9-x86_64-3.8/psycopg2
    copying lib/__init__.py -&gt; build/lib.macosx-10.9-x86_64-3.8/psycopg2
    copying lib/extensions.py -&gt; build/lib.macosx-10.9-x86_64-3.8/psycopg2
    copying lib/errors.py -&gt; build/lib.macosx-10.9-x86_64-3.8/psycopg2
    copying lib/sql.py -&gt; build/lib.macosx-10.9-x86_64-3.8/psycopg2
    copying lib/pool.py -&gt; build/lib.macosx-10.9-x86_64-3.8/psycopg2
    running build_ext
    building 'psycopg2._psycopg' extension
    creating build/temp.macosx-10.9-x86_64-3.8
    creating build/temp.macosx-10.9-x86_64-3.8/psycopg
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/psycopgmodule.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/psycopgmodule.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/green.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/green.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/pqpath.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/pqpath.o
    psycopg/pqpath.c:135:17: warning: implicit conversion from enumeration type 'ConnStatusType' to different enumeration type 'ExecStatusType' [-Wenum-conversion]
                    PQstatus(conn-&gt;pgconn) : PQresultStatus(*pgres)));
                    ^~~~~~~~~~~~~~~~~~~~~~
    psycopg/pqpath.c:1714:11: warning: code will never be executed [-Wunreachable-code]
        ret = 1;
              ^
    psycopg/pqpath.c:1819:17: warning: implicit conversion from enumeration type 'ConnStatusType' to different enumeration type 'ExecStatusType' [-Wenum-conversion]
                    PQstatus(curs-&gt;conn-&gt;pgconn) : PQresultStatus(curs-&gt;pgres)));
                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
    3 warnings generated.
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/utils.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/utils.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/bytes_format.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/bytes_format.o
    In file included from psycopg/bytes_format.c:81:
    In file included from ./psycopg/psycopg.h:37:
    ./psycopg/config.h:81:13: warning: unused function 'Dprintf' [-Wunused-function]
    static void Dprintf(const char *fmt, ...) {}
                ^
    1 warning generated.
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/libpq_support.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/libpq_support.o
    In file included from psycopg/libpq_support.c:29:
    In file included from ./psycopg/psycopg.h:37:
    ./psycopg/config.h:81:13: warning: unused function 'Dprintf' [-Wunused-function]
    static void Dprintf(const char *fmt, ...) {}
                ^
    1 warning generated.
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/win32_support.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/win32_support.o
    In file included from psycopg/win32_support.c:27:
    In file included from ./psycopg/psycopg.h:37:
    ./psycopg/config.h:81:13: warning: unused function 'Dprintf' [-Wunused-function]
    static void Dprintf(const char *fmt, ...) {}
                ^
    1 warning generated.
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/solaris_support.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/solaris_support.o
    In file included from psycopg/solaris_support.c:28:
    In file included from ./psycopg/psycopg.h:37:
    ./psycopg/config.h:81:13: warning: unused function 'Dprintf' [-Wunused-function]
    static void Dprintf(const char *fmt, ...) {}
                ^
    1 warning generated.
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/connection_int.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/connection_int.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/connection_type.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/connection_type.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/cursor_int.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/cursor_int.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/cursor_type.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/cursor_type.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/column_type.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/column_type.o
    In file included from psycopg/column_type.c:27:
    In file included from ./psycopg/psycopg.h:37:
    ./psycopg/config.h:81:13: warning: unused function 'Dprintf' [-Wunused-function]
    static void Dprintf(const char *fmt, ...) {}
                ^
    1 warning generated.
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/replication_connection_type.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/replication_connection_type.o
    In file included from psycopg/replication_connection_type.c:27:
    In file included from ./psycopg/psycopg.h:37:
    ./psycopg/config.h:81:13: warning: unused function 'Dprintf' [-Wunused-function]
    static void Dprintf(const char *fmt, ...) {}
                ^
    1 warning generated.
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/replication_cursor_type.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/replication_cursor_type.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/replication_message_type.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/replication_message_type.o
    In file included from psycopg/replication_message_type.c:27:
    In file included from ./psycopg/psycopg.h:37:
    ./psycopg/config.h:81:13: warning: unused function 'Dprintf' [-Wunused-function]
    static void Dprintf(const char *fmt, ...) {}
                ^
    1 warning generated.
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/diagnostics_type.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/diagnostics_type.o
    In file included from psycopg/diagnostics_type.c:27:
    In file included from ./psycopg/psycopg.h:37:
    ./psycopg/config.h:81:13: warning: unused function 'Dprintf' [-Wunused-function]
    static void Dprintf(const char *fmt, ...) {}
                ^
    1 warning generated.
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/error_type.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/error_type.o
    In file included from psycopg/error_type.c:27:
    In file included from ./psycopg/psycopg.h:37:
    ./psycopg/config.h:81:13: warning: unused function 'Dprintf' [-Wunused-function]
    static void Dprintf(const char *fmt, ...) {}
                ^
    1 warning generated.
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/conninfo_type.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/conninfo_type.o
    In file included from psycopg/conninfo_type.c:27:
    In file included from ./psycopg/psycopg.h:37:
    ./psycopg/config.h:81:13: warning: unused function 'Dprintf' [-Wunused-function]
    static void Dprintf(const char *fmt, ...) {}
                ^
    1 warning generated.
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/lobject_int.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/lobject_int.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/lobject_type.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/lobject_type.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/notify_type.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/notify_type.o
    In file included from psycopg/notify_type.c:27:
    In file included from ./psycopg/psycopg.h:37:
    ./psycopg/config.h:81:13: warning: unused function 'Dprintf' [-Wunused-function]
    static void Dprintf(const char *fmt, ...) {}
                ^
    1 warning generated.
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/xid_type.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/xid_type.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/adapter_asis.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_asis.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/adapter_binary.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_binary.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/adapter_datetime.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_datetime.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/adapter_list.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_list.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/adapter_pboolean.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_pboolean.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/adapter_pdecimal.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_pdecimal.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/adapter_pint.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_pint.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/adapter_pfloat.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_pfloat.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/adapter_qstring.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_qstring.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/microprotocols.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/microprotocols.o
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/microprotocols_proto.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/microprotocols_proto.o
    In file included from psycopg/microprotocols_proto.c:27:
    In file included from ./psycopg/psycopg.h:37:
    ./psycopg/config.h:81:13: warning: unused function 'Dprintf' [-Wunused-function]
    static void Dprintf(const char *fmt, ...) {}
                ^
    1 warning generated.
    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch x86_64 -g -DPSYCOPG_VERSION=2.8.4 (dt dec pq3 ext lo64) -DPG_VERSION_NUM=120001 -DHAVE_LO64=1 -I/Library/Frameworks/Python.framework/Versions/3.8/include/python3.8 -I. -I/usr/local/include -I/usr/local/include/postgresql/server -c psycopg/typecast.c -o build/temp.macosx-10.9-x86_64-3.8/psycopg/typecast.o
    gcc -bundle -undefined dynamic_lookup -arch x86_64 -g build/temp.macosx-10.9-x86_64-3.8/psycopg/psycopgmodule.o build/temp.macosx-10.9-x86_64-3.8/psycopg/green.o build/temp.macosx-10.9-x86_64-3.8/psycopg/pqpath.o build/temp.macosx-10.9-x86_64-3.8/psycopg/utils.o build/temp.macosx-10.9-x86_64-3.8/psycopg/bytes_format.o build/temp.macosx-10.9-x86_64-3.8/psycopg/libpq_support.o build/temp.macosx-10.9-x86_64-3.8/psycopg/win32_support.o build/temp.macosx-10.9-x86_64-3.8/psycopg/solaris_support.o build/temp.macosx-10.9-x86_64-3.8/psycopg/connection_int.o build/temp.macosx-10.9-x86_64-3.8/psycopg/connection_type.o build/temp.macosx-10.9-x86_64-3.8/psycopg/cursor_int.o build/temp.macosx-10.9-x86_64-3.8/psycopg/cursor_type.o build/temp.macosx-10.9-x86_64-3.8/psycopg/column_type.o build/temp.macosx-10.9-x86_64-3.8/psycopg/replication_connection_type.o build/temp.macosx-10.9-x86_64-3.8/psycopg/replication_cursor_type.o build/temp.macosx-10.9-x86_64-3.8/psycopg/replication_message_type.o build/temp.macosx-10.9-x86_64-3.8/psycopg/diagnostics_type.o build/temp.macosx-10.9-x86_64-3.8/psycopg/error_type.o build/temp.macosx-10.9-x86_64-3.8/psycopg/conninfo_type.o build/temp.macosx-10.9-x86_64-3.8/psycopg/lobject_int.o build/temp.macosx-10.9-x86_64-3.8/psycopg/lobject_type.o build/temp.macosx-10.9-x86_64-3.8/psycopg/notify_type.o build/temp.macosx-10.9-x86_64-3.8/psycopg/xid_type.o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_asis.o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_binary.o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_datetime.o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_list.o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_pboolean.o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_pdecimal.o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_pint.o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_pfloat.o build/temp.macosx-10.9-x86_64-3.8/psycopg/adapter_qstring.o build/temp.macosx-10.9-x86_64-3.8/psycopg/microprotocols.o build/temp.macosx-10.9-x86_64-3.8/psycopg/microprotocols_proto.o build/temp.macosx-10.9-x86_64-3.8/psycopg/typecast.o -L/usr/local/lib -lpq -lssl -lcrypto -o build/lib.macosx-10.9-x86_64-3.8/psycopg2/_psycopg.cpython-38-darwin.so
    ld: library not found for -lssl
    clang: error: linker command failed with exit code 1 (use -v to see invocation)
    error: command 'gcc' failed with exit status 1
    ----------------------------------------
ERROR: Command errored out with exit status 1: /Users/DavidKronish/dev/citram/MyCampus-Backend/citramenv/bin/python3.8 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/8x/lls1w4m94l90p8qszpnrvzgw0000gp/T/pip-install-c2yxmbq8/psycopg2/setup.py'""'""'; __file__='""'""'/private/var/folders/8x/lls1w4m94l90p8qszpnrvzgw0000gp/T/pip-install-c2yxmbq8/psycopg2/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/8x/lls1w4m94l90p8qszpnrvzgw0000gp/T/pip-record-3aciztvp/install-record.txt --single-version-externally-managed --compile --install-headers /Users/DavidKronish/dev/citram/MyCampus-Backend/citramenv/bin/../include/site/python3.8/psycopg2 Check the logs for full command output.
</code></pre>
","<django><python-3.x><psycopg2><requirements>","2020-02-11 00:22:26","1832","2","1","60160523","<p>gcc cannot use -lssl flag by default so you should install openssl     </p>

<pre><code>brew install openssl
export LDFLAGS=""-L/usr/local/opt/openssl@1.1/lib""
export CPPFLAGS=""-I/usr/local/opt/openssl@1.1/include""
</code></pre>

<p>or install precompiled binary</p>

<pre><code>   pip install psycopg2-binary
</code></pre>
"
"60151207","How to build a conda environment with pytorch=0.3.1, since I keep getting conflicts","<p>I need to get an environment working with the following requirements, but it just won't do.
I have tried many things and always end up with something like below. Does anyone know how I can get an environment with the things that I need?</p>

<pre><code>conda create -n myenv python=3.5 pytorch=0.3.1
Collecting package metadata (repodata.json): done
Solving environment: - 
Found conflicts! Looking for incompatible packages.
This can take several minutes.  Press CTRL-C to abort.
failed                                                                                               

UnsatisfiableError: The following specifications were found to be incompatible with each other:



Package libffi conflicts for:
python=3.5 -&gt; libffi[version='3.2.*|&gt;=3.2.1,&lt;4.0a0']
Package numpy conflicts for:
pytorch=0.3.1 -&gt; numpy[version='&gt;=1.11.3,&lt;2.0a0']
Package openssl conflicts for:
python=3.5 -&gt; openssl[version='1.0.*|1.0.*,&gt;=1.0.2l,&lt;1.0.3a|&gt;=1.0.2m,&lt;1.0.3a|&gt;=1.0.2n,&lt;1.0.3a|&gt;=1.0.2o,&lt;1.0.3a|&gt;=1.0.2p,&lt;1.0.3a']
Package libstdcxx-ng conflicts for:
pytorch=0.3.1 -&gt; libstdcxx-ng[version='&gt;=5.4.0']
python=3.5 -&gt; libstdcxx-ng[version='&gt;=7.2.0|&gt;=7.3.0']
Package nccl conflicts for:
pytorch=0.3.1 -&gt; nccl[version='&lt;2']
Package libgcc-ng conflicts for:
pytorch=0.3.1 -&gt; libgcc-ng[version='&gt;=5.4.0']
python=3.5 -&gt; libgcc-ng[version='&gt;=7.2.0|&gt;=7.3.0']
Package readline conflicts for:
python=3.5 -&gt; readline[version='7.*|&gt;=7.0,&lt;8.0a0']
Package cudatoolkit conflicts for:
pytorch=0.3.1 -&gt; cudatoolkit=8.0
Package cudnn conflicts for:
pytorch=0.3.1 -&gt; cudnn[version='&gt;=7.0.5,&lt;=8.0a0']
Package cffi conflicts for:
pytorch=0.3.1 -&gt; cffi
Package tk conflicts for:
python=3.5 -&gt; tk[version='8.6.*|&gt;=8.6.7,&lt;8.7.0a0']
Package xz conflicts for:
python=3.5 -&gt; xz[version='&gt;=5.2.3,&lt;6.0a0|&gt;=5.2.4,&lt;6.0a0']
Package zlib conflicts for:
python=3.5 -&gt; zlib[version='&gt;=1.2.11,&lt;1.3.0a0']
Package python conflicts for:
pytorch=0.3.1 -&gt; python[version='&gt;=2.7,&lt;2.8.0a0|&gt;=3.5,&lt;3.6.0a0|&gt;=3.6,&lt;3.7.0a0']
Package sqlite conflicts for:
python=3.5 -&gt; sqlite[version='&gt;=3.20.1,&lt;4.0a0|&gt;=3.22.0,&lt;4.0a0|&gt;=3.23.1,&lt;4.0a0|&gt;=3.24.0,&lt;4.0a0']
Package pip conflicts for:
python=3.5 -&gt; pip
Package mkl conflicts for:
pytorch=0.3.1 -&gt; mkl[version='&gt;=2018.0.2,&lt;2019.0a0']
Package ncurses conflicts for:
python=3.5 -&gt; ncurses[version='6.0.*|&gt;=6.0,&lt;7.0a0|&gt;=6.1,&lt;7.0a0']
</code></pre>
","<python><pytorch><requirements><faster-rcnn><conflicting-libraries>","2020-02-10 13:12:53","1165","0","2","60162333","<p>I'm afraid you need to reinstall your dependencies firstly which should be corresponding to pytorch version with 0.3.1 in your vitual environment. First step, install python-3.5, and then each dependency with specified version, and finally pytorch-0.3.1.</p>
"
"60151207","How to build a conda environment with pytorch=0.3.1, since I keep getting conflicts","<p>I need to get an environment working with the following requirements, but it just won't do.
I have tried many things and always end up with something like below. Does anyone know how I can get an environment with the things that I need?</p>

<pre><code>conda create -n myenv python=3.5 pytorch=0.3.1
Collecting package metadata (repodata.json): done
Solving environment: - 
Found conflicts! Looking for incompatible packages.
This can take several minutes.  Press CTRL-C to abort.
failed                                                                                               

UnsatisfiableError: The following specifications were found to be incompatible with each other:



Package libffi conflicts for:
python=3.5 -&gt; libffi[version='3.2.*|&gt;=3.2.1,&lt;4.0a0']
Package numpy conflicts for:
pytorch=0.3.1 -&gt; numpy[version='&gt;=1.11.3,&lt;2.0a0']
Package openssl conflicts for:
python=3.5 -&gt; openssl[version='1.0.*|1.0.*,&gt;=1.0.2l,&lt;1.0.3a|&gt;=1.0.2m,&lt;1.0.3a|&gt;=1.0.2n,&lt;1.0.3a|&gt;=1.0.2o,&lt;1.0.3a|&gt;=1.0.2p,&lt;1.0.3a']
Package libstdcxx-ng conflicts for:
pytorch=0.3.1 -&gt; libstdcxx-ng[version='&gt;=5.4.0']
python=3.5 -&gt; libstdcxx-ng[version='&gt;=7.2.0|&gt;=7.3.0']
Package nccl conflicts for:
pytorch=0.3.1 -&gt; nccl[version='&lt;2']
Package libgcc-ng conflicts for:
pytorch=0.3.1 -&gt; libgcc-ng[version='&gt;=5.4.0']
python=3.5 -&gt; libgcc-ng[version='&gt;=7.2.0|&gt;=7.3.0']
Package readline conflicts for:
python=3.5 -&gt; readline[version='7.*|&gt;=7.0,&lt;8.0a0']
Package cudatoolkit conflicts for:
pytorch=0.3.1 -&gt; cudatoolkit=8.0
Package cudnn conflicts for:
pytorch=0.3.1 -&gt; cudnn[version='&gt;=7.0.5,&lt;=8.0a0']
Package cffi conflicts for:
pytorch=0.3.1 -&gt; cffi
Package tk conflicts for:
python=3.5 -&gt; tk[version='8.6.*|&gt;=8.6.7,&lt;8.7.0a0']
Package xz conflicts for:
python=3.5 -&gt; xz[version='&gt;=5.2.3,&lt;6.0a0|&gt;=5.2.4,&lt;6.0a0']
Package zlib conflicts for:
python=3.5 -&gt; zlib[version='&gt;=1.2.11,&lt;1.3.0a0']
Package python conflicts for:
pytorch=0.3.1 -&gt; python[version='&gt;=2.7,&lt;2.8.0a0|&gt;=3.5,&lt;3.6.0a0|&gt;=3.6,&lt;3.7.0a0']
Package sqlite conflicts for:
python=3.5 -&gt; sqlite[version='&gt;=3.20.1,&lt;4.0a0|&gt;=3.22.0,&lt;4.0a0|&gt;=3.23.1,&lt;4.0a0|&gt;=3.24.0,&lt;4.0a0']
Package pip conflicts for:
python=3.5 -&gt; pip
Package mkl conflicts for:
pytorch=0.3.1 -&gt; mkl[version='&gt;=2018.0.2,&lt;2019.0a0']
Package ncurses conflicts for:
python=3.5 -&gt; ncurses[version='6.0.*|&gt;=6.0,&lt;7.0a0|&gt;=6.1,&lt;7.0a0']
</code></pre>
","<python><pytorch><requirements><faster-rcnn><conflicting-libraries>","2020-02-10 13:12:53","1165","0","2","70571299","<p>You would first fire up a <a href=""https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html"" rel=""nofollow noreferrer"">conda environment</a> like so:</p>
<pre><code>conda create -n myenv python=3.6
</code></pre>
<p>You can then specify a specific pytorch version like so:</p>
<pre><code>conda install pytorch=0.4.1 cuda75 -c pytorch
</code></pre>
"
"60105569","Minimum hardware and software requirements to run mobile apps built with React Native","<p>I am looking to source some testing Android and iOS devices for React Native apps. I've looked at the <a href=""https://facebook.github.io/react-native/docs/getting-started"" rel=""nofollow noreferrer"">official docs</a>, but there isn't a specific section for it.</p>
","<android><ios><react-native>","2020-02-07 00:31:05","4062","0","2","60106020","<p>I don't think there is a set of 'minimum requirements' per se. React-native applications should work on most modern smartphones, and even some very old ones.</p>

<p>The caveat I would raise here is that it's more about how the app is written, there are many things you can do inside react-native that will kill performance on older devices, such as avoiding unnecessary UI element frame updates. (This can happen if you are hooking into the state changes non optimally)</p>

<p>I suggest having a look at some common anti-patterns when it comes to RN, a good place to start would be here: <a href=""https://facebook.github.io/react-native/docs/performance"" rel=""nofollow noreferrer"">https://facebook.github.io/react-native/docs/performance</a> (this page goes over common reasons why apps will be performing slowly.)</p>
"
"60105569","Minimum hardware and software requirements to run mobile apps built with React Native","<p>I am looking to source some testing Android and iOS devices for React Native apps. I've looked at the <a href=""https://facebook.github.io/react-native/docs/getting-started"" rel=""nofollow noreferrer"">official docs</a>, but there isn't a specific section for it.</p>
","<android><ios><react-native>","2020-02-07 00:31:05","4062","0","2","60107137","<p>For your scenario there is no any official smart devices which are recommended to use to test React Native applications. </p>

<p>You can use any of smart devices of both Android and iOS to test your applications.</p>

<p><strong>For testing your applications on Android :</strong></p>

<ul>
<li>Android 4.1 (API 16) or newer. ( You can find minSDKVersion from android studio app gradle file)</li>
</ul>

<p>So you can run your application any smart device on or above Android OS 4.1</p>

<p><strong>For testing your applications on iOS :</strong></p>

<ul>
<li>iOS 9.0 or newer ( You can find Target min OS version from Deployment Info on XCODE )</li>
</ul>

<p>So you can run your application any smart device on or above iOS 9.0</p>

<p><strong>Note :</strong></p>

<ul>
<li>My solution is to find devices with different screen sizes.</li>
<li>If you are going to test iOS application try to use different screen sizes and different os Apple devices like -> iPhone SE , iPhone 6s , iPhone 8 Plus , iPhone X</li>
<li>For iPhones try to test both notch devices and normal old devices because you need to avoid notch issues with height and width.</li>
<li>For Android try to use different android os running devices which have different screen sizes with different brands.</li>
<li>As example try to use both low end budget and high end flagship models.</li>
</ul>

<p><strong><em>You can find requirements from official git repo <a href=""https://github.com/facebook/react-native#-requirements"" rel=""nofollow noreferrer"">here</a></em></strong></p>
"
"59739151","NP Hard's relation to Requirements Engineering","<p>I want to know about NP-Hard from a requirements engineering point of view and not mathematical. Any input is appreciated.</p>
","<requirements><np><np-hard><requirements-management>","2020-01-14 17:44:17","40","0","1","59740361","<p><a href=""https://en.wikipedia.org/wiki/Requirements_engineering"" rel=""nofollow noreferrer"">Requirements engineering</a> is the process of defining, documenting and maintaining requirements in the engineering design process.The only connection to NP-hard problems I can imagine is the following:<br>
If a problem should be solved by an algorithm, require that an algorithm is used that is not NP-hard.<br>
NP-hard means essentially (not mathematically) that one has to compute all possible solutions to a problem, and than select the best one.<br>
The typical example is the <a href=""https://en.wikipedia.org/wiki/Travelling_salesman_problem"" rel=""nofollow noreferrer"">Traveling Salesman Problem</a>:<br>
Given a number of cities to visit, find the shortest visit that visited each city once.<br>
To find the shortest route, all possible routes have to be constructed, and the shortest one has then to be selected. The time to find this best solution grows exponentially with the number of cities, i.e. for a larger number of cities it is not solvable.<br>
PS: Of course, there are algorithms that solve this particular problem pretty well in reasonable time.</p>
"
"59734348","Is this Use Case correct?","<p>Its my first time making a use case and this is for my coursework.
I had to follow the case study below.</p>

<blockquote>
  <p><strong>Case Study 8:</strong> Warehouse Control System (WCS)<br/>
  A warehouse distributes health food and related products. Customers order a particular
  product and quantity from the warehouse. The Warehouse Control System WCS saves the
  order and provides to the customer the order number. The WCS generates a pick list and
  shopping label, which tells the order-picker person how many of each item to pick to fulfil
  the order. The order-picker picks the items, places them in the box, and places the shipping
  label on it. The order-picker then uses the WCS to specify whether the order is ready or
  not. Then the manager sends the order number, address, and the payment data to the
  shipping company. At the end of the day, the shipping company arrives to pick up all the
  orders. The inventory of the product in stock is carried out by the staff, but in others, it is
  outsourced to an external company. Each staff has a specific function which is either to
  raise an order or check the re-order level of the products in stock.<br/>
  The company wants to create a computer system that allows employees and external
  companies to access the application system on desktop. Model, design and implement a
  GUI client that can access the database using Visual Studio or any other software
  development package. The database must be designed from the class model and the entity
  data model using MS Access or Oracle database.</p>
</blockquote>

<p>I'm not sure:  should the Warehouse Control System (WCS) be an actor ? If not how to make the use case without it? </p>

<p>Here the use case I made:</p>

<p><a href=""https://i.stack.imgur.com/w9AAT.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/w9AAT.png"" alt=""enter image description here""></a></p>
","<uml><modeling><use-case><requirements><use-case-diagram>","2020-01-14 13:03:45","62","1","1","59734483","<p>The WCS is the system under consideration (the blue boundary).</p>

<p>Some observations:</p>

<ul>
<li>Use verb-subject(-object) to name use cases</li>
<li><code>Order ready</code> and the like are no use cases</li>
<li>Try to not start  functional decomposition (like it seems you did with that <code>Order ready</code></li>
</ul>

<p>I recommend to read Bittner/Spence about use cases as usual.</p>
"
"59585038","Best practice on mocdeling threshold (T) and objective (O) requirements in SysML?","<p>I have considered making a new requirement stereotype for which I can make threshold and objective attributes.  That is fine as far as capturing the requirement goes, but then becomes ugly when trying to do verification.  I'm starting to think they must be captured as separate requirements, which may also be ugly when doing traceability, satisfactions and verifications.  </p>

<p>For example, my requirement says ""The system shall be no more than 100kg. (T)"" and ""The system shall be no more than 80kg. (O)"" </p>

<p>Tracing this (or a similarly stated requirement) becomes ""ugly"" when making a test plan and showing which requirement has been satisfied.  If (O) is satisfied, then clearly (T) is also. However, the system will still pass test even though it may fail the verification for (O).  Perhaps it is standard to carry some requirements (O) that are not met.  I am new to this modeling method-so just curious. I wanted to know if there is already a best practice out there. I have been looking and haven't found anything that addresses this.</p>
","<uml><requirements><sysml><requirements-management>","2020-01-03 20:35:55","592","0","1","59757684","<p>From what I understood, you want to model, that a certain performance requirement has two values, a threshold and an objective. Meeting the objective is optional, but meeting the threshold is mandatory. In the test plan, the requirement will be shown as satisfied, if the design meets the threshold. Whether it also meets the objective could be evaluated with a model report, but that is only informative and doesn’t have any effect on the test outcome.</p>

<p>I would create a new stereotype «performance requirement» specializing «abstractRequirement» and «ConstraintBlock» (as described in the SysML specification Annex E.8.2). When you use this Stereotype, you need to add three parameters: <code>actualMass</code>, <code>thresholdMass</code> and <code>objectiveMass</code>. The constraint will be <code>{actualMass&lt;thresholdMass}</code>. The <code>objectiveMass</code> is then just informative (I have to think it through, how this could get used for reporting).</p>

<p>Another possibility would be to add a <code>mandatory/optional</code> field to the performance stereotype and use <code>optional</code> for objectives.</p>
"
"59430910","What is the difference between Architectural drivers/factors and architectural significant requirements","<p>I need to be able to explain the terms: architectural factor, architectural driver and architectural significant requirement. i found out that an architectural factor/driver are the same (correct me if i'm wrong).
but when i look up their definitions i get the following explanation:</p>

<p><strong>architectural driver:</strong>
Architectural drivers are formally defined as the set of requirements that have significant influence over your architecture.</p>

<p><strong>architecturally significant requirements:</strong>
architecturally significant requirements are those requirements that play an important role in determining the architecture of the system.</p>

<p>it seems to me both of them are requirements that have influence your architecture, however in the book of larman they are clearly introduced as 2 different things.</p>

<p>so can anyone tell me the exact difference between Architectural drivers/factors and architectural significant requirements </p>
","<architecture><requirements>","2019-12-20 20:17:14","174","1","1","60328053","<p>Good question! They are indeed confusing. I can add this: the way I see it is that among all requirements gathered for a project, only certain ones will achieve status of ASR once the develop-part-of-the-architecture-then-test cycle goes a few rounds and the picture becomes clearer.</p>

<p>Edit: On slide 18 <a href=""https://cs.gmu.edu/~rpettit/files/lectures/443-ASRs.pdf"" rel=""nofollow noreferrer"">here</a>, it says the following: </p>

<pre><code>Architecture drivers presentation
– Briefing by the architect on the driving business and quality attribute requirements: the ASRs.
</code></pre>

<p>To me that indicates that they could be seen as equivalent.</p>
"
"59083510","Insert an empty column in IBM (Telelogic) DOORS","<p>As a reviewer, I've to add an empty REVIEW column in a DOORS module. Actually I can add columns easily but they're associated to other attributes and there is no ""emtpty"" option to choose.</p>

<p>Thanks in advance!</p>
","<requirements><ibm-doors>","2019-11-28 07:17:08","470","1","1","59092624","<p>I'm sure you want to add content to the column as a result of your review, like ""OK"" or ""not OK"".
Content is stored in attributes. So, you first have to add a new <em>attribute</em> on object level to the module with the desired data type (like predefined values, boolean, string or text), and then add a <em>column</em> to your review view which shows the new attribute.</p>
"
"58836485","Sparx Enterprise Architect EA 15 - how to sort requirements of an element within a report","<p>While I run the publish to RTF functionality, the requirements in the generated report for an element are printed in an order I would like to influence.</p>

<p>Consider I have two requirements for an element, one requirement of type functional, one of type performance. The report first shows the performance and then the functional. I would prefer having all functional requirements listed before the performance ones.
How can this be influenced?</p>
","<report><enterprise-architect><requirements>","2019-11-13 11:50:03","301","2","1","58873571","<p>EA offers only 4 options to sort items in a template:</p>

<ul>
<li>Name </li>
<li>Tree Order</li>
<li>Modified date</li>
<li>Creation date</li>
</ul>

<p>You can set these options per template, or when generating a document
<a href=""https://i.stack.imgur.com/PcSbG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PcSbG.png"" alt=""enter image description here""></a></p>

<p>The trick is to getting this done is to use <strong>template fragments</strong>.</p>

<p>If the linked requirement type would be in the list of possible template filters this would have been rather easy.
You could simply create two template fragments, and set their filter to include only functional or technical requirements. Unfortunately the linked requirement type is not included in the available filters.</p>

<p>Alternative is to create two <a href=""https://www.sparxsystems.com/enterprise_architect_user_guide/15.0/model_publishing/custom_sql_fragments.html"" rel=""nofollow noreferrer"">SQL fragments</a>, one of the functional requirements, and another for the technical requirements.</p>

<p>Then add those to your main template in the order you need them to be.</p>
"
"58727347","What counts as functional requirement and what doesnt in the following example?","<p>For my homework, I have to write functional requirement of a game called downfall (<a href=""https://en.wikipedia.org/wiki/Downfall_(game)"" rel=""nofollow noreferrer"">see Wikipedia</a>).
We have to make this game, but with not two sides but n (any number of) sides.</p>

<p>In an example solution (another game), the teacher writes the functional requirements, then writes what use case they belong to.</p>

<p>I have created a use case diagram in which I have the player as an actor, and <code>ChooseDial</code>, <code>RotateDial</code> and <code>EndTurn</code> as use cases:</p>

<p><a href=""https://i.stack.imgur.com/PwUKy.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PwUKy.png"" alt=""enter image description here""></a></p>

<p>What I dont understand are the following:
Is the number of players functional requirement?
Is the table having two sides a functional requirement?
Is the goal of the game (getting coins from top to bottom) a functional requirement?
Is a rule like coins must reach bottom in order a functional requirement?</p>

<p>If they are, what use case could they belong to? Is my use case diagram wrong?</p>

<p>I have no idea where to put these functional requirements, because I feel like they arent part of any of my use cases.</p>
","<uml><modeling><use-case><requirements><use-case-diagram>","2019-11-06 09:54:36","309","1","2","58729608","<p>Requirements management (RM) can be tricky indeed. A requirement like <em>The board must have two sides</em> seems to be more involved in the design, rather than the use case. In such cases you could relate that to the boundary rather than a single use case. That will indicate it's some ""global"" requirement (similar to a non-functional requirement). Usually in a project you start with a more or less strange mix of requirements mixed in user stories. The business analyst (BA) has to comb that information and come up with decent use cases (synthesize the added values). The system architect (with the BA) will then go through requirements and use cases to come up with a (business) class model.</p>

<p>There are tons of books and procedures describing RM. Lots of seminars too. I think if you grasp the condensed idea above you're ready to start. It's a marathon to start...</p>
"
"58727347","What counts as functional requirement and what doesnt in the following example?","<p>For my homework, I have to write functional requirement of a game called downfall (<a href=""https://en.wikipedia.org/wiki/Downfall_(game)"" rel=""nofollow noreferrer"">see Wikipedia</a>).
We have to make this game, but with not two sides but n (any number of) sides.</p>

<p>In an example solution (another game), the teacher writes the functional requirements, then writes what use case they belong to.</p>

<p>I have created a use case diagram in which I have the player as an actor, and <code>ChooseDial</code>, <code>RotateDial</code> and <code>EndTurn</code> as use cases:</p>

<p><a href=""https://i.stack.imgur.com/PwUKy.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PwUKy.png"" alt=""enter image description here""></a></p>

<p>What I dont understand are the following:
Is the number of players functional requirement?
Is the table having two sides a functional requirement?
Is the goal of the game (getting coins from top to bottom) a functional requirement?
Is a rule like coins must reach bottom in order a functional requirement?</p>

<p>If they are, what use case could they belong to? Is my use case diagram wrong?</p>

<p>I have no idea where to put these functional requirements, because I feel like they arent part of any of my use cases.</p>
","<uml><modeling><use-case><requirements><use-case-diagram>","2019-11-06 09:54:36","309","1","2","58735870","<h3>About requirements</h3>

<p>First, let's handle the requirement question: </p>

<ul>
<li>A <a href=""https://en.wikipedia.org/wiki/Functional_requirement"" rel=""nofollow noreferrer"">functional requirement</a> tells something about what a software shall do. Everything related to goal, the gameplay or the rules of the game, is a functional requirement.</li>
<li>A <a href=""https://en.wikipedia.org/wiki/Non-functional_requirement"" rel=""nofollow noreferrer"">non functional requirement</a> tells something about how the software shall be, for example how accurate, how performant, how easy to use, how easy to maintain. Your narrative shows no such requirements.  </li>
</ul>

<h2>About use-cases</h2>

<p>Use case driven software development methods start with the high-level user's goals that are captured in use-cases. Personally, I see only one such goal:  </p>

<p><a href=""https://i.stack.imgur.com/QkPWW.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QkPWW.png"" alt=""enter image description here""></a></p>

<p><strong>Very rare usage</strong>:  a <a href=""https://www.uml-diagrams.org/use-case-actor-association.html"" rel=""nofollow noreferrer"">multiplicity on the actor side</a> of the use case.  This says that 2 or more instances of players are involved in an instance of the use case.  Of course, this makes sense only for the game as a whole, not for individual actions (like you have in your diagram). </p>

<p>In your diagram, you have shown 3 use cases: </p>

<ul>
<li>is <code>EndTurn</code> an independent goal that the user may freely decide to chose ?  No ! It's what always follows a player action.  So this is definitely not a use case.  </li>
<li>you say that <code>RotateDials</code> <a href=""https://www.uml-diagrams.org/use-case-extend.html"" rel=""nofollow noreferrer"">extends</a> <code>ChooseDials</code>. This means that a player could <code>ChooseDials</code> but not rorate it.  Is this a valid scenario ?    </li>
<li>if on the other hand you'd say that <code>ChooseDials</code> <a href=""https://www.uml-diagrams.org/use-case-include.html"" rel=""nofollow noreferrer"">includes</a> <code>RotateDials</code>, the latter would always happen. But then, wouldn't <code>ChooseDial</code> not be more than just choosing a dial ?  Shouldn't it then be called <code>PlayTurn</code> ?  </li>
</ul>

<p>I could understand that for learning purpose, you'd want to decompose the <code>Play game</code> in more detailed use-cases.  Typically, once the players try to reach their goal <code>Play game</code>, this might include sub-goals of <code>Play  turn</code>.  As long as it is goal-oriented, and not too detailed, this is ok.  But do <a href=""https://sce.uhcl.edu/helm/RationalUnifiedProcess/process/modguide/md_ucmod.htm#Avoiding%20Functional%20Decomposition"" rel=""nofollow noreferrer"">avoid simple functional decomposition</a> (it doesn't help for being more user-driven, and use-cases are not functions ). And, above all, do not misuse a use-case diagram for trying to show a sequence of <a href=""https://www.uml-diagrams.org/activity-diagrams.html"" rel=""nofollow noreferrer"">activities</a>.       </p>

<h2>Requirement traceability</h2>

<p>The use cases do not capture the full requirements.  It captures the most enssential thing:  the purpose of the system and the user goals.  </p>

<p>When writing down the requirements, it's then useful to get guided by the use-cases and their narrative, and to trace-back every use-case specific requirement.    </p>

<p>But of course, there are some general requirements as well.  These are not specific to a particular use-case. Some are even common to all use case. Mark these as general requirements (e.g. use case <code>*</code>).    </p>
"
"58718076","I am having difficulty importing code from a server?","<p>I'm working on a project for a client and his code is running on his server. I've tried to download the code so that I can run a local version on my computer. The project is at least 5 years old and runs on Python 2.7. </p>

<p>The problem is I can't run <code>python install -r requirements.txt</code> without running into errors, because some of the files are no longer available. Specifically something called ""sorl"", ""django-page-cms"", ""mercurial"", and a few files the developer hosted on other sites.</p>

<p>If his website is working &amp; the code is functioning on his server, that means there is a working version of these packages stored on the server? How could I find them?</p>
","<python><python-2.7><server><package><requirements>","2019-11-05 19:21:26","21","0","1","58718130","<p>You can try starting <code>python</code> while <code>ssh</code>ed into the server and doing an import like:</p>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; import sorl
&gt;&gt;&gt; sorl.__file__
'/home/jmunsch/PycharmProjects/projectname/venv_ok/lib/python3.6/sorl/__init__.py'
</code></pre>

<p>And if the os is the same then <code>rsync</code> the files over.</p>

<p>see:
 - <a href=""https://stackoverflow.com/questions/9090817/copying-files-using-rsync-from-remote-server-to-local-machine"">Copying files using rsync from remote server to local machine</a></p>
"
"58533074","BDD script for performance of text showing up on summary pane as I type","<p>I want to write a BDD for performance requirements but am not too sure how to separate out the UI details from the requirement itself in this case. I have got a summary plane in my application where text that I enter in my main form as I type appears in the summary plane. The requirement I wrote is below: </p>

<pre><code>Given as a User
When I fill in ""Bob"" as ""Customer Name""
Then ""Bob"" appears as ""Customer Name"" in the summary plane
</code></pre>

<p>I got two questions. Is this advisable and how would I add details that the name ""Bob"" should appear in the summary plane as I type and not appear later ?</p>
","<testing><bdd><requirements>","2019-10-24 01:53:07","34","0","1","58674428","<p>I can think of two ways to do this. You could spawn another thread that does the typing and the test thread checks the auto complete for the given text. The other way would be to type each letter individually and check after each character to see if the expected text shows up.</p>

<p>I think the easiest way is to check after each character has been typed. As long as you see the expected text at least once in between typing each character, then the step passes.</p>
"
"58466332","Is""always"" a workable term to describe the uptime of a server?","<p>since me and my colleagues had a discussion about this, I wanted to ask, if you would use the term ""always"" to describe the uptime of a server in a requirement.</p>

<p>Example:
The server should be always reachable.</p>

<p>Since, in my opinion, alsways can't be measured, I would rather write the requirement like this:</p>

<p>The uptime of the Server should be >= 99%.</p>

<p>Thanks in advance!</p>
","<requirements><uptime><service-level-agreement>","2019-10-19 17:39:26","41","-1","1","58466423","<p>Do not use always, it isn't possible to achieve. Uptime is discussed in terms of nines: <a href=""https://en.wikipedia.org/wiki/High_availability#%22Nines%22"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/High_availability#%22Nines%22</a></p>

<p>Amazon S3 for example, offers <a href=""https://docs.aws.amazon.com/AmazonS3/latest/dev/DataDurability.html"" rel=""nofollow noreferrer"">4 nines of availability</a> (99.99%).</p>

<p>Look at: <a href=""https://uptime.is/"" rel=""nofollow noreferrer"">https://uptime.is/</a> to fully understand how much downtime you are allowed for a given sla.</p>
"
"58442527","How do I write this BDD script?","<p>I have an exit button in my application which I want to write a story for. It behaves this way: </p>

<ol>
<li>If I have content filled in the form I am editing and I click on the exit button, it will pop up with a confirmation message letting me know there are unsaved content and if I am sure I want to exit from the page. </li>
<li>If I do not have any content filled in the form I am editing and I click on the exit button, the confirmation message will not show up and I am instantly exited from the form. </li>
</ol>

<p>What I have so far is something like this: </p>

<pre><code>Given as a User on New Profile page
And I fill in the customer name = ""Bob""
When I click on the Exit button
And I click on the ""Ok"" in the confirmation dialog
Then I will be redirected to the landing page.
</code></pre>

<p>My question is the part on <code>And when I fill in the customer name = ""Bob""</code> only covers one of the fields. How do I write the story in a succinct way that if any of the fields are filled or chosen (drop downs), the confirmation dialog will show up ? Secondly, is my story correct ?</p>
","<testing><automation><bdd><requirements>","2019-10-18 00:51:38","78","0","2","58447135","<p>you can use datatable in that particular step as below </p>

<pre><code>Given as a User on New Profile page
And I fill in the customer details
|name|address1|adress2|pincode| //can be accessed with DataTable datatype in SD*
When I click on the Exit button
And I click on the ""Ok"" in the confirmation dialog
Then I will be redirected to the landing page.
</code></pre>

<p>*SD-Stepdefinitions</p>
"
"58442527","How do I write this BDD script?","<p>I have an exit button in my application which I want to write a story for. It behaves this way: </p>

<ol>
<li>If I have content filled in the form I am editing and I click on the exit button, it will pop up with a confirmation message letting me know there are unsaved content and if I am sure I want to exit from the page. </li>
<li>If I do not have any content filled in the form I am editing and I click on the exit button, the confirmation message will not show up and I am instantly exited from the form. </li>
</ol>

<p>What I have so far is something like this: </p>

<pre><code>Given as a User on New Profile page
And I fill in the customer name = ""Bob""
When I click on the Exit button
And I click on the ""Ok"" in the confirmation dialog
Then I will be redirected to the landing page.
</code></pre>

<p>My question is the part on <code>And when I fill in the customer name = ""Bob""</code> only covers one of the fields. How do I write the story in a succinct way that if any of the fields are filled or chosen (drop downs), the confirmation dialog will show up ? Secondly, is my story correct ?</p>
","<testing><automation><bdd><requirements>","2019-10-18 00:51:38","78","0","2","58486603","<p>You can use a scenario outline in conjunction with parameterizing the step that fills in a field with a dummy value.</p>

<pre><code>Scenario Outline: The user is taken to the landing page after exiting new user profile
    Given I am registering as a new user
    And I have filled in the ""&lt;Profile Field&gt;"" field
    And I have chosen to exit the current page
    When I confirm I want to abandon my unsaved changes
    Then I should be redirected to the landing page

Examples:
    | Profile Field |
    | Name          |
    | Phone Number  |
    | ...           |
</code></pre>

<p>You didn't post the scenario title, which is just as important as the wording for each step, so I made on up. The important thing is to focus on the behavior:</p>

<blockquote>
  <p>Scenario Outline: The user is taken to the landing page after exiting new user profile</p>
</blockquote>

<p>The step <code>Given I am registering as a new user</code> should navigate to the new user profile page.</p>

<p>The step <code>Given I have filled in the ""&lt;Profile Field&gt;"" field</code> should accept an argument where you name the field you want filled in. The definition for this step should fill in the field with dummy information, or blindly chose an option in a dropdown.</p>

<p>The step <code>Given I have chosen to exit the current page</code> should click the exit button. Notice there is no mention of ""clicking"" on anything. You should avoid language in your steps the sound like instructions on how to use the user interface, and instead focus on the behavior of the application using business terms.</p>

<p>Same thing for <code>When I confirm I want to abandon my unsaved changes</code>. It does not mention clicking on anything. It just focuses on the behavior (choosing to abandon your changes). The step definition should know how to click the ""OK"" button in the confirmation dialog. The fact a confirmation dialog even exists should only be known by the step definition.</p>

<p>Finally, <code>Then I should be redirected to the landing page</code> makes your assertion about where the user ends up. I like to include the word ""should"" in my <code>Then</code> steps. If find it easier to pinpoint the test failure when a <code>Then</code> step fails. The condition that comes after the ""should"" in my step is usually the thing that fails.</p>
"
"58344997","Batch tag creation in enterprise architect with javascript","<p>I've created a EA project with a bunch of requirements, that needs to be imported into Redmine. Instead of doing it by hand, We want to use a tool
This tool needs to use some specific tag for sync data, so I need to create five tags for every requirement, and I simply cannot do it for every requirement since I've hundreds of them.</p>

<p>I've starting to check the javascript scripting, and I've noticed a function like this one in one example:</p>

<pre><code>/**
 * Sets the specified TaggedValue on the provided element. If the provided element does not already
 * contain a TaggedValue with the specified name, a new TaggedValue is created with the requested
 * name and value. If a TaggedValue already exists with the specified name then action to take is
 * determined by the replaceExisting variable. If replaceExisting is set to true, the existing value
 * is replaced with the specified value, if not, a new TaggedValue is created with the new value.
 *
 * @param[in] theElement (EA.Element) The element to set the TaggedValue value on
 * @param[in] taggedValueName (String) The name of the TaggedValue to set
 * @param[in] taggedValueValue (variant) The value of the TaggedValue to set
 * @param[in] replaceExisting (boolean) If a TaggedValue of the same name already exists, specifies 
 * whether to replace it, or create a new TaggedValue.
 */
function TVSetElementTaggedValue( theElement /* : EA.Element */, taggedValueName /* : String */, taggedValueValue /* : variant */, replaceExisting /* : boolean */ ) /* : void */
{
    if ( theElement != null &amp;&amp; taggedValueName.length &gt; 0 )
    {
        var taggedValue as EA.TaggedValue;
        taggedValue = null;

        // If replace existing was specified then attempt to get a tagged value from the element
        // with the provided name
        if ( replaceExisting )
            taggedValue = theElement.TaggedValues.GetByName( taggedValueName );

        if ( taggedValue == null )
        {
            taggedValue = theElement.TaggedValues.AddNew( taggedValueName, taggedValueValue );
        }
        else
        {
            taggedValue.Value = taggedValueValue;
        }

        taggedValue.Update();
    }
}
</code></pre>

<p>What I need to do is how to retrieve a list of requirements that are stored in a specific package, and how to cycle them in order to apply this function.</p>

<p>Any help would be appreciated.</p>
","<javascript><enterprise-architect><requirements>","2019-10-11 16:10:26","131","0","1","58347630","<p>Basically:</p>

<pre><code>for e in myPackage.elements:
    if e.type == 9: #code for Requirement
        print(e.name)
        for t in e.taggedValues:
            print(t.name, t.value, t.notes)
</code></pre>

<p>will list the element of the package and all their tagged values.</p>

<p>This it Python, but it's not difficult to translate to any other language.</p>
"
"58141835","Map a mocha test to jira id","<p>I have a bunch of mocha tests, is there a way to map every test to a jira ticket? The intention behind it is, when I have the test report, I click on any test, and it takes me back to the actual jira page. (Tests to Requirements mapping)</p>

<p>NOTE: We do not have a test management tool yet. So will be using JIRA ticket as the source of truth.</p>

<p>Any pointers around this would be really helpful.</p>
","<javascript><automation><mocha.js><jira><requirements>","2019-09-27 22:17:28","545","1","1","58348990","<p>I have the below implementation for cypress tests:</p>

<ol>
<li>I include the JIRA issue number in the test title. </li>
<li>There are cypress events, at the end of every test, I grab the title and strip off the JIRA id and pass it to the mochawesome context.
cypress/support/index.js</li>
</ol>

<pre><code>Cypress.on('test:after:run', (test, runnable) =&gt; {
  const { parent } = runnable;

  const jiraId = test.title;
  jiraId.replace(/\w+-\w+/, match =&gt; {
    const name = match;
    addContext(
      { test },
      {
        title: 'JIRA',
        value: `https://jira.sendgrid.net/browse/${name}`,
      }
    );
  });
});
</code></pre>

<ol start=""3"">
<li>Then in the test reports it looks like this.</li>
</ol>

<p><a href=""https://i.stack.imgur.com/oQu4a.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/oQu4a.png"" alt=""enter image description here""></a></p>

<ol start=""4"">
<li>Click on the jira link and you can navigate to your actual jira ticket.</li>
</ol>
"
"58049762","Does jquery $.get or cordova-plugin-media use or incorporate cryptography?","<p>When submitting an app (created with Cordova and XCode) for iTunes, I'm asked ""Is your app designed to use cryptography or does it contain or incorporate cryptography?"" My app uses the jquery $.get statement to pull files from a https URL and also uses the cordova-plugin-media plugin to access files with an https URL. If it is only accessing files on a secure site, I'm not sure if this applies to export compliance and cryptography.</p>

<p>Apple gives this link, but it doesn't clarify my question.
<a href=""https://www.bis.doc.gov/index.php/policy-guidance/encryption/4-reports-and-reviews/a-annual-self-classification"" rel=""nofollow noreferrer"">https://www.bis.doc.gov/index.php/policy-guidance/encryption/4-reports-and-reviews/a-annual-self-classification</a></p>

<p>I'm still not sure if encryption is built in to the plugin or Cordova app automatically since I am accessing an external https resource, or if simply accessing a URL that is https through the app qualifies as use of encryption.</p>

<p>Related article: <a href=""https://www.cocoanetics.com/2017/02/itunes-connect-encryption-info/"" rel=""nofollow noreferrer"">iTunes connect encryption info</a></p>

<p>If I select ""Yes"" to ""Only makes calls over HTTS"" I get this statement, which appears to indicate I still need to submit a year-end self classification report because I'm getting a file on an https website?</p>

<blockquote>
  <p>""If you are making use of ATS or making a call to HTTPS, you are required to submit a year-end self classification report to the US government.""</p>
</blockquote>

<p>Should I just change my calls to be http instead? But the website redirects to https.</p>

<p>Another related link which I can't understand completely: <a href=""https://stackoverflow.com/questions/2135081/does-my-application-contain-encryption/40919650#40919650"">Does my application &quot;contain encryption&quot;?</a></p>
","<jquery><ios><cordova><itunes><requirements>","2019-09-22 13:40:39","74","1","1","58404864","<p>Apple support wouldn't answer the question. I never heard back from biz.doc.gov.</p>

<p>The best help I've seen so far is this:
<a href=""https://kitefaster.com/2017/08/10/encryption-export-compliance-ios-apps/"" rel=""nofollow noreferrer"">https://kitefaster.com/2017/08/10/encryption-export-compliance-ios-apps/</a>
which seems to say that if I am using https to get an external resource, then I need to submit an annual report. </p>

<p>I think to be safe I will just say it utilizes encryption and submit the year-end self classification report. Info on the report is here, with a sample document provided: <a href=""https://www.bis.doc.gov/index.php/policy-guidance/encryption/4-reports-and-reviews/a-annual-self-classification"" rel=""nofollow noreferrer"">https://www.bis.doc.gov/index.php/policy-guidance/encryption/4-reports-and-reviews/a-annual-self-classification</a></p>

<p>This link also gives good direction:
<a href=""https://stackoverflow.com/questions/2135081/does-my-application-contain-encryption/40919650#40919650"">Does my application &quot;contain encryption&quot;?</a></p>
"
"57994129","Is OfficeOpenXML required or not","<p>I am confused by the statement 
""EPPlus is a .NET library that reads and writes Excel files using the Office Open XML format (xlsx). EPPlus has no dependencies other than .NET. ""</p>

<p>then the following statement:</p>

<p>""The first thing you do is to create an instance to the ExcelPackage class. To do that you first need to add a using directive to OfficeOpenXml namespace in the top of your file. This is the top namespace in EPPlus;
using OfficeOpenXml;""</p>

<p>so, should I always import OfficeOpenXml?  The datatable to spreadsheet code works fine without it...</p>

<p>Thanks</p>
","<requirements>","2019-09-18 13:39:13","683","0","1","58018075","<p>Those two statements aren't contradictory.  EPPlus doesn't require anything other than .NET to run.  And the ""OfficeOpenXml"" namespace is part of EPPlus.  </p>

<p>""ExcelPackage"" is a class in the ""OfficeOpenXml"" namespace, so you could use a ""using OfficeOpenXml"" or you could fully qualify it as ""OfficeOpenXml.ExcelPackage"".</p>
"
"57746951","Function description vs possible implementation on C++ reference","<p>In both the reference pages of <a href=""https://en.cppreference.com/w/cpp/algorithm/lower_bound"" rel=""nofollow noreferrer""><code>std::lower_bound</code></a> and <a href=""https://en.cppreference.com/w/cpp/algorithm/upper_bound"" rel=""nofollow noreferrer""><code>std::upper_bound</code></a> from <a href=""https://en.cppreference.com/w/"" rel=""nofollow noreferrer"">C++ reference</a> I read</p>

<blockquote>
  <p>[...] uses <code>operator&lt;</code> to compare the elements, [...]</p>
</blockquote>

<p>This is very useful to me, because with this information I know that, even if the latter function</p>

<blockquote>
  <p>Returns an iterator pointing to the first element in the range <code>[first, last)</code> that is <em>greater</em> than <code>value</code></p>
</blockquote>

<p>it still uses the <code>operator&lt;</code> to do so, and not the <code>operator&gt;</code>, so the former has to be defined for the class/type of the objects stored in the container. The <strong>Possible implementation</strong> section, with the line <code>if (!(value &lt; *it)) {</code>, just confirms this.</p>

<p>However, for instance, the reference page for <a href=""https://en.cppreference.com/w/cpp/algorithm/remove"" rel=""nofollow noreferrer""><code>std::remove</code></a>, for which I read that</p>

<blockquote>
  <p>Removes all elements that are <em>equal to</em> <code>value</code></p>
</blockquote>

<p>does not mention any <code>oparator</code> at all, so in principle I would not know which one/ones is/are assumed to be defined in the class of the objects stored in the container. The <strong>Possible implementation</strong> uses <code>operator==</code> (see the line <code>if (!(*i == value))</code>).</p>

<p>Hence my question: is it intentional that the documentation pages of some functions don't specify the ""requirements"" that the classes on which the function is called must satisfy?</p>
","<c++><standards><requirements>","2019-09-01 14:44:36","90","2","1","57747037","<p>While cppreference is generally quite good, it is a community-maintained project; not official documentation.  It also sometimes uses slightly ambiguous wording to make the text more understandable.</p>

<p>For the official requirements, we must turn to the standard.  There, all of these requirements are explicitly spelled out:</p>

<p>From <a href=""http://eel.is/c++draft/lower.bound"" rel=""nofollow noreferrer"">[lower.bound]</a></p>

<blockquote>
  <p>Let <code>comp</code> be <code>less{}</code> and <code>proj</code> be <code>identity{}</code> for overloads with no parameters by those names.<br>
  ...<br>
  <em>Returns</em>: The furthermost iterator <code>i</code> in the range <code>[first, last]</code> such that for every iterator <code>j</code> in the range <code>[first, i)</code>, <code>bool(invoke(comp, invoke(proj, *j), value))</code> is <code>true</code>.</p>
</blockquote>

<p>From <a href=""http://eel.is/c++draft/upper.bound"" rel=""nofollow noreferrer"">[upper.bound]</a></p>

<blockquote>
  <p>Let <code>comp</code> be <code>less{}</code> and <code>proj</code> be <code>identity{}</code> for overloads with no parameters by those names.<br>
  ...<br>
  <em>Returns</em>: The furthermost iterator <code>i</code> in the range <code>[first, last]</code> such that for every iterator <code>j</code> in the range <code>[first, i)</code>, <code>!bool(invoke(comp, invoke(proj, *j), value))</code> is <code>true</code>.</p>
</blockquote>

<p>From <a href=""http://eel.is/c++draft/alg.remove"" rel=""nofollow noreferrer"">[alg.remove]</a></p>

<blockquote>
  <p>Let <em>E</em> be<br>
  -- <code>bool(*i == value)</code> for <code>remove</code>,<br>
  ...<br>
  <em>Effects</em>: Eliminates all the elements referred to by iterator <code>i</code> in the range <code>[first, last)</code> for which <em>E</em> holds.</p>
</blockquote>

<p>There is no ambiguity in these descriptions.  <code>std::lower_bound</code> and <code>std::upper_bound</code> use <code>std::less</code> to do their comparisons by default, and <code>std::remove</code> uses <code>operator==</code>.</p>
"
"57414686","OSGi: What's the difference between Import-Package/Export-Package and Require-Capability/Provide Capability?","<p>I am currently working with the OSGi framework but I have a question about some concepts that are not 100% clear to me. I have searching for it myself but I could not find a decent answer that clearly explains it.</p>

<p>In a bundle his manifest header 2 of the headers that get used are <code>Import-Package</code> and <code>Export-Package</code>. The names speak for themselves: a demand for a certain package and a offering of a certain package. In order to get that package (or give that package), the complete bundle must be installed in the framework where the <em>Import</em> is needed.</p>

<p>But then we get to the part of the <code>Requirements-Capabilities</code> model. This can practically do the same as the <code>Import-Package</code> and <code>Export-Package</code> headers. There are also headers for this <code>Requirements-Capability</code> model: <code>Require-Capability</code> and <code>Provide-Capability</code>. Again these stand for demanding something and for providing something.</p>

<p>I know that <code>Requirements-Capability</code> model was only introduced later on in the development of the OSGi specification(s). Can't exactly find at what year and version it was presented. </p>

<p>But,</p>

<ul>
<li><p>Why has this been added to the specification? I don't see what it has more to offer than what the <code>Import</code>/<code>Export-package</code> already offered: creating dependencies on other packages/bundles?</p></li>
<li><p>Could someone give me a better understanding in the difference (pro's and con's) between these 2 sets of concepts?</p></li>
</ul>
","<java><osgi><requirements><capability>","2019-08-08 14:15:21","1648","13","2","57415720","<p>When we started with OSGi in 1998 we had some clear requirements but of course, no clear view of what would come out of it. So we started to explicitly model the requirements and capabilities we had: packages. The Import-Package requires a capability and that capability is provided by an Export-Package. </p>

<p>In 2003 Eclipse wanted to start using OSGi but they need a facility to require another bundle, they did not like the idea of exporting and importing all their packages. Actually, at that time they failed to see the benefit of packages. To satisfy them we added Require-Bundle and Fragment-Host (another one of their desires that turned out not to be so good.) </p>

<p>After we specified OSGi 4.x with these extensions we starting thinking about a repository, Richard had developed the Oscar Bundle Repository. Analyzing the situation with the new headers in OSGi 4.0 it became clear that the implementation of Import-Package looked a lot like Require-Bundle, and even resembled Fragment-Host processing. </p>

<p>In 2006 Richard S. Hall and I wrote <a href=""https://raw.githubusercontent.com/wiki/barchart/barchart-service/OBR-RFC-112.pdf"" rel=""noreferrer"">RFC 112</a> proposing a more generic model that captured the semantics of the existing dependency model but was not specific for each <em>type</em> of requirement. I.e. for the Framework <em>resolver</em> the Import-Package and Require-Bundle only differ in their <em>namespace</em>. Thinking of Import-Package as a generic requirement and Export-Package as a generic capability made the repository model extremely simple. Even better, it was extendable since we could always add more namespaces. This made the resolver completely independent of the actual namespaces used.</p>

<p>After some very heated discussions, the OSGi Core Platform Expert Group decided to accept the basic idea and developed the Requirements and Capabilities specifications. Although this was originally a model for the repository, it turned out to be highly useful for the Framework itself. We decided therefore to adapt the existing specifications to this model. OSGi 4.3 internally models the Import-Package, Export-Package, Require-Bundle, etc. as requirements and capabilities of a <em>resource</em> (the bundle). For backward compatibility, we kept the existing headers but they are internally translated to requirements and capabilities.</p>

<p>Then finally to the answer to your question. Over time the OSGi specifications added more and more <em>namespaces</em>. A namespace is like a <em>type</em> for a Requirement and a Capability. It defines the semantics of a set of properties of a Capability in that namespace. A Requirement is a filter expression that is asserted on those properties. A <em>Resource</em> has a set of Capabilities that are provided to the runtime when all its Requirements are satisfied. It is the task of the <em>Resolver</em> to find a set of resources that are all satisfied with each other's capabilities and capabilities provided by the runtime.</p>

<p>For example, we added the <code>osgi.ee</code> namespace that defines exactly on what VM's the bundle can run. We added the <code>osgi.extender</code> namespace that models a dependency on an external program like the Service Component Runtime (SCR). Most SCR components do not require any package from the SCR itself, we tried hard to make them as independent as possible. However, a SCR component will sit useless unless some bundle in the runtime provides the SCR functionality. Notice that this cannot use Require-Bundle because there are multiple implementations of SCR. I think there are about 20 namespaces. Each namespace is defined in a <code>Namespace</code> class.</p>

<p>This model has given the OSGi a number of advantages:</p>

<ul>
<li><strong>Cohesion</strong> Although the specification has added many namespaces the resolver implementations never had to change since they worked on the generic model.</li>
<li><strong>Fine-Grained</strong> OSGi bundles are unique in how they describe their dependencies in a very fine-grained way. All module systems I know tend to use the simple module-to-module dependency that does not allow substitution.</li>
<li><strong>Flexible</strong> Since the Framework reifies the dependencies between bundles it is possible in runtime to leverage these dependencies. For example, in OSGi enRoute I linked a bundle to its web page traversing these runtime wirings. </li>
</ul>

<p>I personally consider the Requirements and Capability model of OSGi one of its best kept secrets. As far as I can see it could be used in a lot of areas to improve many development projects into the world of software engineering.</p>

<p>The only disappointing part in this question is that I thought we'd described this pretty well in the <a href=""https://osgi.org/specification/osgi.core/7.0.0/framework.module.html#framework.module.dependencies"" rel=""noreferrer"">Core specification</a>? :-)</p>
"
"57414686","OSGi: What's the difference between Import-Package/Export-Package and Require-Capability/Provide Capability?","<p>I am currently working with the OSGi framework but I have a question about some concepts that are not 100% clear to me. I have searching for it myself but I could not find a decent answer that clearly explains it.</p>

<p>In a bundle his manifest header 2 of the headers that get used are <code>Import-Package</code> and <code>Export-Package</code>. The names speak for themselves: a demand for a certain package and a offering of a certain package. In order to get that package (or give that package), the complete bundle must be installed in the framework where the <em>Import</em> is needed.</p>

<p>But then we get to the part of the <code>Requirements-Capabilities</code> model. This can practically do the same as the <code>Import-Package</code> and <code>Export-Package</code> headers. There are also headers for this <code>Requirements-Capability</code> model: <code>Require-Capability</code> and <code>Provide-Capability</code>. Again these stand for demanding something and for providing something.</p>

<p>I know that <code>Requirements-Capability</code> model was only introduced later on in the development of the OSGi specification(s). Can't exactly find at what year and version it was presented. </p>

<p>But,</p>

<ul>
<li><p>Why has this been added to the specification? I don't see what it has more to offer than what the <code>Import</code>/<code>Export-package</code> already offered: creating dependencies on other packages/bundles?</p></li>
<li><p>Could someone give me a better understanding in the difference (pro's and con's) between these 2 sets of concepts?</p></li>
</ul>
","<java><osgi><requirements><capability>","2019-08-08 14:15:21","1648","13","2","57415762","<p>The <a href=""https://blog.osgi.org/2015/12/using-requirements-and-capabilities.html"" rel=""noreferrer"">requirements and capabilities</a> model is an extension of the Import/Export package model. Actually you can express a package import as a requirement and a package export as a capability.</p>

<p>Exporting / Importing packages allows for loose coupling. You export an API and the client imports it. This way the client only needs to know about the API so loose coupling is achieved.</p>

<p>At a later stage when you assemble the application out of bundles this loose coupling makes it difficult to automate the process.</p>

<p>If you just provide your client bundle to a resolver then it can only automatically find that you need the bundle that provides the API. If the implementation of the API is in a different bundle then the resolver has no way to know that you need it.</p>

<p>This is where requirements can help. Let's take the <a href=""https://osgi.org/specification/osgi.cmpn/7.0.0/service.http.whiteboard.html"" rel=""noreferrer"">HTTP Whiteboard model</a>. A bundle that want to publish a servlet needs to import the servlet api package but is also needs to express that it wants an implementation of the osgi http whiteboard. </p>

<p>This can be expressed by the requirement with namespace=""osgi.implementation"", name=""osgi.http"", version=""1.1.0"". As this is difficult to writer by hand there is annotation support for it.</p>

<pre><code>@HttpWhiteboardServletPattern(""/myservlet"")
@Component(service = Servlet.class)
public class MyServlet extends HttpServlet {
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) 
            throws IOException {
        resp.getWriter().println(""Hello"");
    }
}
</code></pre>

<p>The annotation @HttpWhiteboardServletPattern indirectly translates to the requirement above.</p>

<p>So when you build a bundle with this class it will import the servlet api package and also have a requirement for an http whiteboard implementation.</p>

<p>Now if you look at an implementation bundle like the felix http service you will see that it provide the capability for the whiteboard impl.</p>

<p>So if you have a OSGi repository with your bundle, the servlet API and the felix http service. Then the resolver can provide you with a complete application if you only give it your bundle. </p>
"
"57267792","What I have to modifiy for the 64-bit requirement?","<p>I know about that:</p>
<blockquote>
<p>Inspect your APK or app bundle for native code.
You can check for .so files using APK Analyzer.
Identify whether they are built from your own code or are imported by an SDK or library that you are using.
If you do not have any .so files in your APK, you are already 64-bit compliant.</p>
<p>Enable 64-bit architectures and rebuild native code (.so files) imported by your own code. See the documentation for more details.</p>
<p>Upgrade any SDKs and libraries to 64-bit compliant versions, if needed. Reach out to the SDK or library owner if one is not available. We’re working with top library owners on their 64-bit compatibility.</p>
<p>Test for issues locally once you’ve rebuilt your app.
Rollout to your testers using testing tracks for thorough testing.</p>
</blockquote>
<p>But I miss anything else? Any recommendations?</p>
<p>Thank you for your help!</p>
","<java><android><android-studio><google-play><requirements>","2019-07-30 08:51:40","93","-2","1","57267867","<p>If you have no native (NDK) code, that is you only write Java/Dex code, then you don't need to do anything.</p>

<p>If you have native code (or libraries) then you need to supply their 64-bit versions.
<a href=""https://stackoverflow.com/questions/48549563/how-to-make-android-apps-which-support-both-32-bit-and-64-bit-architecture"">reference</a></p>
"
"56810851","How to install dev version using versioning with asterisk in python/pip?","<p>How to install a dev. version (e.g <code>0.2.dev0+gebdc597</code> generated by for example <a href=""https://github.com/pypa/setuptools_scm/#default-versioning-scheme"" rel=""nofollow noreferrer"">setuptools_scm</a>) of a package?</p>

<p>I tried this</p>

<pre class=""lang-sh prettyprint-override""><code>pip install my-package==0.2.*
</code></pre>

<p>and failed. Unfort. i can't paste the exact error, but it was something like <code>couldn't find this version, &lt;list of found versions&gt;</code></p>

<p>Also, i'd like to use it later in <code>requirements.txt</code>/<code>install_requires</code>, so i need a way which works both with <code>pip</code> and <code>setuptools</code>. I hope it's the same.</p>
","<python><versioning><requirements>","2019-06-28 17:09:17","4629","1","1","56893318","<p>Short answer is use</p>

<pre><code>$ pip install pkg&gt;=0.2.0.dev
</code></pre>

<p>or in <code>requirements.txt</code></p>

<pre><code>pkg&gt;=0.2.0.dev
</code></pre>

<p>Other options are</p>

<p><code>Pip</code> has a special switch <a href=""https://packaging.python.org/tutorials/installing-packages/#installing-prereleases"" rel=""nofollow noreferrer""><code>--pre</code></a> which allows to install even with <code>*</code></p>

<pre><code>$ pip install --pre pkg==0.2.*
</code></pre>

<p>or in <code>requirements.txt</code></p>

<pre><code>--pre
pkg==0.2.*
</code></pre>

<p>This topic is also covered in <a href=""https://www.python.org/dev/peps/pep-0440/"" rel=""nofollow noreferrer"">PEP 440</a>.</p>
"
"56644115","Link two DOOR's modules without programming","<p>I am new with IBM DOORS and I need some hint or help with this, probably, basic issue. </p>

<p>I have a <strong>Module A</strong> which contains some requirements and another <strong>Modules B,C,D etc</strong>, which corresponds to a concrete supplier answering to requirements that come from Module A. Therefore, if a requirement changes (i.e the text) I would like that automatically that change is also shown in modules B,C D...</p>

<p><strong>Module A</strong> (Atributes)<br>
Req_code (text)<br>
Req_type<br>
Req_text<br>
Req_owner<br>
[...]  </p>

<p><strong>Module B,C..</strong> (Atributes)<br>
Req_code (text)<br>
Supplier<br>
Base_option<br>
Req_answer<br>
Req_comments<br>
[...]  </p>

<p>The idea is, somehow, to make a linkage between <em>Req_code</em> in Module A and <em>Req_code</em> from other modules (one to many) so I can create a complete view with atributes from two modules.</p>

<p>I have been searching on the web but I have only found that this could be done with a dxl script. Is there any other way to do this not involving programming? I tried creating a linkage module, but I did not get what I wanted.</p>

<p>Thanks in advance,<br>
Bilbinight</p>
","<module><one-to-many><linkage><requirements><ibm-doors>","2019-06-18 07:45:22","1372","1","2","56659761","<p>You will want to investigate the 'Link by Attribute' tool under the Link - Advanced menu. This is on DOORS 9.6.1.10, though most 9.x should have the same.</p>

<p>You will be able to create links between two modules, matching up a particular attribute- and then repeating the process for each subsequent module you need to link to.</p>
"
"56644115","Link two DOOR's modules without programming","<p>I am new with IBM DOORS and I need some hint or help with this, probably, basic issue. </p>

<p>I have a <strong>Module A</strong> which contains some requirements and another <strong>Modules B,C,D etc</strong>, which corresponds to a concrete supplier answering to requirements that come from Module A. Therefore, if a requirement changes (i.e the text) I would like that automatically that change is also shown in modules B,C D...</p>

<p><strong>Module A</strong> (Atributes)<br>
Req_code (text)<br>
Req_type<br>
Req_text<br>
Req_owner<br>
[...]  </p>

<p><strong>Module B,C..</strong> (Atributes)<br>
Req_code (text)<br>
Supplier<br>
Base_option<br>
Req_answer<br>
Req_comments<br>
[...]  </p>

<p>The idea is, somehow, to make a linkage between <em>Req_code</em> in Module A and <em>Req_code</em> from other modules (one to many) so I can create a complete view with atributes from two modules.</p>

<p>I have been searching on the web but I have only found that this could be done with a dxl script. Is there any other way to do this not involving programming? I tried creating a linkage module, but I did not get what I wanted.</p>

<p>Thanks in advance,<br>
Bilbinight</p>
","<module><one-to-many><linkage><requirements><ibm-doors>","2019-06-18 07:45:22","1372","1","2","56673450","<p>I think what you want is actually the companion of link-by-attribute; Link > Advanced > Create links..., but first lets do a little architecture creation.</p>

<p>I am assuming that B, C, etc. will be creating answers to A and, as such, will be doing the linking to the objects in A as they answer. With this information, we can create Module A with Req_code (use ""Object Identifier""), Req_type (Type:string or enumerated list), Req_text (Use ""Object Text""), Req_owner (Type:string), etc. </p>

<p>Similarly, create Modules B and C with such attributes as necessary to describe the information to be contained in them. finally create a link module ""L"" to contain the Link Sets for B->A and C->A. note the link module contains only link sets, not actual links. the links are stored in the source modules, i.e., Modules B and C.</p>

<p>Just to be safe,  I would also go to File > Module Properties... select Linksets tab and set linksets in each of B and C to A through link Module L. Make mandatory and Only allow outgoing links... at the bottom.</p>

<p>Now we are ready to create objects in A (Insert > Object). Create some requirement text in the ""Object Text"" attribute or any other attributes that you want to appear in the other modules.</p>

<p>go to B and create an object. Link > Start Link go to the Object in A you want to link to and select Link > Make Link from Start. (It may ask the first time if you want to create a link set, just say Yes.) a little orange outgoing, and yellow incoming triangle will appear on each corresponding object. </p>

<p>finally, in B Analysis > Wizard... choose Out-links, DOORS links only; Next> (since we only have one anyway) choose All (formal) modules and All (Link) Modules; Next>
(choose the attributes you want to display from the other module) Next> (make sure Recursive analysis is not checked) and Finish.</p>

<p>This will create another column in Module B with the attributes you want to display from Module A.</p>

<p>You can now go to View > Save As... and give the view a name and at any time, see the linked information from Module B.</p>

<p>The only DXL that was written here was the DXL you wrote when you ran the Wizard.</p>

<p>WOW! A whole free training module in how to use DOORS!</p>
"
"56495866","DXL script to change specific words in strings to italic","<p>I'm new to DXL and learning. I want to check in modules for all attributes for certain words to change them to italics.</p>

<p>Example:</p>

<p>specific word = change</p>

<p>before DXL script in attribute/column A: ""This requirement should change""</p>

<p>after DXL script in attribute/column A: ""This requirement should <em>change</em>""</p>

<p><strong>Code snippet</strong></p>

<pre><code>for itemRef in f do
{

if(shType==""Formal"")
      {
        filtering off;    
        m = read(fullName(itemRef), false)          
        Object o
        for o in m do 
       {

       //Operation for changing words to italic


       }

        close(moduleReference);
      }
}
</code></pre>

<p><strong>Updated Code</strong></p>

<pre><code>void ChangeItalic()
    {

      Module m = current
      filtering off;          
      Object o
      for o in m do
    {
      int i, j

      string t = o.""Object Text"" 
      string ModuleName = m.""Name""
      string ObjectName = identifier(o)
      print ModuleName ""\n""
      print ObjectName ""\n""
      print t

      if(matches(""[Ll]astenheft"",t)){
        print ""changed"" ""\n""
        i = start 0
        j = end 0
        t = t[0:(i-1)] ""\\i "" t[match 0] ""\\i0 "" t[j+1:]
        o.""Object Text"" = richText t


      }

}
}

// Main-Method
void main(void)
{

  ChangeItalic();

}
main()
</code></pre>
","<scripting><requirements><ibm-doors>","2019-06-07 14:05:13","937","0","1","56586960","<p>Here is the ""guts"" of your script:</p>

<pre><code>Object o = current
int i, j
string t = o.""Object Text""
if (matches(""[Cc]hange"", t)){
    i = start 0
    j = end 0
    t = t[0:(i-1)] ""\\i "" t[match 0] ""\\i0 "" t[j+1:]
    o.""Object Text"" = richText t
}
</code></pre>

<p>this script will operate on the current object and change the word ""change"" to Italic if it is within the Object Text.it would be different if you wanted to display only.</p>

<p>Unfortunately, I don't know if you are wanting to <em>display</em> the word in italics (in a column) or to change the word to italics in the attribute.</p>
"
"56086834","Requirements gathering questionarie templete","<p>I have a client who ask me to redesign his e-learning website,and we had a first call he explained everything about his website.Now how I prepare a questionnaire template for asking him about all the functionalities in the website and about the design of the website.</p>

<p>Thanks in advance.</p>
","<web-applications><requirements>","2019-05-11 03:02:21","50","0","1","56086847","<p>I would start by asking what frameworks they are currently using (jQuery, Vue...) and what the backend setup is like (static, NodeJs, php...). From there you can ask where he wants to go with the website and what he wants done. </p>
"
"56010337","Amazon sagemaker. SKlearn estimator vs Tensorflow estimator - why requirements_file is not present in one of them?","<p>I am looking at definitions of two estimators SKLearn and Tensorflow in Amazon Sagemaker:</p>

<p><a href=""https://sagemaker.readthedocs.io/en/stable/sagemaker.sklearn.html"" rel=""nofollow noreferrer"">SKLearn</a></p>

<p><a href=""https://sagemaker.readthedocs.io/en/stable/sagemaker.tensorflow.html"" rel=""nofollow noreferrer"">Tensorflow</a></p>

<pre><code>class sagemaker.sklearn.estimator.SKLearn(entry_point, framework_version='0.20.0', source_dir=None, hyperparameters=None, py_version='py3', image_name=None, **kwargs)

class sagemaker.tensorflow.estimator.TensorFlow(training_steps=None, evaluation_steps=None, checkpoint_path=None, py_version='py2', framework_version=None, model_dir=None, requirements_file='', image_name=None, script_mode=False, distributions=None, **kwargs)
</code></pre>

<p>Tensorflow has requirements_file parameter, while SKLearn does not. Is there reason why? How can I add <code>requirements.txt</code> to SKLearn estimator?</p>
","<python><requirements><amazon-sagemaker>","2019-05-06 18:09:44","251","1","1","56486750","<p>I had similar usecase, while <a href=""https://github.com/aws/sagemaker-scikit-learn-container/issues/5"" rel=""nofollow noreferrer"">this issue</a> states that they will be supporting it, I found that if you keep <a href=""https://pip.pypa.io/en/stable/user_guide/#requirements-files"" rel=""nofollow noreferrer""><code>requirements.txt</code></a> file besides your entry point file, it downloads the required dependencies.</p>
"
"55091129","How can computational requirements be compared?","<p>Calculating the solution to an optimization problem takes a 2 GHz CPU one hour. During this process there are no background processes, no RAM is being used and the CPU is at 100% capacity. </p>

<p>Based on this information, can it be derived that a 1 GHz CPU will take two hours to solve the same problem?</p>
","<requirements>","2019-03-10 18:48:42","22","-1","1","55091337","<p>A quick search of IPC, frequence, and chip architecture will show you this topic has been breached many times. There are many things that can determine the execution speed of a program (without even going into threading at all) the main ones that pop to mind:</p>

<ol>
<li><p><strong>Instruction set</strong> - If one chip has an instruction for multiplication, than <code>a*b</code> is atomic. If not, you will need a lot of atomic instructions to perform such an action - big difference in speed, which can prove to make even higher frequency chips slower.</p></li>
<li><p>Cycles per second - this is the <strong>frequency</strong> of the chip.</p></li>
<li><p><strong>Instructions per cycle (IPC)</strong> - what you are really interested is IPC*frequency, not just frequency. How many atomic actions can you can perform in a second. After the amount of atomic actions (see 1), on a single threaded application this might act as you expect (x2 this => x2 faster program), though no guarantees.</p></li>
</ol>

<p>and there are a ton of other nuance technologies that can affect this, like branch prediction which hit the news big time recently. For a complete understanding a book/course might be a better resource.</p>

<p>So, in general, <strong>no</strong>. If you are comparing two single core, same architecture chips (unlikely), then maybe yes.</p>
"
"54690373","Doxygen custom tag with a placeholder","<p>Is it somehow possible in Doxygen to create a custom tag, which creates a documentation using a placeholder tag as its input?</p>

<p>What I want to accomplish is to create a custom tag for requirements. As our DOORS Urls are quite long, and diverge from SW-component to SW-component, I want to create something similar to this:</p>

<pre><code>@file somefile.c
@doorsdocurl &lt;URL to DOORS document&gt; -&gt; this is going to be my placeholder

...
...
...


/**
* @brief somedescription
* @req{doorsdocurl: &lt;reqID1, reqID2,...&gt; } -&gt; this is going to be the second custom tag
*/
void jambo()
{
}
</code></pre>

<p>Is this somehow achievable with Doxygen? From what I have read, one has to put his custom tags within the ALIASES variable</p>
","<c><doxygen><requirements>","2019-02-14 12:25:17","544","0","1","54693581","<p>In your Doxyfile you would need something like:</p>

<pre><code>ALIASES = ""doorsdocurl_sw_1=&lt;URL to DOORS document&gt;"" \
          ""req{2}=\1 \2&lt;br&gt;""
</code></pre>

<p>and the code would look like:</p>

<pre><code>/**
* @brief somedescription
*
* @req{@doorsdocurl_sw_1,reqID1}
* @req{@doorsdocurl_sw_1,reqID2}
*/
void jambo()
{
}
</code></pre>

<p>The <code>\req</code> command can of course be extended with other commands, in this respect the command <code>xrefitem</code> might be useful, see the manual (<a href=""http://www.doxygen.nl/manual/commands.html#cmdxrefitem"" rel=""nofollow noreferrer"">http://www.doxygen.nl/manual/commands.html#cmdxrefitem</a>)</p>
"
"54687228","DOORS creates Object ID while they are not saved","<p>I am adding some 2000 new objects to a DOORS module, I do this by importing a spread sheet with blank IDs, DOORS is supposed to create IDs for those blank rows.
Now the problem is, while i import spreadsheet, DOORS hangs, then when i Kill DOORS process, it anyhow creates IDs, next time when i add a new object, ID number starts from those which are already created but no exist. For some reason i need to continue from my last saved ID. Is there any way I can do this? </p>
","<requirements><configuration-management><ibm-doors>","2019-02-14 09:37:54","398","0","1","54688876","<p>several remarks here:</p>

<ul>
<li>works as designed. As soon as an object is created in any DOORS session, the new absolute number is centrally marked as ""used"". I think the main reason for this feature is the possibility to work in shared mode. If there were a different design, you would get into trouble as soon as two developers work on the module at the same time.</li>
<li>are you sure that DOORS really hangs? Perhaps it is just not yet finished, at least you can see that the objects are really created. Note that depending on how the script is written that you use for import, the number of imports per second might decrease significantly for bigger files</li>
<li>You should NEVER give any meaning to the absolute number other than uniqueness (perhaps QSS should have used timestamps or UUIDS instead of integers for their absolute numbers when they designed DOORS, this would make the situation clearer). You will have to rework “some reasons” . Perhaps you use a different mechanism to assign your own ID mechanism or you have to evaluate whether the requirement “generate consecutive numbers without gaps” is really necessary.</li>
</ul>
"
"54668439","When shall I create UML diagrams when developing software?","<p>I am currently working on a new software and I am not sure how to go on.</p>

<p>I already started coding before having a good plan.</p>

<p>My opinion was to start with below sequence</p>

<ol>
<li><p>Create User Stories</p></li>
<li><p>Create BMSC &amp; Hsmc</p></li>
<li><p>Code the required features</p></li>
<li><p>Test</p></li>
<li><p>Refactor &amp; solve bugs</p></li>
</ol>

<p>Now I want to know where do I put the UML Diagram, before coding or after coding?</p>
","<uml><software-design><requirements>","2019-02-13 10:51:47","82","-3","2","54668476","<p>UML is the ""graphical"" design of a project. Before you start coding, you should have all UML's done and <strong>checked</strong> so as programming the project later will be faster, easier and with less errors (as the UML will be <strong>CHECKED</strong> to ensure that). </p>

<p>Do not rush making the UML, as it will be the ""core"" before the actual coding core. </p>
"
"54668439","When shall I create UML diagrams when developing software?","<p>I am currently working on a new software and I am not sure how to go on.</p>

<p>I already started coding before having a good plan.</p>

<p>My opinion was to start with below sequence</p>

<ol>
<li><p>Create User Stories</p></li>
<li><p>Create BMSC &amp; Hsmc</p></li>
<li><p>Code the required features</p></li>
<li><p>Test</p></li>
<li><p>Refactor &amp; solve bugs</p></li>
</ol>

<p>Now I want to know where do I put the UML Diagram, before coding or after coding?</p>
","<uml><software-design><requirements>","2019-02-13 10:51:47","82","-3","2","54668580","<p>To be honest, there can not be a ultimate answer here.</p>

<p>There are various process models and you have to find one that suits your needs and your project. </p>

<p><strong>Test driven development</strong> for example puts tests in front of writing the actual code.</p>

<p>My point is, if you feel like <strong>UML</strong> gives you confidence - go do it.
But if you feel like a minimal working example gives you more insights - write some code first and come back to uml later.</p>
"
"54234482","Startup Services AddAuthorization AddPolicy: EmptyRequirement","<p>I'm little bit new in web development. I have an RestController which has many method e.g. (Get, GetById, Create, Update). I use Authorize Attribute, which used with Policy. This policy depend on a bool variable. You can see at below. </p>

<p>Now I use this workaround but I search more nice solution. </p>

<pre><code>services.AddAuthorization(o =&gt;
    {
        o.AddPolicy(""UserRoleCheck"", p =&gt;
        {
            if (C.RequiredAuth)
            {
                p.RequireAuthenticatedUser();
                p.AssertRole(Roles.User);
            }
            else
            {
                p.AddRequirements(new EmptyRequirement()); // Here I don't want to else branch
            }

        });
    });  

public class EmptyRequirement : AuthorizationHandler&lt;EmptyRequirement&gt;, IAuthorizationRequirement
{
    protected override Task HandleRequirementAsync(AuthorizationHandlerContext context, EmptyRequirement requirement)
    {
        context.Succeed(requirement);
        return Task.CompletedTask;
    }
}
</code></pre>

<p>It's work, but can You offer me more beautiful solution?</p>
","<c#><asp.net-core><policy><requirements><authorize-attribute>","2019-01-17 11:02:02","255","0","1","54338610","<p>For your current design, it is caused by that <code>Policy</code> must contains at least one requirement.   </p>

<p>Not sure what is the defination for <code>C</code>, I suggest you implement <code>UserRoleCheckRequirement</code> and move the <code>C</code> to <code>UserRoleCheckRequirement</code> to return <code>context.Succeed(requirement);</code>. And then check <code>AuthenticatedUser</code> and other authorization logic in <code>HandleRequirementAsync</code>.</p>
"
"53581142","Correct classification of client requirements for UML diagrams?","<p>I needed to classify the following RQs as a </p>

<ul>
<li>Design objective, </li>
<li>Design Decisions, </li>
<li>Functional Req, </li>
<li>Non-Functional Req</li>
</ul>

<p>(so I can do class diagram and use case diagram based on them later).</p>

<p>I wanted to know if I'm on the right track here (the bold face is my guess for each requirement):</p>

<p><strong>Requirement document</strong>
 Purchase Commitment System.</p>

<ol>
<li><p>The software is to calculate a number of details needed to purchase by a factory in order to produce its products. <strong>(Design decision)</strong></p></li>
<li><p>The software must be written in C++ or Java Programming Languages on the computer IBM PC. <strong>(Design decision)</strong></p></li>
<li><p>The number of products should be equal to 4. <strong>(Non-Functional Req)</strong></p></li>
<li><p>A general aim in the design of the software is to improve the portability of software. <strong>(Non-Functional Req)</strong></p></li>
<li><p>The system should accept as input (make as a text file) the data about a number, amount and price of detail for every type of products. <strong>(Functional Req)</strong></p></li>
<li><p>A number of details for every type of products should not be less than 5.</p></li>
<li><p>The first and second type of products should have 2 same details. The second and fourth type of products should have one same detail. The third type of products should have 2 same details with the fourth type and one same detail with the first type of products. <strong>(Design Objective)</strong></p></li>
<li><p>The operator should be logged in and logged out to the system by login and password. <strong>(Design Objective)</strong></p></li>
<li><p>At the beginning an operator must provide the following items of data (a validation of input data should be provided):</p>

<ul>
<li>A number of every type of products to be produced by the factory for 3 months ahead.   <strong>(Functional Req)</strong></li>
</ul></li>
<li><p>The software must produce for each action of an operator a report (the report should be saved in a file by the operator's request). The report must consist of :    <strong>(Functional or Design Objective Req)</strong> 
-A number of every detail needed to purchase.</p>

<ul>
<li>The total price for every detail.</li>
<li>The total price for all the details</li>
</ul></li>
</ol>
","<classification><requirements>","2018-12-02 14:22:08","130","1","2","53588604","<p>I remember long discussions in the past about RQs whether a specific one were Non-F or F. However, <a href=""https://en.wikipedia.org/wiki/Functional_requirement"" rel=""nofollow noreferrer"">Wikipedia</a> has a simple definition.</p>

<blockquote>
  <p>As defined in requirements engineering, functional requirements specify particular results of a system.</p>
</blockquote>

<p>So your classification does not look bad. Though, I wonder what your first two classifications should be. Looks a bit like <a href=""https://en.wikipedia.org/wiki/MoSCoW_method"" rel=""nofollow noreferrer"">MoSCoW</a>, but then again it does not. Design decisions (at least to me) are nothing to be found in requirements. They are, what the name suggests, decisions coming from a design process. Further a design objective is a sub-category of NF. Even more important is the fact that your NFs are not classified. There should be at least a handful of sub-classes (legal, performance, etc.). See <a href=""https://en.wikipedia.org/wiki/Non-functional_requirement"" rel=""nofollow noreferrer"">Wikipedia</a> for a rather complete list.</p>
"
"53581142","Correct classification of client requirements for UML diagrams?","<p>I needed to classify the following RQs as a </p>

<ul>
<li>Design objective, </li>
<li>Design Decisions, </li>
<li>Functional Req, </li>
<li>Non-Functional Req</li>
</ul>

<p>(so I can do class diagram and use case diagram based on them later).</p>

<p>I wanted to know if I'm on the right track here (the bold face is my guess for each requirement):</p>

<p><strong>Requirement document</strong>
 Purchase Commitment System.</p>

<ol>
<li><p>The software is to calculate a number of details needed to purchase by a factory in order to produce its products. <strong>(Design decision)</strong></p></li>
<li><p>The software must be written in C++ or Java Programming Languages on the computer IBM PC. <strong>(Design decision)</strong></p></li>
<li><p>The number of products should be equal to 4. <strong>(Non-Functional Req)</strong></p></li>
<li><p>A general aim in the design of the software is to improve the portability of software. <strong>(Non-Functional Req)</strong></p></li>
<li><p>The system should accept as input (make as a text file) the data about a number, amount and price of detail for every type of products. <strong>(Functional Req)</strong></p></li>
<li><p>A number of details for every type of products should not be less than 5.</p></li>
<li><p>The first and second type of products should have 2 same details. The second and fourth type of products should have one same detail. The third type of products should have 2 same details with the fourth type and one same detail with the first type of products. <strong>(Design Objective)</strong></p></li>
<li><p>The operator should be logged in and logged out to the system by login and password. <strong>(Design Objective)</strong></p></li>
<li><p>At the beginning an operator must provide the following items of data (a validation of input data should be provided):</p>

<ul>
<li>A number of every type of products to be produced by the factory for 3 months ahead.   <strong>(Functional Req)</strong></li>
</ul></li>
<li><p>The software must produce for each action of an operator a report (the report should be saved in a file by the operator's request). The report must consist of :    <strong>(Functional or Design Objective Req)</strong> 
-A number of every detail needed to purchase.</p>

<ul>
<li>The total price for every detail.</li>
<li>The total price for all the details</li>
</ul></li>
</ol>
","<classification><requirements>","2018-12-02 14:22:08","130","1","2","53641757","<p>A <a href=""https://en.wikipedia.org/wiki/Functional_requirement"" rel=""nofollow noreferrer"">functional requirement</a> tells <strong>what</strong> the software shall do.  A <a href=""https://en.wikipedia.org/wiki/Non-functional_requirement"" rel=""nofollow noreferrer"">non functional requirement</a> tells something about <strong>how</strong> the software shall be or how well it should do what it does. </p>

<p>Software design is about the <strong>structure and the behavior</strong> of the software.   If some statement seems arbitrary and you think the software could fulfil all the requirements but differently, then there are chances that it's more about design than requirements.  A design objective tells what the design must ensure (ambiguous: at the stage of the requirements, it's difficult to make the difference between non functional requirements and design objective).  A design decision is a decision on the behavior or the structure of the software.     </p>

<p>With this in mind, here an analysis: </p>

<ol>
<li>What the software shall do ==> Functional requirement (FR) <br/> If we'd change this, the software would no longer do what is expected, so it can't be a design decision. </li>
<li>How the software shall be ==> Non functional requirement (NFR) <br/> Not really about structure or behavior of the software. The language will not impact use case nor class model, so it's not really a design decision IMHO.   </li>
<li>Arbitrary decision about cardinality in object model ==> Design decision (DD) </li>
<li>""aim in the design"" ==> Design objective (DO) </li>
<li>What the software shall do ==> FR</li>
<li>Arbitrary constraint about object model ==> DD<br/>If it would be no less than 3 or no less than 10, the software would still fulfil the functional requirements.  However this depends on the context.  If it would turn out that the software would not be fit for purpose if these limits would not be respected, then it could be FR. </li>
<li>Arbitrary constraint on object model ==> DD<br/>The purpose of this statement is unclear.  It looks like some arbitrary constraints that could allow to generalize some categories. </li>
<li>What the software shall do ==> FR  </li>
<li>Arbitrary decision on the interaction ==> DD<br/> I think that the data could be entered at another moment, or in a different way (3 times 1 month).  Therefore I think it is DD.  However, one could argue that the system shall offer a 3 month planning.  So FR cannot be excluded, although I would expect it to be expressed differently.   </li>
<li>What the software shall do ==> FR</li>
</ol>
"
"53360336","External System in UML","<p>I am currently working on software requirements specification document, I am creating a use case to validate or communicate with external system, for example I a want to creating a use case that about sending notification emails to user outlook contacts, donI need to specified the detail for the external system? Like calidation or credentials?</p>
","<uml><use-case><requirements><use-case-diagram>","2018-11-18 11:27:47","1589","0","1","53360841","<p>Not in the UC diagram, but there are others where you might.</p>

<h2>Use Case diagram</h2>

<p>UC will show external systems that are involved in the UC as actors. The UC itself shows functionality of modeled systems and should no go to low with decomposition. Things like ""communicate with external system"" or ""validate query"" are not separate UCs but part of something broader like ""Place an order"". On this level you only show the main function, leaving details for other, more specific diagrams (e.g. activity diagram depicting the UC's flow).</p>

<h2>Activity diagram</h2>

<p>On activity diagram you show the information about processing but in general you do not show too much static data. As a result things like ""Validate query"" or ""Create notification e-mail"" will be separate actions within the activity. They may have be further decomposed as Activities with details about how validation is performed or what steps has to be performed to communicate with the system.</p>

<h1>Sequence diagram</h1>

<p>Sequence diagram is another great way of showing the flow of action, especially when communication between various parties (e.g. systems) is involved. Here you can show the order of messages being sent, to some degree actions taken (as called operations - so you can show that you run validation first and send the message to the e-mail system then if the validation was successful). With the operation you can also show information about parameters that has to be provided (so for example credentials for communication with external systems).</p>

<h2>Other diagrams</h2>

<p>It all depends on the specific diagram and most of them give you a possibility to show the other system in some way. Sometimes there is more than one good way to do so. Details would depend on what exactly you want to show and which diagram did you choose to present the information</p>

<hr>

<p>I would suggest you read some good books about modelling with the use of UML. Craig Larman's ""Applying UML and patterns"" or Howard Podesva's ""UML for the IT business analysis"" are my usual starting recommendations.</p>
"
"52858824","How do we gather and document non-functional requirements in Agile","<p>I know in waterfall, they are gathered and documented at an early stage of SDLC, I believe very first stage. Therefore, they are captured and documented before development and testing even starts.</p>

<p>But I am confused how is that done in Agile? </p>

<p>If I understand correctly, user stories should be written with acceptance criteria which capture non-functional requirements. But in Agile, we pick project, create it, and start working on it right away.  </p>

<p>So, my guess is that someone (perhaps product owner) goes through user stories and collects acceptance criteria into a formatted document which then becomes Non-Functional-Requirements document?</p>
","<agile><requirements>","2018-10-17 15:46:03","566","-2","1","52859874","<p>First, to answer your question, I must be clear that no Agile frameworks or methodologies attempt to define everything that a team might need to do (especially Scrum) so there is nothing wrong with adding extra artifacts or practices that the team finds useful as long as they aren't contradicting a defined practice.</p>

<p>There are a few places I typically see non-functional requirements recorded. Here are a few of the most common ones:</p>

<p><strong>Definition of Done</strong></p>

<p>The definition of done contains standards for quality that should be applied across all backlog items that come through. Often times this includes things like ""n% unit test coverage of code"", ""code and configuration changes have been peer reviewed"", and ""all automated regression tests have been run and pass"". I've sometimes seen broader non-functional requirements like ""no changes cause the application load time to exceed X ms"".</p>

<p><strong>Architectural Design Documents</strong></p>

<p>You can still have these in Agile. Rather than establishing the finished architecture at the beginning of the project, they introduce constraints that the architecture has to stay within. As the project progresses and architectural decisions are made or changed, these documents are updated to reflect that information. Examples of constraints may include ""System X is considered to be the authoritative source of customer personal data"" or ""Details needed for payment processing should never be available to a public-facing server in order to reduce attack opportunities on that data.""</p>

<p><strong>Product Chartering</strong></p>

<p>Depending on the project, ""starting right away"" is a bit fluid. On very large projects or products, it is not uncommon to take a few days (in my experience, 1 - 3 is a good number) to charter the project. This would include identifying personas, making sure business stakeholders and team members have a shared understanding of the vision, talk through some expected user experiences and problems at a high level, etc. It is very common that non-functional needs come out here and should be recorded either in the DoD, existing architectural documents, or in some cases, in backlog items. One good example of this happening is something called a trade-off matrix. When building a tradeoff matrix, we talk about constraints on the project like performance, adaptability, feature set, budget, time, etc. We identify one as a primary constraint, two as secondary, and all others are considered tertiary. This isn't a hard-and-fast rule, but it establishes an general understanding of how trade-offs on non-functional needs will be decided in the work.</p>

<p><strong>Backlog Items</strong></p>

<p>Ok, last one. Not all backlog items have to be User Stories. If you have an actionable non-functional requirement (set up a server, reconfigure a firewall, team needs to convert to a new version of the IDE) there is nothing that stops you from creating a backlog item for this. It isn't a User Story, but that's ok. I will warn that most teams find a correlation between the number of items in the backlog that are User Stories and their ability to effectively deliver value and adapt to changes along the way, so don't get carries away. But I'd rather see a team put in a non-US in their backlog than try to pass off those things as user stories like ""As a firewall, I want to be updated, so we don't get h@XX0rD"" &lt;- real backlog item I saw.</p>

<p>As a final note: remember that in Agile, we strive to adapt to change, so don't worry about getting the DoD or architectural document perfect the first time. It can change as you learn more.</p>
"
"52849063","Searching for free requirements management software","<p>I am looking for a requirements management software, like DOORS, but for free <em>(I need to enter requirements, and generate a specification document, not only follow requirement traceability like reqtify allows you to do)</em>
I searched on the Internet, and I found the nearly perfect sofware : <strong>GenSpec</strong>. Moreover, GenSpec use templates with standards, like IEEE 830 which is the one I am interested in.</p>

<p>I said ""nearly perfect"" because the document generation does not work in GenSpec (runtime error). So I tried to subscribe to the google group to ask some assistance, but I think it is an old software which is not supported and updated anymore (for info, I downloaded GenSpec 6.8.40 and I work with Microsoft Office 2016, I think there is a compatibility issue, but it is only an hypothesis)</p>

<p>So I am posting this subject here if someone can :</p>

<ul>
<li>Either tell me if there is a similar software ?</li>
<li>Or, knows GenSpec and
can perhaps help me with my document generation issue (I could give
more details in this case) ?</li>
</ul>

<p>Thanks !</p>
","<requirements><requirements-management>","2018-10-17 07:04:10","288","-3","1","52930531","<p>Yes, there is a similar SW - ReqView. See the SW Recommendations question at 
<a href=""https://softwarerecs.stackexchange.com/a/52607/41086"">https://softwarerecs.stackexchange.com/a/52607/41086</a></p>
"
"52193141","Storing requirements/specification documents in TFS on-premise","<p>We're starting a new development project using on-premise TFS 2018, git and Visual Studio. In the past we've followed the Agile model of creating epics and user stories and putting the requirements/ui mockups and other details directly in the user stories.</p>

<p>After living through that approach, we don't want go back down that road for the following reasons:
1) Once that feature is shipped, it becomes extremely difficult to locate the info. Who remembers what feature was done in what user story?
2) No centralized place to store feature documentation. Of course, we all don't want take the waterfall approach of spending 2 years writing feature requirements, but there is something to be said of having a centralized place organized by feature area that contains the relevant documentation.
3) Have you ever tried to read an extensive user story with requirements acceptance testing through either the web interface or through Visual Studio? It gets old pretty fast having to read through a 8 line window.</p>

<p>What we would like to do is do a hybrid of documentation and reference a link to the doc in the user story.  The user story exists for sprint tracking, but the details are stored in the document.  After the feature/user story has shipped, we can refer to the doc.</p>

<p>Therefore the question becomes how to store this type of info in TFS and link to it so it can open with a link in the user story.  We know we can do this with SharePoint, but is it possible to do in on-premise TFS?</p>
","<sharepoint><tfs><documentation><requirements>","2018-09-05 20:44:37","482","2","1","52215778","<p>Currently, this is not directly possible in TFS with outgoing with some 3rd party vendors like <a href=""https://marketplace.visualstudio.com/items?itemName=edevtech-mr.inteGREAT4TFS"" rel=""nofollow noreferrer"">Modernrequirements</a> which will be <strong>paid services</strong>.</p>

<p>You could always use the CMMI template which is used for creating and managing requirement Workitems, but not for storing a huge set of requirements as you typically stored in requirement documents. </p>

<ol>
<li>As you mentioned there are other ways like  Storing the documents in
SharePoint, one drive etc., and link to the user stories</li>
<li>Creating a
<a href=""https://marketplace.visualstudio.com/items?itemName=cschleiden.markdown"" rel=""nofollow noreferrer"">markdown</a>
in the user stories itself.</li>
<li>Check-in those documents in the version control(Git,TFVS)</li>
</ol>

<p>Refer to this similar <a href=""https://stackoverflow.com/a/35968872/7073340"">SO</a> in order to understand it better.</p>
"
"52153676","What is the requirements for running a Rust compiled program on another Windows machine?","<p>I'm totally new to Rust. I installed Rust on my Windows 10 machine. Created a simple helloworld program like this:</p>

<pre><code>fn main() {
    print!(""Hello world!"");
}
</code></pre>

<p>And compiled it with <code>rustc rust.rs</code>. After that there are two files generated:</p>

<pre><code>admin@myserver MINGW64 ~/Documents/rust_test
$ ls -latrh
total 1.6M
drwxr-xr-x 1 admin 197121    0 Sep  2 03:28 ..
-rw-r--r-- 1 admin 197121   45 Sep  4 00:26 rust.rs
-rwxr-xr-x 1 admin 197121 146K Sep  4 00:26 rust.exe
-rw-r--r-- 1 admin 197121 1.5M Sep  4 00:26 rust.pdb
drwxr-xr-x 1 admin 197121    0 Sep  4 00:26 .
</code></pre>

<p>I can successfully run <code>rust.exe</code> and get the proper result. However, when I copy <code>rust.exe</code> to another newly created Windows 2016 virtual machine and run it, I got this error:</p>

<p><a href=""https://i.stack.imgur.com/eJ5QJ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/eJ5QJ.png"" alt=""enter image description here""></a></p>

<p>My question is, what's the requirement to run a Rust compiled program on a machine that doesn't have Rust installed? Do I need to install the <code>vc++ build tools</code> on it too (just as I did on the development machine)? </p>
","<compilation><rust><requirements>","2018-09-03 16:44:45","2322","6","3","52160045","<p>You need to install the <a href=""https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads"" rel=""nofollow noreferrer"">Microsoft Visual C++ Redistributable Package</a> in the correct version. </p>

<p>The ""140"" in the file name in your error message indicates the version, which should be the <a href=""https://www.microsoft.com/en-US/download/details.aspx?id=48145"" rel=""nofollow noreferrer"">Visual C++ Redistributable for Visual Studio 2015</a>.</p>

<hr>

<p>As a shortcut, here are the most common dowload links for other versions:</p>

<ul>
<li>Microsoft Visual C++ Redistributable 2017 — <a href=""https://aka.ms/vs/15/release/vc_redist.x86.exe"" rel=""nofollow noreferrer"">32-bit (x86)</a>, <a href=""https://aka.ms/vs/15/release/vc_redist.x64.exe"" rel=""nofollow noreferrer"">64-bit (x64)</a></li>
<li>Microsoft Visual C++ Redistributable 2015 — <a href=""https://download.microsoft.com/download/9/3/F/93FCF1E7-E6A4-478B-96E7-D4B285925B00/vc_redist.x86.exe"" rel=""nofollow noreferrer"">32-bit (x86)</a>, <a href=""https://download.microsoft.com/download/9/3/F/93FCF1E7-E6A4-478B-96E7-D4B285925B00/vc_redist.x64.exe"" rel=""nofollow noreferrer"">64-bit (x64)</a></li>
<li>Microsoft Visual C++ Redistributable 2013 — <a href=""http://download.microsoft.com/download/2/E/6/2E61CFA4-993B-4DD4-91DA-3737CD5CD6E3/vcredist_x86.exe"" rel=""nofollow noreferrer"">32-bit (x86)</a>, <a href=""http://download.microsoft.com/download/2/E/6/2E61CFA4-993B-4DD4-91DA-3737CD5CD6E3/vcredist_x64.exe"" rel=""nofollow noreferrer"">64-bit (x64)</a></li>
<li>Microsoft Visual C++ Redistributable 2012 — <a href=""http://download.microsoft.com/download/1/6/B/16B06F60-3B20-4FF2-B699-5E9B7962F9AE/VSU3/vcredist_x86.exe"" rel=""nofollow noreferrer"">32-bit (x86)</a>, <a href=""http://download.microsoft.com/download/1/6/B/16B06F60-3B20-4FF2-B699-5E9B7962F9AE/VSU3/vcredist_x64.exe"" rel=""nofollow noreferrer"">64-bit (x64)</a></li>
<li>Microsoft Visual C++ Redistributable 2010 — <a href=""http://download.microsoft.com/download/5/B/C/5BC5DBB3-652D-4DCE-B14A-475AB85EEF6E/vcredist_x86.exe"" rel=""nofollow noreferrer"">32-bit (x86)</a>, <a href=""http://download.microsoft.com/download/d/2/4/d242c3fb-da5a-4542-ad66-f9661d0a8d19/vcredist_x64.exe"" rel=""nofollow noreferrer"">64-bit (x64)</a></li>
<li>Microsoft Visual C++ Redistributable 2008 — <a href=""http://download.microsoft.com/download/1/1/1/1116b75a-9ec3-481a-a3c8-1777b5381140/vcredist_x86.exe"" rel=""nofollow noreferrer"">32-bit (x86)</a>, <a href=""http://download.microsoft.com/download/d/2/4/d242c3fb-da5a-4542-ad66-f9661d0a8d19/vcredist_x64.exe"" rel=""nofollow noreferrer"">64-bit (x64)</a></li>
<li>Microsoft Visual C++ Redistributable 2005 — <a href=""http://download.microsoft.com/download/d/3/4/d342efa6-3266-4157-a2ec-5174867be706/vcredist_x86.exe"" rel=""nofollow noreferrer"">32-bit (x86)</a>, <a href=""http://download.microsoft.com/download/9/1/4/914851c6-9141-443b-bdb4-8bad3a57bea9/vcredist_x64.exe"" rel=""nofollow noreferrer"">64-bit (x64)</a></li>
</ul>
"
"52153676","What is the requirements for running a Rust compiled program on another Windows machine?","<p>I'm totally new to Rust. I installed Rust on my Windows 10 machine. Created a simple helloworld program like this:</p>

<pre><code>fn main() {
    print!(""Hello world!"");
}
</code></pre>

<p>And compiled it with <code>rustc rust.rs</code>. After that there are two files generated:</p>

<pre><code>admin@myserver MINGW64 ~/Documents/rust_test
$ ls -latrh
total 1.6M
drwxr-xr-x 1 admin 197121    0 Sep  2 03:28 ..
-rw-r--r-- 1 admin 197121   45 Sep  4 00:26 rust.rs
-rwxr-xr-x 1 admin 197121 146K Sep  4 00:26 rust.exe
-rw-r--r-- 1 admin 197121 1.5M Sep  4 00:26 rust.pdb
drwxr-xr-x 1 admin 197121    0 Sep  4 00:26 .
</code></pre>

<p>I can successfully run <code>rust.exe</code> and get the proper result. However, when I copy <code>rust.exe</code> to another newly created Windows 2016 virtual machine and run it, I got this error:</p>

<p><a href=""https://i.stack.imgur.com/eJ5QJ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/eJ5QJ.png"" alt=""enter image description here""></a></p>

<p>My question is, what's the requirement to run a Rust compiled program on a machine that doesn't have Rust installed? Do I need to install the <code>vc++ build tools</code> on it too (just as I did on the development machine)? </p>
","<compilation><rust><requirements>","2018-09-03 16:44:45","2322","6","3","52166618","<p>You can also statically link the CRT by adding</p>

<pre><code>[target.x86_64-pc-windows-msvc]
rustflags = [""-Ctarget-feature=+crt-static"", ""-Zunstable-options""]
</code></pre>

<p>to your <code>.cargo/config</code>. As pointed out in <a href=""https://stackoverflow.com/a/44387312/2430485"">this Stack Overflow answer</a>.</p>
"
"52153676","What is the requirements for running a Rust compiled program on another Windows machine?","<p>I'm totally new to Rust. I installed Rust on my Windows 10 machine. Created a simple helloworld program like this:</p>

<pre><code>fn main() {
    print!(""Hello world!"");
}
</code></pre>

<p>And compiled it with <code>rustc rust.rs</code>. After that there are two files generated:</p>

<pre><code>admin@myserver MINGW64 ~/Documents/rust_test
$ ls -latrh
total 1.6M
drwxr-xr-x 1 admin 197121    0 Sep  2 03:28 ..
-rw-r--r-- 1 admin 197121   45 Sep  4 00:26 rust.rs
-rwxr-xr-x 1 admin 197121 146K Sep  4 00:26 rust.exe
-rw-r--r-- 1 admin 197121 1.5M Sep  4 00:26 rust.pdb
drwxr-xr-x 1 admin 197121    0 Sep  4 00:26 .
</code></pre>

<p>I can successfully run <code>rust.exe</code> and get the proper result. However, when I copy <code>rust.exe</code> to another newly created Windows 2016 virtual machine and run it, I got this error:</p>

<p><a href=""https://i.stack.imgur.com/eJ5QJ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/eJ5QJ.png"" alt=""enter image description here""></a></p>

<p>My question is, what's the requirement to run a Rust compiled program on a machine that doesn't have Rust installed? Do I need to install the <code>vc++ build tools</code> on it too (just as I did on the development machine)? </p>
","<compilation><rust><requirements>","2018-09-03 16:44:45","2322","6","3","68900092","<p>I ran into the same problem but I resolved it by installing Microsoft Visual C++ Redistributable 2019.  You do not need to stick with 2015.  Any newer version will work just fine.</p>
"
"52021074","why templated non const parameter constructor is preferred to given copy constructor","<p>I want to make my class be able to be used in a <code>std::variant</code>.</p>

<p>The simply code that should work is:</p>

<pre><code>int main()
{
    std::variant&lt; int, A &gt; v;

    A a(1);
    v = a;
}
</code></pre>

<p>My class contains a templated constructor:</p>

<pre><code> template &lt;typename T&gt; A( T&amp; );
</code></pre>

<p>At this point the trouble starts! The constructor binds to the call from <code>std::variant</code> and not the provided <code>A(const A&amp;)</code> is used anymore.</p>

<p>For copy&amp;paste reasons the full example here:</p>

<pre><code>#include &lt;iostream&gt;
#include &lt;variant&gt;

class A
{
    private:
        int x;

    public:

        A( A&amp;&amp;) {}
        A( const A&amp; ) {}
        A(){}
        ~A() {}

        A&amp; operator=( const A&amp; ) { return *this;}
        A&amp; operator=( A&amp;&amp; ) {return *this;}

        template &lt;typename T&gt;
            A( T&amp; t  ) 
            {
                std::cout &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; std::endl;
            }

        A(int _x):x{_x}{}
};

int main()
{
    std::variant&lt; int, A &gt; v;

    A a(1);
    v = a;
}
</code></pre>

<p>Background:</p>

<p>Why the template here?
The problem starts while using a constructor which takes a serializer type. The serializer can have multiple types, depends on files or streams to serialize with.</p>

<p>Remark: I know that the functionality of the constructors is missing!</p>
","<c++><c++17><variant><requirements>","2018-08-25 20:41:59","121","2","1","52021094","<p>The problem is not with <code>std::variant</code>. The problem is with the constructor template,</p>

<pre><code>template &lt;typename T&gt;
A(T&amp; t)
</code></pre>

<p>Such constructors are problematic because when the argument is a non-<code>const</code> lvalue of type <code>A</code>, this constructor is preferred over the copy constructor taking <code>const A&amp;</code>---which is usually not the intended behaviour. To prevent this, we usually constrain this constructor with SFINAE:</p>

<pre><code>template &lt;typename T, typename = std::enable_if_t&lt;!std::is_same_v&lt;std::decay_t&lt;T&gt;, A&gt;&gt;&gt;
A(T&amp; t)  // or T&amp;&amp; t
</code></pre>

<p>and might consider making it <code>explicit</code> as well.</p>

<p>We usually do not provide copy constructors taking non-<code>const</code> <code>A&amp;</code>, since they are redundant next to the ones taking <code>const A&amp;</code>.</p>
"
"51535618","Best practices for including large resource folder into java project","<p>I'm working on a project where having access to a big resource folder (structure with thousand of little images) is required. The client want to offer the app through a native installation (which includes the JVM that the app require to run). He doesn't want to pack that resources as a folder in the app because it would create a folder structure as big as the original in the final user's hard drive (the folder doesn't take much space but it has many little files), plus the folder could be stealed easily by simply copying it. Giving this, I can't package all the app with a resource folder in a jar file, as far as i know jar files are not installables. Another requirement is that client needs certain flexibility to add some files in a installed app folders structure to add new features to the program. So an installation is the only way (i think) to obtain this.</p>

<p>I've tried to pack them in a jar file, include it in the build path and tried to access it but i failed even with all the research i've made through various sites.  Tried getResources() in a million ways but it was impossible to get a simple directory inside the jar file meanwhile doing it from a folder outside the jar is really easy. I need to get access to a directory in order to get a list of files it cointains.</p>

<p>Arrived to this point. I've started to ask myself if i'm facing this problem on the best way so i wanted to ask you all: how would you package the resources you need in a native java app with this requirements?</p>

<p>I'm even thinking about create some kind of encryption proccess to create a single file with all the information and simply temporarily decrypt it when needed at runtime but i think there would be a simpler and cleaner way to face this.</p>

<p>Thank you in advance</p>

<p><strong>EDIT:</strong> As you asked for, i'm adding the code of what i've tried:</p>

<p>this is the project structure</p>

<pre><code>project
├───src
│   ├───main
│   │   └───java
│   │       ├───model &lt;--- where my class is
│   │       ├───controllers
│   │       ├───utilities
│   │       └───views
│   ├───resources &lt;--- this is where is (formerly) accessed the content i need
|   |   ├─── jarfile.jar &lt;--- i've placed file here and included to build path
│   │   └───-various folders and files -
│   └───test
└───target
</code></pre>

<p>inside the jar file there are the packages src.resources.blalblaba and inside of this, the folder i need</p>

<p>Way1: </p>

<p>getResources replacing jar file ""."" with ""/"" tried with paths: ""src/resources/blablabla/folderINeed"",""src/resources/src/resources/blablabla"" (due to possible duplicity), ""folderINeed"", ""blablabla/folderINeed""  -> URI always get NullPointerException with message ""null""</p>

<pre><code>public void loadContent(String contentPath) throws Exception
{ 
    File resources= null;
    File[] listFiles = null;

    URI uri = getClass().getClassLoader().getResource(contentPath).toURI();
    resources= new File(uri);
    listFiles = resources.listFiles();

    //do some file proccessing and load them
}
</code></pre>

<p>Way 2: paths used ""folderINeed"",""src/resources/blablabla/folderINeed"",""blablabla/folderINeed"",""../../../resources/blablabla/folderINeed"" &lt;--- URL return null but, at least, doesn't raise a NullPointerException.</p>

<pre><code>public void loadContent(String contentPath) throws Exception
{ 
    // conseguimos todas las carpetas de animaciones
    File resources;
    File[] listFiles = null;

    URL url = MyClass.class.getResource(contentPath);
    if (url == null) {
         // error - missing folder
    } else {
        resources = new File(url.toURI());
        listFiles = resources.listFiles();
    }
}
</code></pre>

<p>Way 3: some complex code using class JarFile that didn't work for me and was oriented to get a simple file, not a folder. Obtained <a href=""https://stackoverflow.com/questions/11012819/how-can-i-get-a-resource-folder-from-inside-my-jar-file"" title=""here"">here</a></p>
","<java><jar><resources><packaging><requirements>","2018-07-26 09:35:11","2928","0","2","51537188","<p><code>src/main/java/</code> is the build convention of <strong>maven</strong>, so I'll assume it is that.</p>

<p>Then one normally would pack the images as read-only resources in its own jar, a separate maven project <code>jarfile</code>.</p>

<p><code>jarfile/src/main/resources/</code> would be the root directory for the images. For instance:
<code>jarfile/src/main/resources/icons16/new.png</code> would then be accessed by something like:</p>

<pre><code>getClass().getResource(""/icons16/new.png""); // Class' package relative path
getClass().getResourceAsStream(""/icons16/new.png"");
getClassLoader().getResource(""icons16/new.png""); // Absolute class path path
</code></pre>

<p>In the original project one would add a <code>dependency</code> in the pom.xml to jarfile.</p>

<p>If you do no use maven, the jarfile.jar must be on the class path.</p>

<p><code>File</code> cannot be used with resources, but getResourceAsStream most often is feasible.</p>

<hr>

<p>To read a resource directory, the directory path should be rather unique,
and it is simply a list of file names in the directory resource.</p>

<pre><code>    InputStream in = App.class.getResourceAsStream(""/icons16"");
    try (BufferedReader rd = new BufferedReader(new InputStreamReader(in, ""UTF-8""))) {
        String line;
        while ((line = rd.readLine()) != null) {
            System.out.println(""line: "" + line);
        }
    }
</code></pre>
"
"51535618","Best practices for including large resource folder into java project","<p>I'm working on a project where having access to a big resource folder (structure with thousand of little images) is required. The client want to offer the app through a native installation (which includes the JVM that the app require to run). He doesn't want to pack that resources as a folder in the app because it would create a folder structure as big as the original in the final user's hard drive (the folder doesn't take much space but it has many little files), plus the folder could be stealed easily by simply copying it. Giving this, I can't package all the app with a resource folder in a jar file, as far as i know jar files are not installables. Another requirement is that client needs certain flexibility to add some files in a installed app folders structure to add new features to the program. So an installation is the only way (i think) to obtain this.</p>

<p>I've tried to pack them in a jar file, include it in the build path and tried to access it but i failed even with all the research i've made through various sites.  Tried getResources() in a million ways but it was impossible to get a simple directory inside the jar file meanwhile doing it from a folder outside the jar is really easy. I need to get access to a directory in order to get a list of files it cointains.</p>

<p>Arrived to this point. I've started to ask myself if i'm facing this problem on the best way so i wanted to ask you all: how would you package the resources you need in a native java app with this requirements?</p>

<p>I'm even thinking about create some kind of encryption proccess to create a single file with all the information and simply temporarily decrypt it when needed at runtime but i think there would be a simpler and cleaner way to face this.</p>

<p>Thank you in advance</p>

<p><strong>EDIT:</strong> As you asked for, i'm adding the code of what i've tried:</p>

<p>this is the project structure</p>

<pre><code>project
├───src
│   ├───main
│   │   └───java
│   │       ├───model &lt;--- where my class is
│   │       ├───controllers
│   │       ├───utilities
│   │       └───views
│   ├───resources &lt;--- this is where is (formerly) accessed the content i need
|   |   ├─── jarfile.jar &lt;--- i've placed file here and included to build path
│   │   └───-various folders and files -
│   └───test
└───target
</code></pre>

<p>inside the jar file there are the packages src.resources.blalblaba and inside of this, the folder i need</p>

<p>Way1: </p>

<p>getResources replacing jar file ""."" with ""/"" tried with paths: ""src/resources/blablabla/folderINeed"",""src/resources/src/resources/blablabla"" (due to possible duplicity), ""folderINeed"", ""blablabla/folderINeed""  -> URI always get NullPointerException with message ""null""</p>

<pre><code>public void loadContent(String contentPath) throws Exception
{ 
    File resources= null;
    File[] listFiles = null;

    URI uri = getClass().getClassLoader().getResource(contentPath).toURI();
    resources= new File(uri);
    listFiles = resources.listFiles();

    //do some file proccessing and load them
}
</code></pre>

<p>Way 2: paths used ""folderINeed"",""src/resources/blablabla/folderINeed"",""blablabla/folderINeed"",""../../../resources/blablabla/folderINeed"" &lt;--- URL return null but, at least, doesn't raise a NullPointerException.</p>

<pre><code>public void loadContent(String contentPath) throws Exception
{ 
    // conseguimos todas las carpetas de animaciones
    File resources;
    File[] listFiles = null;

    URL url = MyClass.class.getResource(contentPath);
    if (url == null) {
         // error - missing folder
    } else {
        resources = new File(url.toURI());
        listFiles = resources.listFiles();
    }
}
</code></pre>

<p>Way 3: some complex code using class JarFile that didn't work for me and was oriented to get a simple file, not a folder. Obtained <a href=""https://stackoverflow.com/questions/11012819/how-can-i-get-a-resource-folder-from-inside-my-jar-file"" title=""here"">here</a></p>
","<java><jar><resources><packaging><requirements>","2018-07-26 09:35:11","2928","0","2","51650404","<p><strong>MY WRONGS:</strong> </p>

<ul>
<li><p>As @Joop Egen told in his answer, one of my problem was my folder structure in the project. I was not following the maven convention of putting the resource folder in the src/main/ folder it's because of this all the solutions i were trying didn't have the necessary scope to get the resource folder. </p></li>
<li><p>I didn't know how jar files work with java. For java .jar files are a collection (not a Collection of java) of jar entries to every single file within them. In my single case, the .jar file was created using the Eclipse export wizard and didn't have any reference to folders, it just had references to files. So it's simply IMPOSSIBLE to get a folder with all its content. </p></li>
<li><p>I used the java JarFile class to manage the content but this class doesn't offer methods to manage files like java File class does. So it's not as easy to do as it is with another kind of files.</p></li>
</ul>

<p><strong>WHAT I'VE DONE:</strong> <br>
I've developed a code to read all the file entries in the .jar, discriminate the ones i was interested to. And then extract them to a directory within the app. By doing this i had standard access to them and, if i want to, i can simply remove the directory when the application closes. I was trying to use them directly from the jar but jar files are zip files so in some moment that inner files need to be extrated from the jar to somewhere as OS do with zip files. It's can a be a temp directory or not.</p>

<pre><code>import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.nio.file.Files;
import java.util.ArrayList;
import java.util.Enumeration;
import java.util.List;
import java.util.jar.JarEntry;
import java.util.jar.JarFile;
import org.apache.commons.io.FileUtils;

public class App
{
  public static void main(String[] args)
  {
    try
    {

      //needed attributes
      String pathToJar = ""./src/main/blablalba/fileName.jar"";
      String folderYouWantToRetrieveFromTheJar = ""/folderIWant"";
      String pathOfFilesWithinTheJar=""src/resources/blablabla/""+folderYouWantToRetrieveFromTheJar+""/"";
      String tempDirectoryWhereExtract=""./src/main/resources/temp"";

      //creating the temp directory
      File tempDirectoryReference = new File(tempDirectoryWhereExtract);
      if (!tempDirectoryReference.exists())
      {
        Files.createDirectory(tempDirectoryReference.toPath());
      }

      //searching what entries i need
      JarFile jar = new JarFile(pathToJar);
      final Enumeration&lt;JarEntry&gt; entries = jar.entries(); 
      List&lt;JarEntry&gt; targetEntries = new ArrayList&lt;&gt;();
      while (entries.hasMoreElements())
      {
        JarEntry entry = entries.nextElement();
        //if the entry is what i need 
        if (entry.getName().startsWith(pathOfFilesWithinTheJar))
        { 
          targetEntries.add(entry);
        }
      }
      //extract every target entry from the .jar
      for (JarEntry entry : targetEntries)
      {
        //in order to copy the structure i will get only the point where folderIWant is present
        int index = entry.getName().indexOf(folderYouWantToRetrieveFromTheJar);
        String newTemporaryPath = tempDirectoryReference.getPath().toString()+""/""+entry.getName().substring(index);
        extractFileFromJar(jar, entry, new File(newTemporaryPath));

      }

      jar.close();
      //(optional) clean after use
      FileUtils.deleteDirectory(tempDirectoryReference);


    }
    catch (IOException e)
    {
      // TODO Auto-generated catch block
      e.printStackTrace();
    }
  }

  public static void extractFileFromJar (JarFile jarFile, JarEntry targetEntry, File destinyPath)
  {
    try
    {
      if (!destinyPath.getParentFile().exists())
      {
        createFolderStructure(destinyPath);
      }
      else
      {
        Files.createFile(destinyPath.toPath());
      }

      InputStream inputStream = jarFile.getInputStream(targetEntry); 
      FileOutputStream outputStream = new java.io.FileOutputStream(destinyPath);
      while (inputStream.available() &gt; 0) {  
          outputStream.write(inputStream.read());
      }
      outputStream.flush();
      outputStream.close();
      inputStream.close();
    }
    catch (IOException e)
    {
      e.printStackTrace();
    }
  }


  private static void createFolderStructure(File destinyPath)
  {
    File parentPath = destinyPath.getParentFile();
    try
    {
      if (parentPath.exists())
      {
          Files.createFile(destinyPath.toPath());
      }
      else
      {
        Files.createDirectories(destinyPath.getParentFile().toPath());
        Files.createFile(destinyPath.toPath());
      }
    }
    catch(IOException e)
    {
      System.err.println(e.getMessage());
    }
  }
}
</code></pre>
"
"51441053","Minimum hardware and software requirements to install Xcode 10.0","<p>What are the minimum hardware and software specifications to install Xcode 10.0 in a MAC mini and Macbook Pro? How much RAM is required? What processor is required?</p>
","<xcode><xcode10>","2018-07-20 11:00:44","27075","8","1","51441220","<p>These are specification for Xcode 10</p>

<ol>
<li><p>Xcode 10 requires a Mac running macOS 10.13.6 or later..</p></li>
<li><p>Xcode 10 includes SDKs for iOS 12, watchOS 5, macOS 10.14, and tvOS 12.</p></li>
<li><p>Xcode 10 supports running multiple concurrent versions of the Xcode app and of any associated tools such as Simulator.</p></li>
<li><p>Xcode 10 can coexist with previous versions of Xcode.</p></li>
</ol>

<p>reference: <a href=""https://developer.apple.com/documentation/xcode_release_notes/xcode_10_release_notes"" rel=""noreferrer"">https://developer.apple.com/documentation/xcode_release_notes/xcode_10_release_notes</a></p>
"
"51020927","MS VSTS How do I view Requirements in a tree","<p>We are in the process of evaluating VSTS as a Requirements/Test Management platform.</p>

<p>Is there a way of viewing Requirements (Or Work Items in General) in a tree structure?</p>

<p>I have tried but can't find any way of doing it.</p>

<p>Cheers</p>
","<tree><azure-devops><requirements><workitem>","2018-06-25 10:08:44","145","0","1","51038326","<p>If you mean map child work items to parents and show the work items in a tree structure, then you can try below ways:</p>

<ul>
<li><p>In <strong>Backlog</strong>:</p>

<p>You can set <code>Parents</code> to <code>Show</code> and click the expand <code>＋</code> icon to
expand <code>one level</code> of the hierarchy (click twice to expand two
levels). See <a href=""https://learn.microsoft.com/en-us/vsts/work/backlogs/organize-backlog?view=vsts&amp;tabs=horizontal#show-parents-and-expand-the-tree-hierarchy"" rel=""nofollow noreferrer"">Show parents and expand the tree hierarchy</a></p></li>
<li><p>In <strong>query</strong>: </p>

<p>Use the tree query (<code>Tree of work items</code>) to view a multi-tiered, nested list of work items.
See <a href=""https://learn.microsoft.com/en-us/vsts/work/track/using-queries?view=vsts&amp;tabs=new-query-exp#use-a-tree-query-to-view-hierarchies"" rel=""nofollow noreferrer"">Use a tree query to view hierarchies</a></p></li>
</ul>

<p><a href=""https://i.stack.imgur.com/EpSfL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/EpSfL.png"" alt=""enter image description here""></a></p>
"
"50963447","Swift - Conform third-party type to my own protocol with conflicting requirement","<p>Here's the boiled down situation:</p>

<p>Let's say a third-party framework written by Alice Allman provides a very useful class:</p>

<pre><code>public class AATrackpad {
  public var cursorLocation: AAPoint = .zero
}
</code></pre>

<p>and another framework written by Bob Bell provides a different class:</p>

<pre><code>public class BBMouse {
  public var where_is_the_mouse: BBPoint = .zero
}
</code></pre>

<p>At runtime either one of these classes may be needed depending on which piece of hardware the user has decided to use. Therefore, in keeping with the <a href=""https://drive.google.com/file/d/0BwhCYaYDn8EgMjdlMWIzNGUtZTQ0NC00ZjQ5LTkwYzQtZjRhMDRlNTQ3ZGMz/view"" rel=""nofollow noreferrer"">Dependency Inversion Principle</a>, I do not want my own types to depend on <code>AATrackpad</code> or <code>BBMouse</code> directly. Rather, I want to define a protocol which describes the behaviors I need:</p>

<pre><code>protocol CursorInput {
  var cursorLocation: CGPoint { get }
}
</code></pre>

<p>and then have my own types make use of that protocol instead:</p>

<pre><code>class MyCursorDescriber {
  var cursorInput: CursorInput?

  func descriptionOfCursor () -&gt; String {
    return ""Cursor Location: \(cursorInput?.cursorLocation.description ?? ""nil"")""
  }
}
</code></pre>

<p>I want to be able to use an instance of <code>BBMouse</code> as the cursor input, like this:</p>

<pre><code>let myCursorDescriber = MyCursorDescriber()
myCursorDescriber.cursorInput = BBMouse()
</code></pre>

<p>but in order for this to compile I have to retroactively conform <code>BBMouse</code> to my protocol:</p>

<pre><code>extension BBMouse: CursorInput {
  var cursorLocation: CGPoint {
    return CGPoint(x: self.where_is_the_mouse.x, y: self.where_is_the_mouse.y)
  }
}
</code></pre>

<p>Now that I've conformed <code>BBMouse</code> to my <code>CursorInput</code> protocol, my code compiles and my architecture is the way I want it. The reason I have no problem here is that I think that <code>where_is_the_mouse</code> is a terrible name for that property, and I'm quite happy to never use that name again. However, with <code>AATrackpad</code> its a different story. I happen to think that Alice named her <code>cursorLocation</code> property perfectly, and as you can see I want to be able to use the same name for my protocol requirement. My problem is that <code>AATrackpad</code> does not use <code>CGPoint</code> as the type of this property, but instead uses a proprietary point type called <code>AAPoint</code>. The fact that my protocol requirement (<code>cursorLocation</code>) has the same name as an existing property of <code>AATrackpad</code> but a different type means that I can't retroactively conform to <code>CursorInput</code>:</p>

<pre><code>extension AATrackpad: CursorInput {
  var cursorLocation: CGPoint { // -- Invalid redeclaration
    return CGPoint(x: self.cursorLocation.x, y: self.cursorLocation.y) // -- Infinite recursion
  }
}
</code></pre>

<p>As the comments in that snippet say, this code does not compile, and even if it did I'd be facing an infinite recursion at runtime because I have no way to specifically reference the <code>AATrackpad</code> version of <code>cursorLocation</code>. It would be great if something like this would work <code>(self as? AATrackpad)?.cursorLocation</code>, but I don't believe this makes sense in this context. Again though, the protocol conformance won't even compile in the first place, so disambiguating in order to solve the infinite recursion is secondary.</p>

<p>With all of that context in mind, my question is:</p>

<p>If I architect my app using protocols (which is widely recommended, for good reason), is it really true that my ability to use a certain third-party concrete type depends on the hope this third-party developer doesn't share my taste for naming conventions?</p>

<hr>

<p>NOTE: The answer <strong>""Just pick a name that doesn't conflict with the types you want to use""</strong> won't be satisfactory. Maybe in the beginning I only had <code>BBMouse</code> and had no conflicts, and then a year later I decided that I wanted to add support for <code>AATrackpad</code> as well. I initially chose a great name and it's now used pervasively throughout my app - should I have to change it everywhere for the sake of one new concrete type? What happens later on when I want to add support for <code>CCStylusTablet</code>, which now conflicts with whatever new name I chose? Do I have to change the name of my protocol requirement <em>again</em>? I hope you see why I'm looking for a more sound answer than that.</p>
","<swift><protocols><conflict><requirements><dependency-inversion>","2018-06-21 08:06:40","402","3","1","50984709","<p>Inspired by Jonas Maier's comment, I found what I believe to be an architecturally adequate solution to this problem. As Jonas said, function overloading exhibits the behavior that I'm looking for. I'm starting to think that maybe protocol requirements should only ever be functions, and not properties. Following this line of thinking, my protocol will now be:</p>

<pre><code>protocol CursorInput {
  func getCursorLocation () -&gt; CGPoint
  func setCursorLocation (_ newValue: CGPoint)
}
</code></pre>

<p><em>(Note that in this answer I'm making it settable as well, unlike in the original post.)</em></p>

<p>I can now retroactively conform <code>AATrackpad</code> to this protocol without conflict:</p>

<pre><code>extension AATrackpad: CursorInput {
  func getCursorLocation () -&gt; CGPoint {
    return CGPoint(x: self.cursorLocation.x, y: self.cursorLocation.y)
  }
  func setCursorLocation (_ newValue: CGPoint) {
    self.cursorLocation = AAPoint(newValue)
  }
}
</code></pre>

<p><strong>Important -</strong> This will still compile even if <code>AATrackpad</code> already has a function <code>func getCursorLocation () -&gt; AAPoint</code>, which has the same name but a different type. This behavior is exactly what I was wanting from my property in the original post. Thus:</p>

<p><em>The major problem with including a property in a protocol is that it can render certain concrete types literally incapable of conforming to that protocol due to namespace collisions.</em></p>

<p>After solving this in this way, I have a new problem to solve: there was a reason I wanted <code>cursorLocation</code> to be a property and not a function. I definitely do not want to be forced to use the <code>getPropertyName()</code> syntax all across my app. Thankfully, this can be solved, like this:</p>

<pre><code>extension CursorInput {
  var cursorLocation: CGPoint {
    get { return self.getCursorLocation() }
    set { self.setCursorLocation(newValue) }
  }
}
</code></pre>

<p>This is what is so cool about protocol extensions. Anything declared in a protocol extension behaves analogously to a default argument for a function - only used if nothing else takes precedence. Because of this different mode of behavior, this property does not cause a conflict when I conform <code>AATrackpad</code> to <code>CursorInput</code>. I can now use the property semantics that I originally wanted and I don't have to worry about namespace conflicts. I'm satisfied.</p>

<hr>

<p><strong>""Wait a second - now that</strong> <code>AATrackpad</code> <strong>conforms to</strong> <code>CursorInput</code><strong>, doesn't it have two versions of</strong> <code>cursorLocation</code><strong>? If I were to use</strong> <code>trackpad.cursorLocation</code><strong>, would it be a</strong> <code>CGPoint</code> <strong>or an</strong> <code>AAPoint</code><strong>?</strong></p>

<p>The way this works is this - if within this scope the object is known to be an <code>AATrackpad</code> then Alice's original property is used:</p>

<pre><code>let trackpad = AATrackpad()
type(of: trackpad.cursorLocation) // This is AAPoint
</code></pre>

<p>However, if the type is known only to be a <code>CursorInput</code> then the default property that I defined gets used:</p>

<pre><code>let cursorInput: CursorInput = AATrackpad()
type(of: cursorInput.cursorLocation) // This is CGPoint
</code></pre>

<p>This means that if I do happen to know that the type is <code>AATrackpad</code> then I can access either version of the property like this:</p>

<pre><code>let trackpad = AATrackpad()
type(of: trackpad.cursorLocation) // This is AAPoint
type(of: (trackpad as CursorInput).cursorLocation) // This is CGPoint
</code></pre>

<p>and it also means that my use case is exactly solved, because I specifically wanted <em>not</em> to know whether my <code>cursorInput</code> happens to be an <code>AATrackpad</code> or a <code>BBMouse</code> - only that it is some kind of <code>CursorInput</code>. Therefore, wherever I am using my <code>cursorInput: CursorInput?</code>, its properties will be of the types which I defined in the protocol extension, not the original types defined in the class.</p>

<hr>

<p>There is one possibility that a protocol with only functions as requirements could cause a namespace conflict - Jonas pointed this out in his comment. If one of the protocol requirements is a function with no arguments and the conforming type already has a property with that name then the type will not be able to conform to the protocol. This is why I made sure to name my functions including verbs, not just nouns (<code>func getCursorLocation () -&gt; CGPoint</code>) - if any third-party type is using a verb in a property name then I probably don't want to be using it anyway :)</p>
"
"50866024","Drupal 8, just after installing, css files can't loaded, server error 500","<p>I have just installed Drupal 8.5.4, like this:</p>

<ul>
<li><p>get the code from the site</p></li>
<li><p>extracted it in the s folder on my site ('katelec.com/s').</p></li>
<li><p>create database, installed the site.</p></li>
</ul>

<p>when trying to access the site, no styles loaded.</p>

<p>when trying to access any css file i get server error 500.</p>

<p>the style are generated correctly and lay in the corresponding folder.</p>

<p>everything went well when I disabled css / js aggregation.</p>

<p>PHP Version 7.0.30
Memory limit: 500M
TRUSTED HOST SETTINGS</p>

<p>Why I get this error?</p>
","<installation><drupal-8><requirements>","2018-06-14 21:13:11","282","0","1","50878465","<p>After reviewing server log.</p>

<p>Drupal's .htaccess files has a command to stop cgi from running.</p>

<p>And it seems that the shared hosting I'm using disabled cgi.</p>

<blockquote>
  <p>So I edited .htaccess file by removing that cgi command.</p>
</blockquote>
"
"50861906","Could not find a version that satisfies the requirement <every package> , No matching distribution","<p>On windows, I can't install any packages of these : numpy, matplotlib, skimage,...</p>

<p>My python version is 2.7</p>

<p>Everytime the same error :</p>

<p><strong>Could not find a version that satisfies the requirement scikit-image (from ver
sions: )
No matching distribution found for scikit-image</strong></p>

<p>I have tried to consider 'abce' requirements, but didn't work.</p>

<p>Thank you very much for helping me</p>
","<windows><pip><scikit-image><requirements>","2018-06-14 16:17:50","10750","5","1","50892195","<p>You're using pip to install your packages ?</p>

<p>First install numpy : <code>pip install numpy</code></p>

<p>Then install matplotlib <code>pip install matplotlib</code></p>

<p>Then install scipy <code>pip install scipy</code></p>

<p>And finally install skimage <code>pip install scikit-image</code></p>

<p>The error you obtain means that you're not giving the right name for your package</p>

<p>Hope it helps</p>

<p>Cheers</p>
"
"50742839","How to use the proxy provided in .condarc for pip packages in the environment.yml?","<p>I have to use a proxy, which I have configured in the .condarc file, for conda work, which works perfectly fine. However when I'm setting up a new python environment with an environment.yml file, which could look like this:</p>

<pre><code>name: Test
channels:
  - intel
  - defaults
dependencies:
  - pypdf2=1.26.0=py36_1
  - mkl=2018.0.2=1
  - pip:
    - adjusttext==0.7.2
prefix: C:\ProgramData\Anaconda3\envs\Test
</code></pre>

<p>Pip doesn't use the provided proxy to install those packages, so I get an error. How can I get pip to use that proxy as well?</p>
","<python><proxy><pip><conda><requirements>","2018-06-07 13:44:10","1558","3","2","51629346","<p>Indeed pip doesn't pick proxy settings from .condarc.
But it will use HTTPS_PROXY environment variable if present.
Just add this line to .bash_profile:
export HTTPS_PROXY=<a href=""https://user:pwd@proxy_host:port"" rel=""nofollow noreferrer"">https://user:pwd@proxy_host:port</a></p>
"
"50742839","How to use the proxy provided in .condarc for pip packages in the environment.yml?","<p>I have to use a proxy, which I have configured in the .condarc file, for conda work, which works perfectly fine. However when I'm setting up a new python environment with an environment.yml file, which could look like this:</p>

<pre><code>name: Test
channels:
  - intel
  - defaults
dependencies:
  - pypdf2=1.26.0=py36_1
  - mkl=2018.0.2=1
  - pip:
    - adjusttext==0.7.2
prefix: C:\ProgramData\Anaconda3\envs\Test
</code></pre>

<p>Pip doesn't use the provided proxy to install those packages, so I get an error. How can I get pip to use that proxy as well?</p>
","<python><proxy><pip><conda><requirements>","2018-06-07 13:44:10","1558","3","2","63356126","<p>Struggled with this issue a lot working on Win10. When modifying <code>https_proxy</code> I had issues with git, but with a file <code>pip.ini</code> in <code>C:\ProgramData\pip\</code> as <code>C:\ProgramData\pip\pip.ini</code> it works finally:</p>
<p><code>pip.ini</code>:</p>
<pre><code>[global]
timeout = 10
proxy=http://myproxy:8080
cert = C:\Users\Public\mycert.cer
</code></pre>
<p>now I can install conda environments with included pip packages</p>
<p>for more infos for default location visit: <a href=""https://pip.pypa.io/en/stable/user_guide/"" rel=""nofollow noreferrer"">https://pip.pypa.io/en/stable/user_guide/</a></p>
"
"50685300","Local dependencies requeriments.txt for Bluemix server","<p>I want to upload a flask server to bluemix. The structure of my project is something like this</p>

<ul>
<li>Classes

<ul>
<li>functions.py</li>
</ul></li>
<li>Watson

<ul>
<li>bot.py</li>
</ul></li>
<li>requirements.txt</li>
<li>runtime.txt</li>
<li>Procfile</li>
<li>manifest.yml</li>
</ul>

<p>my bot.py has this dependency:  </p>

<pre><code>from classes import functions
</code></pre>

<p>I have tried to include it in the manifest using things like this:<br>
./classes or ./classes/functions</p>

<p>but I have had no luck, it keeps saying either that module is not found or things like pip.exceptions.InstallationError: Invalid requirement: './classes/functions'</p>

<p>I dont know how to add the dependency</p>

<p>manifest.yml</p>

<pre><code>---
applications:
- name: chatbotstest
  random-route: true
  memory: 256M
</code></pre>

<p>Procfile (the file that I use to run the app)</p>

<pre><code>web: python watson/bot.py
</code></pre>

<p>when I print my sys.path I get this:</p>

<pre><code>    ['..', '/home/vcap/app/watson', '/home/vcap/deps/0/python/lib/python36.zip', '/home/vcap/deps/0/py
e/vcap/deps/0/python/lib/python3.6/lib-dynload', '/home/vcap/deps/0/python/lib/python3.6/site-packages', '/home/vcap/deps/0/python/lib/python3.6/site-
-py3.6.egg', '/home/vcap/deps/0/python/lib/python3.6/site-packages/pip-9.0.1-py3.6.egg']
</code></pre>

<p>I have tried to add the folder parent to my script using </p>

<p>Thanks a lot for your help!!!</p>
","<python><flask><pip><ibm-cloud><requirements>","2018-06-04 16:48:48","47","0","2","50685605","<p>You don't need to include it into the manifest file. Your entire app directory and its subdirectories are uploaded as part of the <code>push</code> command. Thereafter, it is possible to reference the file as shown.</p>

<p>This imports a file in the current directory:</p>

<pre><code>import myfile
</code></pre>

<p>This should work for your <code>functions.py</code>:</p>

<pre><code>from classes import functions
</code></pre>
"
"50685300","Local dependencies requeriments.txt for Bluemix server","<p>I want to upload a flask server to bluemix. The structure of my project is something like this</p>

<ul>
<li>Classes

<ul>
<li>functions.py</li>
</ul></li>
<li>Watson

<ul>
<li>bot.py</li>
</ul></li>
<li>requirements.txt</li>
<li>runtime.txt</li>
<li>Procfile</li>
<li>manifest.yml</li>
</ul>

<p>my bot.py has this dependency:  </p>

<pre><code>from classes import functions
</code></pre>

<p>I have tried to include it in the manifest using things like this:<br>
./classes or ./classes/functions</p>

<p>but I have had no luck, it keeps saying either that module is not found or things like pip.exceptions.InstallationError: Invalid requirement: './classes/functions'</p>

<p>I dont know how to add the dependency</p>

<p>manifest.yml</p>

<pre><code>---
applications:
- name: chatbotstest
  random-route: true
  memory: 256M
</code></pre>

<p>Procfile (the file that I use to run the app)</p>

<pre><code>web: python watson/bot.py
</code></pre>

<p>when I print my sys.path I get this:</p>

<pre><code>    ['..', '/home/vcap/app/watson', '/home/vcap/deps/0/python/lib/python36.zip', '/home/vcap/deps/0/py
e/vcap/deps/0/python/lib/python3.6/lib-dynload', '/home/vcap/deps/0/python/lib/python3.6/site-packages', '/home/vcap/deps/0/python/lib/python3.6/site-
-py3.6.egg', '/home/vcap/deps/0/python/lib/python3.6/site-packages/pip-9.0.1-py3.6.egg']
</code></pre>

<p>I have tried to add the folder parent to my script using </p>

<p>Thanks a lot for your help!!!</p>
","<python><flask><pip><ibm-cloud><requirements>","2018-06-04 16:48:48","47","0","2","50698219","<p>Thanks a lot, this finally worked for me, the answered you pointed me to gave me the solution, thanks a lot again!</p>

<pre><code>currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))
parentdir = os.path.dirname(currentdir)
sys.path.insert(0,parentdir)
</code></pre>
"
"50362158","Need answers regarding MongoDB set up on local machine for lot of data","<p>I have data more than 200gb and it is in JSON and CSV format and more than 300millian rows (documents). </p>

<p>I want to store it in MongoDB Database. I want to know that what requirement of the machine to handle this process like store and retrieval and manipulation of data. Also what time it would take to search data from whole data?</p>
","<mongodb><performance><mongodb-query><requirements>","2018-05-16 03:40:44","60","0","1","50364319","<p>IMO, technical choice depends on your data structure and how to use these data. Below answer <strong>assumed you store all the data into a single collection in a single mongodb instance in a single machine</strong>.</p>

<hr>

<p>I did an experiment in the past to test the performance of mongodb with large data. I will share the result to you.</p>

<h2>Data volume</h2>

<ul>
<li>Amount of data: 1 Billion</li>
<li>document format: 4 fields(ObjectID + Int + String + Date) ~ 200Bytes/document</li>
<li>All documents are stored into one collection</li>
</ul>

<h2>Hardware</h2>

<ul>
<li>CPU: Intel(R) Xeon(R) CPU E5-2620 v2 @ 2.10Ghz(4 cores)</li>
<li>RAM: 32GB</li>
<li>Disk: 2TB LSI MRSASRoMB-8i SCSI Disk Device</li>
</ul>

<h2>Software</h2>

<ul>
<li>OS: Redhat Sever6.4-X86-64 with Ext4</li>
<li>Mongodb: 3.2 x64 (engine: wireTiger, cacheSize set to 28GB)</li>
</ul>

<h2>Test result</h2>

<h3>Insert performance</h3>

<p>Before index creation: No additional index(only default _id index)
After index creation: Add one more index on the string field</p>

<pre><code>╔══════════════════════╦═══════════════════════╦══════════════════════╗
║                      ║ Before index creation ║ After index creation ║
╠══════════════════════╬═══════════════════════╬══════════════════════╣
║ Single thread insert ║ 656/s - 746/s         ║ 534/s - 712/s        ║
║ 10 Threads insert    ║ 3817/s - 3964/s       ║ 3306/s - 3389/s      ║
╚══════════════════════╩═══════════════════════╩══════════════════════╝
</code></pre>

<h3>Query performance</h3>

<p>Query by the string field.</p>

<pre><code>╔═══════════════════╦═══════════════════════╦══════════════════════╗
║                   ║ Before index creation ║ After index creation ║
╠═══════════════════╬═══════════════════════╬══════════════════════╣
║ Return 1 document ║ 1268904 ms            ║ 15 ms                ║
╚═══════════════════╩═══════════════════════╩══════════════════════╝
</code></pre>

<h3>Build index</h3>

<p>If build index on string field after already 1 Billion documents in the collection, <strong>it takes ~3 hours to finish.</strong></p>

<h3>RAM consumption</h3>

<p>In the insert test, when all the cahce(28GB) runs out, the insert speed will drop.</p>

<h2>Conclusion</h2>

<ol>
<li><p>No big different between before index &amp; after index in insert performance.(In my condition, not sure when created a lot of indexes)</p></li>
<li><p>Mongodb tend to use as much as RAM it can, if you have large hot data, you'd better provide large RAM to it.</p></li>
<li><p>If built good index, then the query performance is good at Billion data level.</p></li>
<li><p>Build index on large data will cost you a lot of time.</p></li>
</ol>
"
"49747973","what necessary requirements to support the arcore in a android phone","<p>If i have a android phone. and i want to know if my phone support ARCORE?
Is there any requests necessary ?
Such as the fps of the camera、 size of images 、Android version and so on.
I want to get some specific requirements to assess whether or not it is supported.
Thanks!</p>
","<android-camera><requirements><arcore>","2018-04-10 07:38:31","3277","0","1","49760199","<p>ARCore currently has a specific set of devices that it supports:</p>

<p><a href=""https://developers.google.com/ar/discover/#supported_devices"" rel=""nofollow noreferrer"">https://developers.google.com/ar/discover/#supported_devices</a></p>

<p>Within your application, you can use the <code>ArCoreApk</code> API provided to check whether the current device supports ARCore:</p>

<p><a href=""https://developers.google.com/ar/reference/java/com/google/ar/core/ArCoreApk"" rel=""nofollow noreferrer"">https://developers.google.com/ar/reference/java/com/google/ar/core/ArCoreApk</a></p>

<p>The ARCore sample applications provide a good example of how to use this API:</p>

<p><a href=""https://github.com/google-ar/arcore-android-sdk/blob/master/samples/hello_ar_java/app/src/main/java/com/google/ar/core/examples/java/helloar/HelloArActivity.java#L118"" rel=""nofollow noreferrer"">https://github.com/google-ar/arcore-android-sdk/blob/master/samples/hello_ar_java/app/src/main/java/com/google/ar/core/examples/java/helloar/HelloArActivity.java#L118</a></p>
"
"49067215","Testing if a string is null","<p>I am pretty new in VBA and I have not yet got used to the syntax completely, so I'm sorry if my question sounds stupid.</p>

<p>I am working with RequisitePro40 and VBA 7.0 in Word 2010. In one of my modules I have the following loop and If conditions:</p>

<pre><code>Dim rqRequirements As ReqPro40.Requirements
Dim rqRequirement As ReqPro40.Requirement
Const eAttrValueLookup_Label = 4
Dim a As Integer
...

For Each vReqKey In rqRequirements
    Set rqRequirement = rqRequirements(vReqKey)

    If rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text &lt;&gt; Null Then
        a = 1
    End If

    If rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text = Null Then
         a = 2
    End If

 Next
</code></pre>

<p>In each iteration of the loop, both <strong>a = 1</strong> and <strong>a = 2</strong> are executed!!</p>

<p>Based on <a href=""https://learn.microsoft.com/en-us/dotnet/visual-basic/language-reference/operators/comparison-operators"" rel=""nofollow noreferrer"">This</a>, the equality and inequality operators are ""="" and ""&lt;>"". Therefore I would expect that either <strong>a = 1</strong> or <strong>a = 2</strong> execute for a string.
Is there something wrong with my syntax? Or is it a ReqPro related Problem?</p>

<p>I also tried using ""Is"" and ""IsNot"" operators but they result in Compiler error: Type mismatch</p>

<p>Can Someone help me with this?</p>

<p><strong>Update:</strong> The actual goal is to see if the</p>

<blockquote>
  <p>rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text</p>
</blockquote>

<p>is Null or not. I added the second if to show the problem that the statement is somehow not working the way I expect it to work.</p>

<p>Replacing ""Null"" to ""vbNullString"" did not make any changes.</p>

<p>I also tried the IsNull function as @Slai suggested. the result is pretty much the same:</p>

<pre><code>    If IsNull(rqRequirement.AttrValue(att, eAttrValueLookup_Label).text) Then
        a = 3
    End If

    If Not IsNull(rqRequirement.AttrValue(att, eAttrValueLookup_Label).text) Then
        a = 4
    End If
</code></pre>

<p>Both statements <strong>a = 3</strong> and <strong>a = 4</strong> are true and executed.</p>
","<vba><ms-word><requirements>","2018-03-02 10:25:04","30847","8","5","49067344","<p>1) I think you can use vbNullString to test for empty string. Otherwise use ""Null"" if actual string value.</p>

<p>2) Ensure a is declared as long</p>

<pre><code>If rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text &lt;&gt; vbNullString Then

     a = 1

End If

If rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text = vbNullString Then
     a = 2
Else
     a = 3
End If
</code></pre>
"
"49067215","Testing if a string is null","<p>I am pretty new in VBA and I have not yet got used to the syntax completely, so I'm sorry if my question sounds stupid.</p>

<p>I am working with RequisitePro40 and VBA 7.0 in Word 2010. In one of my modules I have the following loop and If conditions:</p>

<pre><code>Dim rqRequirements As ReqPro40.Requirements
Dim rqRequirement As ReqPro40.Requirement
Const eAttrValueLookup_Label = 4
Dim a As Integer
...

For Each vReqKey In rqRequirements
    Set rqRequirement = rqRequirements(vReqKey)

    If rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text &lt;&gt; Null Then
        a = 1
    End If

    If rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text = Null Then
         a = 2
    End If

 Next
</code></pre>

<p>In each iteration of the loop, both <strong>a = 1</strong> and <strong>a = 2</strong> are executed!!</p>

<p>Based on <a href=""https://learn.microsoft.com/en-us/dotnet/visual-basic/language-reference/operators/comparison-operators"" rel=""nofollow noreferrer"">This</a>, the equality and inequality operators are ""="" and ""&lt;>"". Therefore I would expect that either <strong>a = 1</strong> or <strong>a = 2</strong> execute for a string.
Is there something wrong with my syntax? Or is it a ReqPro related Problem?</p>

<p>I also tried using ""Is"" and ""IsNot"" operators but they result in Compiler error: Type mismatch</p>

<p>Can Someone help me with this?</p>

<p><strong>Update:</strong> The actual goal is to see if the</p>

<blockquote>
  <p>rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text</p>
</blockquote>

<p>is Null or not. I added the second if to show the problem that the statement is somehow not working the way I expect it to work.</p>

<p>Replacing ""Null"" to ""vbNullString"" did not make any changes.</p>

<p>I also tried the IsNull function as @Slai suggested. the result is pretty much the same:</p>

<pre><code>    If IsNull(rqRequirement.AttrValue(att, eAttrValueLookup_Label).text) Then
        a = 3
    End If

    If Not IsNull(rqRequirement.AttrValue(att, eAttrValueLookup_Label).text) Then
        a = 4
    End If
</code></pre>

<p>Both statements <strong>a = 3</strong> and <strong>a = 4</strong> are true and executed.</p>
","<vba><ms-word><requirements>","2018-03-02 10:25:04","30847","8","5","49068375","<p>VBA doesn't support testing whether a string is ""Null"". VBA isn't like a .NET language or JavaScript (for example). The basic variable types all have a default value, a String is of zero length (<code>""""</code>) from the moment the variable is declared - it has no uninstantiated state. You can also test for vbNullString.</p>

<p>If you test</p>

<pre><code>Dim s as String
Debug.Print s = Null, s &lt;&gt; Null, s = """", s = ""a"", IsNull(s), s = vbNullString
</code></pre>

<p>The return is</p>

<pre><code>Null  Null  True  False  False  True
</code></pre>

<p>So if you're trying to test whether anything has been assigned to a String variable the only things you can do are:</p>

<pre><code>Debug.Print Len(s), s = """", Len(s) = 0, s = vbNullString
</code></pre>

<p>Which returns</p>

<pre><code>0  True  True True
</code></pre>

<p>Note that the slowest of these possibilities is <code>s = """"</code>, even though it seems the simplest to remember.</p>
"
"49067215","Testing if a string is null","<p>I am pretty new in VBA and I have not yet got used to the syntax completely, so I'm sorry if my question sounds stupid.</p>

<p>I am working with RequisitePro40 and VBA 7.0 in Word 2010. In one of my modules I have the following loop and If conditions:</p>

<pre><code>Dim rqRequirements As ReqPro40.Requirements
Dim rqRequirement As ReqPro40.Requirement
Const eAttrValueLookup_Label = 4
Dim a As Integer
...

For Each vReqKey In rqRequirements
    Set rqRequirement = rqRequirements(vReqKey)

    If rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text &lt;&gt; Null Then
        a = 1
    End If

    If rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text = Null Then
         a = 2
    End If

 Next
</code></pre>

<p>In each iteration of the loop, both <strong>a = 1</strong> and <strong>a = 2</strong> are executed!!</p>

<p>Based on <a href=""https://learn.microsoft.com/en-us/dotnet/visual-basic/language-reference/operators/comparison-operators"" rel=""nofollow noreferrer"">This</a>, the equality and inequality operators are ""="" and ""&lt;>"". Therefore I would expect that either <strong>a = 1</strong> or <strong>a = 2</strong> execute for a string.
Is there something wrong with my syntax? Or is it a ReqPro related Problem?</p>

<p>I also tried using ""Is"" and ""IsNot"" operators but they result in Compiler error: Type mismatch</p>

<p>Can Someone help me with this?</p>

<p><strong>Update:</strong> The actual goal is to see if the</p>

<blockquote>
  <p>rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text</p>
</blockquote>

<p>is Null or not. I added the second if to show the problem that the statement is somehow not working the way I expect it to work.</p>

<p>Replacing ""Null"" to ""vbNullString"" did not make any changes.</p>

<p>I also tried the IsNull function as @Slai suggested. the result is pretty much the same:</p>

<pre><code>    If IsNull(rqRequirement.AttrValue(att, eAttrValueLookup_Label).text) Then
        a = 3
    End If

    If Not IsNull(rqRequirement.AttrValue(att, eAttrValueLookup_Label).text) Then
        a = 4
    End If
</code></pre>

<p>Both statements <strong>a = 3</strong> and <strong>a = 4</strong> are true and executed.</p>
","<vba><ms-word><requirements>","2018-03-02 10:25:04","30847","8","5","49069438","<p>As others have noted, you want to test against the null version of a string, vbNullString, and not against <code>Null</code> specifically. In addition to this, you also need to make sure your object isn't null itself. For example:</p>

<pre><code>Dim rqRequirements As ReqPro40.Requirements
Dim rqRequirement As ReqPro40.Requirement
Const eAttrValueLookup_Label = 4
Dim a As Long ' Avoid Integer since it has a strong habit of causing overflow errors.
...

For Each vReqKey In rqRequirements
    Set rqRequirement = rqRequirements(vReqKey)

    If Not rqRequirement Is Nothing Then
        If rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text &lt;&gt; vbNullString Then
            a = 1
        End If

        If rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text = vbNullString Then
             a = 2
        End If
    End If
 Next
</code></pre>

<p>Now, I haven't worked with this specific object type before, but I am fairly certain that <code>AttrValue(""MyAttreName"", eAttrValueLookup_Label)</code> is returning some kind of object. If this is the case, then the below pattern would be preferred:</p>

<pre><code>    Dim rqRequirements As ReqPro40.Requirements
    Dim rqRequirement As ReqPro40.Requirement
    Const eAttrValueLookup_Label = 4
    Dim a As Long ' Avoid Integer since it has a strong habit of causing overflow errors.
    ...

    For Each vReqKey In rqRequirements
        Set rqRequirement = rqRequirements(vReqKey)

        If Not rqRequirement Is Nothing Then
            Dim Attribute as Object ' Or whatever type it should be
            Set Attribute = rq.Requirement.AttrValue(""MyAttreName"", eAttrValueLookup)
            If Not Attribute is Nothing Then
                If Attribute.text &lt;&gt; Null Then
                    a = 1
                End If

                If Attribute.text = Null Then
                     a = 2
                End If
            End If
        End If
     Next
</code></pre>

<p>In this way, we are only ever calling upon the <code>text</code> property of the <code>Attribute</code> if we have actually set the <code>Attribute</code>. This avoids 424 errors down the line.</p>

<p>Finally, if you want to figure out what is happening in the code that is causing both if's to run, do something like this:</p>

<p><code>Debug.Print ""Attribute Text: "", Attribute.Text</code></p>

<p>This will allow you to see what your code is seeing. You can consider using breakpoints as well.</p>
"
"49067215","Testing if a string is null","<p>I am pretty new in VBA and I have not yet got used to the syntax completely, so I'm sorry if my question sounds stupid.</p>

<p>I am working with RequisitePro40 and VBA 7.0 in Word 2010. In one of my modules I have the following loop and If conditions:</p>

<pre><code>Dim rqRequirements As ReqPro40.Requirements
Dim rqRequirement As ReqPro40.Requirement
Const eAttrValueLookup_Label = 4
Dim a As Integer
...

For Each vReqKey In rqRequirements
    Set rqRequirement = rqRequirements(vReqKey)

    If rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text &lt;&gt; Null Then
        a = 1
    End If

    If rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text = Null Then
         a = 2
    End If

 Next
</code></pre>

<p>In each iteration of the loop, both <strong>a = 1</strong> and <strong>a = 2</strong> are executed!!</p>

<p>Based on <a href=""https://learn.microsoft.com/en-us/dotnet/visual-basic/language-reference/operators/comparison-operators"" rel=""nofollow noreferrer"">This</a>, the equality and inequality operators are ""="" and ""&lt;>"". Therefore I would expect that either <strong>a = 1</strong> or <strong>a = 2</strong> execute for a string.
Is there something wrong with my syntax? Or is it a ReqPro related Problem?</p>

<p>I also tried using ""Is"" and ""IsNot"" operators but they result in Compiler error: Type mismatch</p>

<p>Can Someone help me with this?</p>

<p><strong>Update:</strong> The actual goal is to see if the</p>

<blockquote>
  <p>rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text</p>
</blockquote>

<p>is Null or not. I added the second if to show the problem that the statement is somehow not working the way I expect it to work.</p>

<p>Replacing ""Null"" to ""vbNullString"" did not make any changes.</p>

<p>I also tried the IsNull function as @Slai suggested. the result is pretty much the same:</p>

<pre><code>    If IsNull(rqRequirement.AttrValue(att, eAttrValueLookup_Label).text) Then
        a = 3
    End If

    If Not IsNull(rqRequirement.AttrValue(att, eAttrValueLookup_Label).text) Then
        a = 4
    End If
</code></pre>

<p>Both statements <strong>a = 3</strong> and <strong>a = 4</strong> are true and executed.</p>
","<vba><ms-word><requirements>","2018-03-02 10:25:04","30847","8","5","49077709","<p>To ensure mutual exclusivity, ask the question only once.</p>

<pre><code>a = IIf(rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text = vbNullString , 2, 1)
</code></pre>

<p>You can also use an <code>If-Then-Else</code> construct, particularly if you have other actions you want to perform at the same time.</p>

<p>The above code example assumes the  <code>~.text</code> call is correct.</p>
"
"49067215","Testing if a string is null","<p>I am pretty new in VBA and I have not yet got used to the syntax completely, so I'm sorry if my question sounds stupid.</p>

<p>I am working with RequisitePro40 and VBA 7.0 in Word 2010. In one of my modules I have the following loop and If conditions:</p>

<pre><code>Dim rqRequirements As ReqPro40.Requirements
Dim rqRequirement As ReqPro40.Requirement
Const eAttrValueLookup_Label = 4
Dim a As Integer
...

For Each vReqKey In rqRequirements
    Set rqRequirement = rqRequirements(vReqKey)

    If rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text &lt;&gt; Null Then
        a = 1
    End If

    If rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text = Null Then
         a = 2
    End If

 Next
</code></pre>

<p>In each iteration of the loop, both <strong>a = 1</strong> and <strong>a = 2</strong> are executed!!</p>

<p>Based on <a href=""https://learn.microsoft.com/en-us/dotnet/visual-basic/language-reference/operators/comparison-operators"" rel=""nofollow noreferrer"">This</a>, the equality and inequality operators are ""="" and ""&lt;>"". Therefore I would expect that either <strong>a = 1</strong> or <strong>a = 2</strong> execute for a string.
Is there something wrong with my syntax? Or is it a ReqPro related Problem?</p>

<p>I also tried using ""Is"" and ""IsNot"" operators but they result in Compiler error: Type mismatch</p>

<p>Can Someone help me with this?</p>

<p><strong>Update:</strong> The actual goal is to see if the</p>

<blockquote>
  <p>rqRequirement.AttrValue(""MyAttreName"", eAttrValueLookup_Label).text</p>
</blockquote>

<p>is Null or not. I added the second if to show the problem that the statement is somehow not working the way I expect it to work.</p>

<p>Replacing ""Null"" to ""vbNullString"" did not make any changes.</p>

<p>I also tried the IsNull function as @Slai suggested. the result is pretty much the same:</p>

<pre><code>    If IsNull(rqRequirement.AttrValue(att, eAttrValueLookup_Label).text) Then
        a = 3
    End If

    If Not IsNull(rqRequirement.AttrValue(att, eAttrValueLookup_Label).text) Then
        a = 4
    End If
</code></pre>

<p>Both statements <strong>a = 3</strong> and <strong>a = 4</strong> are true and executed.</p>
","<vba><ms-word><requirements>","2018-03-02 10:25:04","30847","8","5","57083876","<p>I landed here looking for an answer to ""VBA: How to test if a string is Null""</p>

<p>while this answer may not apply to this particular users situation, it does apply to the subject question.</p>

<pre><code>Dim s As String, s2 As String
s = """"
s2 = vbNullString
Debug.Print StrPtr(s) = 0, StrPtr(s2) = 0
</code></pre>

<p>which returns</p>

<pre><code>False   True
</code></pre>

<p>because <code>vbNullString</code> is a C style NULL pointer for working with COM objects, and so its memory address when returned by the undocumented <code>StrPtr</code> function will always be 0</p>
"