{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a24b781-070b-4205-a281-afb3df3269f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\tanjawolf_7ms6v6m\\anaconda3\\envs\\udemy_nlp-course\\lib\\site-packages (2.12.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('merged_adf_df_with_lda_topic1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b285204e-c68c-46a9-a13f-654d80e667ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "214/214 [==============================] - 4861s 23s/step - loss: 0.4608 - accuracy: 0.7889\n",
      "Epoch 2/7\n",
      "214/214 [==============================] - 4851s 23s/step - loss: 0.3037 - accuracy: 0.8660\n",
      "Epoch 3/7\n",
      "214/214 [==============================] - 4776s 22s/step - loss: 0.2250 - accuracy: 0.9084\n",
      "Epoch 4/7\n",
      "214/214 [==============================] - 4955s 23s/step - loss: 0.1712 - accuracy: 0.9349\n",
      "Epoch 5/7\n",
      "214/214 [==============================] - 4744s 22s/step - loss: 0.1243 - accuracy: 0.9522\n",
      "Epoch 6/7\n",
      "214/214 [==============================] - 5420s 25s/step - loss: 0.0920 - accuracy: 0.9650\n",
      "Epoch 7/7\n",
      "214/214 [==============================] - 5518s 26s/step - loss: 0.0714 - accuracy: 0.9729\n",
      "54/54 - 72s - loss: 0.5112 - accuracy: 0.8684 - 72s/epoch - 1s/step\n",
      "score: 0.51\n",
      "acc: 0.87\n"
     ]
    }
   ],
   "source": [
    "'''from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=5000, split=' ')\n",
    "tokenizer.fit_on_texts(df['LemmatizedQuestionBody'].values)\n",
    "\n",
    "# Convert text to sequences\n",
    "X = tokenizer.texts_to_sequences(df['LemmatizedQuestionBody'].values)\n",
    "X = pad_sequences(X)\n",
    "\n",
    "# Build the model\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, embed_dim, input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation='softmax')) # 2 for binary classification\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "Y = pd.get_dummies(df['LDATopic']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs = 7, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the model\n",
    "score, acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3f0bc6f-e6d0-4564-b88c-6a47c6323637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "#model.save('RNN_model.h5')  # HDF5 file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5b7588-ffdd-4da8-9e47-a1b817aa607d",
   "metadata": {},
   "source": [
    "***GPT4 prompt***: How to interpret these results?\n",
    "\n",
    "***GPT4 result***:\n",
    "\n",
    "The results you posted are from training and evaluating a Long Short-Term Memory (LSTM) model with TensorFlow. LSTM is a type of Recurrent Neural Network (RNN) that's good for sequence data, like text.\n",
    "\n",
    "The training part of your model is done over 7 epochs. Each epoch is a full pass through your dataset. Here's a summary of what happens in each epoch:\n",
    "\n",
    "    Epoch 1: The model starts with a loss of 0.4608 and accuracy of 78.89%. Loss is a measure of error—lower is better. Accuracy is the percentage of correct predictions—higher is better. The model is learning, but it's just starting, so it's not very accurate yet.\n",
    "\n",
    "    Epoch 2-6: The loss keeps decreasing and the accuracy keeps increasing. This is a good sign. It means the model is learning from the data and getting better at making predictions.\n",
    "\n",
    "    Epoch 7: The model ends with a loss of 0.0714 and accuracy of 97.29%. This is a high accuracy and low loss, suggesting that the model is performing well on the training data.\n",
    "\n",
    "After training, you evaluate the model on your test data. This is data that the model has never seen before, which gives you a good idea of how the model will perform on new, unseen data. The model ends with a test score (loss) of 0.51 and test accuracy of 87%, which is quite good.\n",
    "\n",
    "However, there's a significant difference between the accuracy on the training data (97.29%) and the accuracy on the test data (87%). This suggests that the model may be overfitting to the training data, i.e., it's learning the training data so well that it performs poorly on new data. You may need to adjust your model or add regularization to reduce overfitting.\n",
    "\n",
    "In summary, you've built a LSTM model that's achieving high accuracy on your training data, but it might be overfitting. You might need to try different strategies (like adding dropout, trying a simpler model, or collecting more data) to reduce overfitting and improve performance on your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "657724c1-8cdd-4a19-bd63-1c89b51bb98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('RNN_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4b67560-2ced-436b-ac16-9f46ef7fcd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 46s 844ms/step\n",
      "Confusion Matrix\n",
      "[[ 294  118]\n",
      " [ 107 1191]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred, axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_test, axis = 1)\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444341d2-47de-42c2-808b-155fa60ba220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
