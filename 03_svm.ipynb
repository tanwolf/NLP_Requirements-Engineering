{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3a28b1d-d87e-467f-9240-2bdbfe4891f1",
   "metadata": {},
   "source": [
    "**Project: Applying NLP in Requirements Engineering: Exploring Data Management Challenges in Azure Data Factory**\n",
    "\n",
    "Source data: Stackoverflow question and answers concerning Azure Data Factory\n",
    "\n",
    "Tags: azure-data-factory, adf \n",
    "\n",
    "Title keywords: azure data factory, adf\n",
    "\n",
    "Link to data source: https://data.stackexchange.com/stackoverflow/query/new\n",
    "\n",
    "Link to generated schema: https://dbdiagram.io/d/6448f5b26b3194705139098b\n",
    "\n",
    "Link to GitHub Repo: https://github.com/tanwolf/NLP_Requirements-Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb598e08-6e6b-428f-86e7-0b660bf52f2a",
   "metadata": {},
   "source": [
    "**Purposes of this notebook:** \n",
    "- Train a Support Vector Machine Model to correctly identify topics belonging to topic0/ \"Data Management in Pipelines\". The topic was identified through Latent Dirichilet Allocation   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b7e7e36-4e60-44c2-8707-0c23142508d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('merged_adf_df_with_lda_topic1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c98c9054-7ca8-4528-ab6b-472d7f61c918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['LemmatizedQuestionBody']).toarray()\n",
    "Y = df['LDATopic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3105937f-3367-4c43-abe2-d659ca129904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.61      0.70       412\n",
      "          11       0.89      0.96      0.92      1298\n",
      "\n",
      "    accuracy                           0.87      1710\n",
      "   macro avg       0.85      0.78      0.81      1710\n",
      "weighted avg       0.87      0.87      0.87      1710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''from sklearn import svm\n",
    "\n",
    "# Training the model\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluating the model\n",
    "Y_pred_svm = svm_model.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred_svm))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6ea9bc8-bf49-48ee-8cd8-a6a873685c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 251  161]\n",
      " [  54 1244]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, Y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b38df9f7-8730-43de-b2a7-6c83c9f5d8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.83508772 0.82105263 0.84259801 0.79169105 0.83382095]\n",
      "Average cross-validation score:  0.8248500713457136\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "scores = cross_val_score(svm_model, X, Y, cv=5)\n",
    "print(\"Cross-validation scores: \", scores)\n",
    "print(\"Average cross-validation score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a48fe6-110a-4c94-82bf-9a5d4b74266a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support vectors:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Inspect support vectors\n",
    "print(\"Support vectors:\")\n",
    "print(svm_model.support_vectors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2156c045-451c-4f12-afe5-bfcdcbf377ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients for support vectors:\n",
      "[[-0.94367023 -1.         -0.5883715  ...  0.89119695  1.\n",
      "   0.44994965]]\n"
     ]
    }
   ],
   "source": [
    "# Inspect coefficients for support vectors\n",
    "print(\"Coefficients for support vectors:\")\n",
    "print(svm_model.dual_coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e418e530-43cf-457f-a479-438b7a3c4e83",
   "metadata": {},
   "source": [
    "***GPT4 prompt:*** Summarize and anylze the results:\n",
    "\n",
    "***GPT4 result:*** The SVM model is used to classify the questions into two categories, class 0 and class 11.\n",
    "\n",
    "    Classification Report: The classification report shows that the model has an overall accuracy of 87%, which is quite good. The precision, recall and f1-score for class 0 are 82%, 61% and 70% respectively. For class 11, these metrics are 89%, 96% and 92%. This shows that the model is performing better on class 11 than class 0. The model has a high recall for class 11, meaning it is correctly identifying most of the positive class 11 instances. However, for class 0, the recall is lower indicating that the model is missing a fair amount of positive class 0 instances.\n",
    "\n",
    "    Confusion Matrix: The confusion matrix provides similar information. The model correctly identified 251 instances of class 0, but misclassified 161 as class 11. Similarly, the model correctly identified 1244 instances of class 11, but misclassified 54 as class 0. This again shows that the model is performing better on class 11 than class 0.\n",
    "\n",
    "    Cross-validation scores: The cross-validation scores are fairly consistent, ranging from about 0.79 to 0.84, with an average of 0.82. This suggests that the model's performance is robust and not overly dependent on the particular division of the data into training and test sets.\n",
    "\n",
    "    Support vectors: The support vectors represent the data points that are closest to the decision boundary. These are the data points that are most difficult to classify and have the most influence on the decision boundary.\n",
    "\n",
    "    Coefficients for support vectors: The coefficients for the support vectors determine the margin and position of the hyperplane in the SVM model. They are associated with each support vector and can be positive or negative. Positive coefficients push the hyperplane away from the corresponding support vector, while negative ones pull it closer.\n",
    "\n",
    "In conclusion, your SVM model seems to perform reasonably well with an average accuracy of 82% in cross-validation. The model is, however, more accurate for class 11 than for class 0. It might be beneficial to explore ways to improve the model's performance for class 0, perhaps by adjusting class weights, trying different kernels, or using more advanced techniques for dealing with imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1126e6d5-e6f6-4d07-8211-88df8d273349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1685\n",
      "          11       0.98      1.00      0.99      5152\n",
      "\n",
      "    accuracy                           0.98      6837\n",
      "   macro avg       0.99      0.97      0.98      6837\n",
      "weighted avg       0.98      0.98      0.98      6837\n",
      "\n",
      "Training Accuracy for SVM:  0.9840573350884891\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Make predictions on the training set\n",
    "Y_train_pred_svm = svm_model.predict(X_train)\n",
    "\n",
    "# Print a classification report for the training set\n",
    "print(classification_report(Y_train, Y_train_pred_svm))\n",
    "\n",
    "# Compute the accuracy on the training set\n",
    "train_accuracy_svm = accuracy_score(Y_train, Y_train_pred_svm)\n",
    "print(\"Training Accuracy for SVM: \", train_accuracy_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f1587b-5fd4-470b-9368-2bdd7efa9311",
   "metadata": {},
   "source": [
    "***GPT4:*** \n",
    "\n",
    "Based on the provided results:\n",
    "\n",
    "In the classification report for the test data, the SVM model achieves an accuracy of 0.87. When we look at the precision, recall, and F1-score metrics for the individual classes (0 and 11), we see that the model performs better on class 11 than on class 0. This suggests that the model might have difficulties distinguishing class 0 instances.\n",
    "\n",
    "In the classification report for the training data, the SVM model achieves an accuracy of 0.98, which is higher than that of the test data. Again, the model performs slightly better on class 11 than on class 0, but the difference is less pronounced than in the test data.\n",
    "\n",
    "The accuracy on the training set is higher than the accuracy on the test set. This difference could indicate some degree of overfitting, as the model seems to perform better on the data it was trained on than on new data. However, the difference is not extremely large, so it might not be a major concern.\n",
    "\n",
    "In summary, the SVM model performs fairly well, but it might have difficulties distinguishing instances of class 0. There might be some degree of overfitting, but it's not clear whether this is a major issue based on the provided results alone. Other diagnostic tools, such as learning curves or more detailed error analysis, could provide more insights into the model's performance and potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ae5f11-3230-438c-b740-c673e8086992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
